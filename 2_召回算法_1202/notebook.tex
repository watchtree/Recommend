
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{movie\_recommender}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{个性化推荐}\label{ux4e2aux6027ux5316ux63a8ux8350}

\textbf{本项目使用文本卷积神经网络，并使用\href{https://grouplens.org/datasets/movielens/}{\texttt{MovieLens}}数据集完成电影推荐的任务。}

    推荐系统在日常的网络应用中无处不在，比如网上购物、网上买书、新闻app、社交网络、音乐网站、电影网站等等等等，有人的地方就有推荐。根据个人的喜好，相同喜好人群的习惯等信息进行个性化的内容推荐。比如打开新闻类的app，因为有了个性化的内容，每个人看到的新闻首页都是不一样的。

    这当然是很有用的，在信息爆炸的今天，获取信息的途径和方式多种多样，人们花费时间最多的不再是去哪获取信息，而是要在众多的信息中寻找自己感兴趣的，这就是信息超载问题。为了解决这个问题，推荐系统应运而生。

    协同过滤是推荐系统应用较广泛的技术，该方法搜集用户的历史记录、个人喜好等信息，计算与其他用户的相似度，利用相似用户的评价来预测目标用户对特定项目的喜好程度。优点是会给用户推荐未浏览过的项目，缺点呢，对于新用户来说，没有任何与商品的交互记录和个人喜好等信息，存在冷启动问题，导致模型无法找到相似的用户或商品。

    为了解决\textbf{冷启动}的问题，通常的做法是对于刚注册的用户，要求用户先选择自己感兴趣的话题、群组、商品、性格、喜欢的音乐类型等信息，比如豆瓣FM：

    \subsection{下载数据集准备}\label{ux4e0bux8f7dux6570ux636eux96c6ux51c6ux5907}

运行下面代码把\href{http://files.grouplens.org/datasets/movielens/ml-1m.zip}{\texttt{数据集}}下载下来

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}\PY{c+c1}{\PYZsh{}支持便捷和快速地计数}
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{pickle}
        \PY{k+kn}{import} \PY{n+nn}{re}
        \PY{k+kn}{from} \PY{n+nn}{tensorflow}\PY{n+nn}{.}\PY{n+nn}{python}\PY{n+nn}{.}\PY{n+nn}{ops} \PY{k}{import} \PY{n}{math\PYZus{}ops}\PY{c+c1}{\PYZsh{}tensorflow中的图上的节点称之为operations或者ops}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{from} \PY{n+nn}{urllib}\PY{n+nn}{.}\PY{n+nn}{request} \PY{k}{import} \PY{n}{urlretrieve} \PY{c+c1}{\PYZsh{}用于打开URL的可扩展库,将URL表示的网络对象复制到本地文件}
        \PY{k+kn}{from} \PY{n+nn}{os}\PY{n+nn}{.}\PY{n+nn}{path} \PY{k}{import} \PY{n}{isfile}\PY{p}{,} \PY{n}{isdir}
        \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k}{import} \PY{n}{tqdm} \PY{c+c1}{\PYZsh{}Tqdm 是一个快速，可扩展的Python进度条}
        \PY{k+kn}{import} \PY{n+nn}{zipfile}
        \PY{k+kn}{import} \PY{n+nn}{hashlib} \PY{c+c1}{\PYZsh{}hashlib模块提供了很多加密的算法}
        
        \PY{k}{def} \PY{n+nf}{\PYZus{}unzip}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{database\PYZus{}name}\PY{p}{,} \PY{n}{data\PYZus{}path}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} 实现类似于c++中私有方法，意味着该方法或属性不应该去调用}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Unzip wrapper with the same interface as \PYZus{}ungzip}
        \PY{l+s+sd}{    使用与\PYZus{}ungzip相同的接口解压缩包装器}
        \PY{l+s+sd}{    :param save\PYZus{}path: The path of the gzip files}
        \PY{l+s+sd}{    :param database\PYZus{}name: Name of database}
        \PY{l+s+sd}{    :param data\PYZus{}path: Path to extract to}
        \PY{l+s+sd}{    :param \PYZus{}: HACK \PYZhy{} Used to have to same interface as \PYZus{}ungzip}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Extracting }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{...}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{database\PYZus{}name}\PY{p}{)}\PY{p}{)}
            \PY{k}{with} \PY{n}{zipfile}\PY{o}{.}\PY{n}{ZipFile}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{)} \PY{k}{as} \PY{n}{zf}\PY{p}{:}\PY{c+c1}{\PYZsh{}ZipFile是主要的类，用来创建和读取zip文件}
                \PY{n}{zf}\PY{o}{.}\PY{n}{extractall}\PY{p}{(}\PY{n}{data\PYZus{}path}\PY{p}{)}\PY{c+c1}{\PYZsh{}将所有文件解压到channel1目录下}
        
        \PY{k}{def} \PY{n+nf}{download\PYZus{}extract}\PY{p}{(}\PY{n}{database\PYZus{}name}\PY{p}{,} \PY{n}{data\PYZus{}path}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{}下载并提取主程序}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Download and extract database}
        \PY{l+s+sd}{    下载并提取数据库}
        \PY{l+s+sd}{    :param database\PYZus{}name: Database name}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{DATASET\PYZus{}ML1M} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ml\PYZhy{}1m}\PY{l+s+s1}{\PYZsq{}}
            \PY{c+c1}{\PYZsh{}如果要下载m1数据集，见url和hashcode对应，设定地址文件}
            \PY{k}{if} \PY{n}{database\PYZus{}name} \PY{o}{==} \PY{n}{DATASET\PYZus{}ML1M}\PY{p}{:}
                \PY{n}{url} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{http://files.grouplens.org/datasets/movielens/ml\PYZhy{}1m.zip}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{hash\PYZus{}code} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{c4d9eecfca2ab87c1945afe126590906}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{extract\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ml\PYZhy{}1m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                \PY{n}{save\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ml\PYZhy{}1m.zip}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                \PY{n}{extract\PYZus{}fn} \PY{o}{=} \PY{n}{\PYZus{}unzip} \PY{c+c1}{\PYZsh{}调用私有方法，打开zip保存路径的文件并提取}
            
            \PY{c+c1}{\PYZsh{}提取路径存在就直接返回}
            \PY{k}{if} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{extract\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Found }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ Data}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{database\PYZus{}name}\PY{p}{)}\PY{p}{)}
                \PY{k}{return}
            
            \PY{c+c1}{\PYZsh{}如果不存在对文件在当前位置创建文件夹}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{data\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{data\PYZus{}path}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}如果下载文件保存的位置不存在，}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{}生成一个动态下载条}
                \PY{k}{with} \PY{n}{DLProgress}\PY{p}{(}\PY{n}{unit}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{B}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{unit\PYZus{}scale}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{miniters}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{desc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Downloading }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{database\PYZus{}name}\PY{p}{)}\PY{p}{)} \PY{k}{as} \PY{n}{pbar}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} urlretrieve方法直接将远程数据下载到本地。}
                    \PY{n}{urlretrieve}\PY{p}{(}
                        \PY{n}{url}\PY{p}{,}
                        \PY{n}{save\PYZus{}path}\PY{p}{,}
                        \PY{n}{pbar}\PY{o}{.}\PY{n}{hook}\PY{p}{)}
            \PY{c+c1}{\PYZsh{}python assert 断言句语格式及用法很简单。在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行最崩溃，不如在出现错误条件时就崩溃}
            \PY{c+c1}{\PYZsh{}见下载文件的md5文件与hashcode值相对应进行判定}
            \PY{c+c1}{\PYZsh{}读取文件，并hexdigest()返回摘要，作为十六进制数据字符串值，如果不相等，文件不存在，删除文件重新尝试}
            \PY{k}{assert} \PY{n}{hashlib}\PY{o}{.}\PY{n}{md5}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{hexdigest}\PY{p}{(}\PY{p}{)} \PY{o}{==} \PY{n}{hash\PYZus{}code}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ file is corrupted.  Remove the file and try again.}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{)}
        
            \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{extract\PYZus{}path}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}解压缩，对应地址和文件位置}
            \PY{k}{try}\PY{p}{:}
                \PY{n}{extract\PYZus{}fn}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{,} \PY{n}{extract\PYZus{}path}\PY{p}{,} \PY{n}{database\PYZus{}name}\PY{p}{,} \PY{n}{data\PYZus{}path}\PY{p}{)}
            \PY{k}{except} \PY{n+ne}{Exception} \PY{k}{as} \PY{n}{err}\PY{p}{:}
                \PY{n}{shutil}\PY{o}{.}\PY{n}{rmtree}\PY{p}{(}\PY{n}{extract\PYZus{}path}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Remove extraction folder if there is an error}
                \PY{k}{raise} \PY{n}{err}
            
            \PY{c+c1}{\PYZsh{}结束}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Done.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Remove compressed data}
        \PY{c+c1}{\PYZsh{}     os.remove(save\PYZus{}path)}
        
        \PY{k}{class} \PY{n+nc}{DLProgress}\PY{p}{(}\PY{n}{tqdm}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Handle Progress Bar while Downloading}
        \PY{l+s+sd}{    下载时处理进度条}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{n}{last\PYZus{}block} \PY{o}{=} \PY{l+m+mi}{0}
        
            \PY{k}{def} \PY{n+nf}{hook}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{block\PYZus{}num}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{block\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{total\PYZus{}size}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        A hook function}
        \PY{l+s+sd}{        在建立网络连接时将被调用一次 之后每个块读取一次。}
        \PY{l+s+sd}{        :param block\PYZus{}num: A count of blocks transferred so far}
        \PY{l+s+sd}{        :param block\PYZus{}size: Block size in bytes}
        \PY{l+s+sd}{        :param total\PYZus{}size: The total size of the file. This may be \PYZhy{}1 on older FTP servers which do not return}
        \PY{l+s+sd}{                            a file size in response to a retrieval request.}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{total} \PY{o}{=} \PY{n}{total\PYZus{}size}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{update}\PY{p}{(}\PY{p}{(}\PY{n}{block\PYZus{}num} \PY{o}{\PYZhy{}} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{last\PYZus{}block}\PY{p}{)} \PY{o}{*} \PY{n}{block\PYZus{}size}\PY{p}{)}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{last\PYZus{}block} \PY{o}{=} \PY{n}{block\PYZus{}num}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{}当前运行文件目录下（相对路径）}
        \PY{n}{download\PYZus{}extract}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ml\PYZhy{}1m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data\PYZus{}dir}\PY{p}{)} \PY{c+c1}{\PYZsh{}下载并保存在当前文件夹下}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Downloading ml-1m: 5.92MB [00:07, 760kB/s]                                                                             

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Extracting ml-1m{\ldots}
Done.

    \end{Verbatim}

    \subsection{先来看看数据}\label{ux5148ux6765ux770bux770bux6570ux636e}

    本项目使用的是MovieLens 1M
数据集，包含6000个用户在近4000部电影上的1亿条评论。

数据集分为三个文件：用户数据users.dat，电影数据movies.dat和评分数据ratings.dat。

    \subsubsection{用户数据}\label{ux7528ux6237ux6570ux636e}

分别有用户ID、性别、年龄、职业ID和邮编等字段。

数据中的格式：UserID::Gender::Age::Occupation::Zip-code

\begin{itemize}
\item
  Gender is denoted by a "M" for male and "F" for female
\item
  Age is chosen from the following ranges:

  \begin{itemize}
  \tightlist
  \item
    1: "Under 18"
  \item
    18: "18-24"
  \item
    25: "25-34"
  \item
    35: "35-44"
  \item
    45: "45-49"
  \item
    50: "50-55"
  \item
    56: "56+"
  \end{itemize}
\item
  Occupation is chosen from the following choices:

  \begin{itemize}
  \tightlist
  \item
    0: "other" or not specified
  \item
    1: "academic/educator"
  \item
    2: "artist"
  \item
    3: "clerical/admin"
  \item
    4: "college/grad student"
  \item
    5: "customer service"
  \item
    6: "doctor/health care"
  \item
    7: "executive/managerial"
  \item
    8: "farmer"
  \item
    9: "homemaker"
  \item
    10: "K-12 student"
  \item
    11: "lawyer"
  \item
    12: "programmer"
  \item
    13: "retired"
  \item
    14: "sales/marketing"
  \item
    15: "scientist"
  \item
    16: "self-employed"
  \item
    17: "technician/engineer"
  \item
    18: "tradesman/craftsman"
  \item
    19: "unemployed"
  \item
    20: "writer"
  \end{itemize}
\end{itemize}

    \textbf{数据处理}

Gender字段：需要将`F'和`M'转换成0和1。
Age字段：要转成7个连续数字0\textasciitilde{}6。 Occupationid职业id保留

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{}UserID::Gender::Age::Occupation::Zip\PYZhy{}code基本的user信息}
        \PY{n}{users\PYZus{}title} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{OccupationID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Zip\PYZhy{}code}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{users} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./ml\PYZhy{}1m/users.dat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{users\PYZus{}title}\PY{p}{,} \PY{n}{engine} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}sep=\PYZsq{}::\PYZsq{},间隔符}
        \PY{c+c1}{\PYZsh{}pd.read\PYZus{}table读取dat文件}
        \PY{n}{users} \PY{o}{=} \PY{n}{users}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{n}{regex}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID|Gender|Age|JobID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{gender\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
        \PY{n}{users}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Gender}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{users}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Gender}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{gender\PYZus{}map}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}map()是python 自带的方法, 可以对df某列内的元素进行操作, 我个人最常用的场景就是有toward\PYZus{}dict的映射关系 ,为df中的toward匹配出结果,}
        \PY{n}{age\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{ii} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}} \PY{c+c1}{\PYZsh{}对应key\PYZhy{}value值来源于}
        \PY{c+c1}{\PYZsh{}enumerate函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引索引}
        \PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{age\PYZus{}map}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{users}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:}    UserID  Gender  Age
        0       1       0    0
        1       2       1    5
        2       3       1    6
        3       4       1    2
        4       5       1    6
\end{Verbatim}
            
    可以看出UserID、Gender、Age和Occupation都是类别字段，其中邮编字段是我们不使用的。

    \subsubsection{电影数据}\label{ux7535ux5f71ux6570ux636e}

分别有电影ID、电影名和电影风格等字段。

数据中的格式：MovieID::Title::Genres

\begin{itemize}
\item
  Titles are identical to titles provided by the IMDB (including year of
  release)
\item
  Genres are pipe-separated and are selected from the following genres:

  \begin{itemize}
  \tightlist
  \item
    Action
  \item
    Adventure
  \item
    Animation
  \item
    Children's
  \item
    Comedy
  \item
    Crime
  \item
    Documentary
  \item
    Drama
  \item
    Fantasy
  \item
    Film-Noir
  \item
    Horror
  \item
    Musical
  \item
    Mystery
  \item
    Romance
  \item
    Sci-Fi
  \item
    Thriller
  \item
    War
  \item
    Western
  \end{itemize}
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{movies\PYZus{}title} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MovieID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{movies} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./ml\PYZhy{}1m/movies.dat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{movies\PYZus{}title}\PY{p}{,} \PY{n}{engine} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{movies}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:}    MovieID                               Title                        Genres
        0        1                    Toy Story (1995)   Animation|Children's|Comedy
        1        2                      Jumanji (1995)  Adventure|Children's|Fantasy
        2        3             Grumpier Old Men (1995)                Comedy|Romance
        3        4            Waiting to Exhale (1995)                  Comedy|Drama
        4        5  Father of the Bride Part II (1995)                        Comedy
\end{Verbatim}
            
    正则表达式re.compile() 需要和findall(), search(), match(）搭配使用
compile()与findall()一起使用，返回一个列表。

    \textbf{movie的title}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{}取出时间序列参数re正则化 r 表示原生字符串正则表达式里使用\PYZdq{}\PYZbs{}\PYZdq{}作为转义字符，这就可能造成反斜杠困扰。}
        \PY{c+c1}{\PYZsh{}假如你需要匹配文本中的字符\PYZdq{}\PYZbs{}\PYZdq{}，那么使用编程语言表示的正则表达式里将需要4个反斜杠\PYZdq{}\PYZbs{}\PYZbs{}\PYZbs{}\PYZbs{}\PYZdq{}：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠}
        \PY{n}{pattern} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZca{}(.*)}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{((}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{d+)}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{)\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} \PYZsh{}将title转化为对应字典id}
        \PY{c+c1}{\PYZsh{} title\PYZus{}map = \PYZob{}val:pattern.match(val).group(1) for ii,val in enumerate(set(movies[\PYZsq{}Title\PYZsq{}]))\PYZcb{}}
        \PY{c+c1}{\PYZsh{} movies[\PYZsq{}Title\PYZsq{}] = movies[\PYZsq{}Title\PYZsq{}].map(title\PYZus{}map)}
            \PY{c+c1}{\PYZsh{}将Title中的年份去掉}
        
        \PY{n}{title\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{pattern}\PY{o}{.}\PY{n}{match}\PY{p}{(}\PY{n}{val}\PY{p}{)}\PY{o}{.}\PY{n}{group}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}} 
        \PY{c+c1}{\PYZsh{}group()用来提出分组截获的字符串}
        \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{)}
\end{Verbatim}


    \textbf{属性类型的onehot编码}(进行了修改针对set的对应问题)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{}获取可能出现的类型集合}
        \PY{n}{genres\PYZus{}set} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
        \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{n}{genres\PYZus{}set}\PY{o}{.}\PY{n}{update}\PY{p}{(}\PY{n}{val}\PY{p}{)}
        \PY{n}{genres\PYZus{}list} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{genres\PYZus{}set}\PY{p}{)} \PY{c+c1}{\PYZsh{}}
        \PY{n}{genres\PYZus{}list}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{}作为0等级对应}
        \PY{n}{genres2int} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{ii} \PY{k}{for} \PY{n}{ii}\PY{p}{,} \PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{genres\PYZus{}list}\PY{p}{)}\PY{p}{\PYZcb{}} 
        \PY{c+c1}{\PYZsh{}将电影类型转成等长数字列表，长度是18}
        \PY{n}{genres\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{p}{[}\PY{n}{genres2int}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{val}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
        \PY{c+c1}{\PYZsh{}将movies中可能出现的类型的组合提取出来，对应val和val进行分割后对应的数字}
\end{Verbatim}


    ** 理论上是否应该把pad设为0，但是元祖顺序是随机的**

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{genres\PYZus{}map} 
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}10}]:} \{'Action': [9],
          'Action|Adventure': [9, 12],
          'Action|Adventure|Animation': [9, 12, 15],
          "Action|Adventure|Animation|Children's|Fantasy": [9, 12, 15, 16, 11],
          'Action|Adventure|Animation|Horror|Sci-Fi': [9, 12, 15, 8, 18],
          "Action|Adventure|Children's": [9, 12, 16],
          "Action|Adventure|Children's|Comedy": [9, 12, 16, 1],
          "Action|Adventure|Children's|Fantasy": [9, 12, 16, 11],
          "Action|Adventure|Children's|Sci-Fi": [9, 12, 16, 18],
          'Action|Adventure|Comedy': [9, 12, 1],
          'Action|Adventure|Comedy|Crime': [9, 12, 1, 4],
          'Action|Adventure|Comedy|Horror': [9, 12, 1, 8],
          'Action|Adventure|Comedy|Horror|Sci-Fi': [9, 12, 1, 8, 18],
          'Action|Adventure|Comedy|Romance': [9, 12, 1, 3],
          'Action|Adventure|Comedy|Sci-Fi': [9, 12, 1, 18],
          'Action|Adventure|Comedy|War': [9, 12, 1, 5],
          'Action|Adventure|Crime': [9, 12, 4],
          'Action|Adventure|Crime|Drama': [9, 12, 4, 6],
          'Action|Adventure|Crime|Thriller': [9, 12, 4, 17],
          'Action|Adventure|Drama': [9, 12, 6],
          'Action|Adventure|Drama|Romance': [9, 12, 6, 3],
          'Action|Adventure|Drama|Sci-Fi|War': [9, 12, 6, 18, 5],
          'Action|Adventure|Drama|Thriller': [9, 12, 6, 17],
          'Action|Adventure|Fantasy': [9, 12, 11],
          'Action|Adventure|Fantasy|Sci-Fi': [9, 12, 11, 18],
          'Action|Adventure|Horror': [9, 12, 8],
          'Action|Adventure|Horror|Thriller': [9, 12, 8, 17],
          'Action|Adventure|Mystery': [9, 12, 2],
          'Action|Adventure|Mystery|Sci-Fi': [9, 12, 2, 18],
          'Action|Adventure|Romance': [9, 12, 3],
          'Action|Adventure|Romance|Sci-Fi|War': [9, 12, 3, 18, 5],
          'Action|Adventure|Romance|Thriller': [9, 12, 3, 17],
          'Action|Adventure|Romance|War': [9, 12, 3, 5],
          'Action|Adventure|Sci-Fi': [9, 12, 18],
          'Action|Adventure|Sci-Fi|Thriller': [9, 12, 18, 17],
          'Action|Adventure|Sci-Fi|Thriller|War': [9, 12, 18, 17, 5],
          'Action|Adventure|Sci-Fi|War': [9, 12, 18, 5],
          'Action|Adventure|Thriller': [9, 12, 17],
          'Action|Adventure|War': [9, 12, 5],
          'Action|Adventure|Western': [9, 12, 7],
          "Action|Animation|Children's|Sci-Fi|Thriller|War": [9, 15, 16, 18, 17, 5],
          "Action|Children's": [9, 16],
          "Action|Children's|Fantasy": [9, 16, 11],
          'Action|Comedy': [9, 1],
          'Action|Comedy|Crime': [9, 1, 4],
          'Action|Comedy|Crime|Drama': [9, 1, 4, 6],
          'Action|Comedy|Crime|Horror|Thriller': [9, 1, 4, 8, 17],
          'Action|Comedy|Drama': [9, 1, 6],
          'Action|Comedy|Fantasy': [9, 1, 11],
          'Action|Comedy|Musical': [9, 1, 10],
          'Action|Comedy|Musical|Sci-Fi': [9, 1, 10, 18],
          'Action|Comedy|Romance|Thriller': [9, 1, 3, 17],
          'Action|Comedy|Sci-Fi|Thriller': [9, 1, 18, 17],
          'Action|Comedy|Sci-Fi|War': [9, 1, 18, 5],
          'Action|Comedy|War': [9, 1, 5],
          'Action|Comedy|Western': [9, 1, 7],
          'Action|Crime': [9, 4],
          'Action|Crime|Drama': [9, 4, 6],
          'Action|Crime|Drama|Thriller': [9, 4, 6, 17],
          'Action|Crime|Mystery': [9, 4, 2],
          'Action|Crime|Mystery|Thriller': [9, 4, 2, 17],
          'Action|Crime|Romance': [9, 4, 3],
          'Action|Crime|Sci-Fi': [9, 4, 18],
          'Action|Crime|Thriller': [9, 4, 17],
          'Action|Drama': [9, 6],
          'Action|Drama|Fantasy|Romance': [9, 6, 11, 3],
          'Action|Drama|Mystery': [9, 6, 2],
          'Action|Drama|Mystery|Romance|Thriller': [9, 6, 2, 3, 17],
          'Action|Drama|Romance': [9, 6, 3],
          'Action|Drama|Romance|Thriller': [9, 6, 3, 17],
          'Action|Drama|Sci-Fi|Thriller': [9, 6, 18, 17],
          'Action|Drama|Thriller': [9, 6, 17],
          'Action|Drama|Thriller|War': [9, 6, 17, 5],
          'Action|Drama|War': [9, 6, 5],
          'Action|Drama|Western': [9, 6, 7],
          'Action|Horror': [9, 8],
          'Action|Horror|Sci-Fi': [9, 8, 18],
          'Action|Horror|Sci-Fi|Thriller': [9, 8, 18, 17],
          'Action|Horror|Thriller': [9, 8, 17],
          'Action|Mystery|Romance|Thriller': [9, 2, 3, 17],
          'Action|Mystery|Sci-Fi|Thriller': [9, 2, 18, 17],
          'Action|Mystery|Thriller': [9, 2, 17],
          'Action|Romance': [9, 3],
          'Action|Romance|Sci-Fi': [9, 3, 18],
          'Action|Romance|Thriller': [9, 3, 17],
          'Action|Romance|War': [9, 3, 5],
          'Action|Sci-Fi': [9, 18],
          'Action|Sci-Fi|Thriller': [9, 18, 17],
          'Action|Sci-Fi|Thriller|War': [9, 18, 17, 5],
          'Action|Sci-Fi|Thriller|Western': [9, 18, 17, 7],
          'Action|Sci-Fi|War': [9, 18, 5],
          'Action|Sci-Fi|Western': [9, 18, 7],
          'Action|Thriller': [9, 17],
          'Action|Thriller|War': [9, 17, 5],
          'Action|War': [9, 5],
          'Action|Western': [9, 7],
          'Adventure': [12],
          "Adventure|Animation|Children's": [12, 15, 16],
          "Adventure|Animation|Children's|Comedy|Fantasy": [12, 15, 16, 1, 11],
          "Adventure|Animation|Children's|Comedy|Musical": [12, 15, 16, 1, 10],
          "Adventure|Animation|Children's|Fantasy": [12, 15, 16, 11],
          "Adventure|Animation|Children's|Musical": [12, 15, 16, 10],
          "Adventure|Animation|Children's|Sci-Fi": [12, 15, 16, 18],
          'Adventure|Animation|Film-Noir': [12, 15, 13],
          'Adventure|Animation|Sci-Fi': [12, 15, 18],
          'Adventure|Animation|Sci-Fi|Thriller': [12, 15, 18, 17],
          "Adventure|Children's": [12, 16],
          "Adventure|Children's|Comedy": [12, 16, 1],
          "Adventure|Children's|Comedy|Fantasy": [12, 16, 1, 11],
          "Adventure|Children's|Comedy|Fantasy|Romance": [12, 16, 1, 11, 3],
          "Adventure|Children's|Comedy|Fantasy|Sci-Fi": [12, 16, 1, 11, 18],
          "Adventure|Children's|Comedy|Musical": [12, 16, 1, 10],
          "Adventure|Children's|Drama": [12, 16, 6],
          "Adventure|Children's|Drama|Musical": [12, 16, 6, 10],
          "Adventure|Children's|Drama|Romance": [12, 16, 6, 3],
          "Adventure|Children's|Fantasy": [12, 16, 11],
          "Adventure|Children's|Fantasy|Sci-Fi": [12, 16, 11, 18],
          "Adventure|Children's|Musical": [12, 16, 10],
          "Adventure|Children's|Romance": [12, 16, 3],
          "Adventure|Children's|Sci-Fi": [12, 16, 18],
          'Adventure|Comedy': [12, 1],
          'Adventure|Comedy|Drama': [12, 1, 6],
          'Adventure|Comedy|Musical': [12, 1, 10],
          'Adventure|Comedy|Romance': [12, 1, 3],
          'Adventure|Comedy|Sci-Fi': [12, 1, 18],
          'Adventure|Crime|Sci-Fi|Thriller': [12, 4, 18, 17],
          'Adventure|Drama': [12, 6],
          'Adventure|Drama|Romance': [12, 6, 3],
          'Adventure|Drama|Romance|Sci-Fi': [12, 6, 3, 18],
          'Adventure|Drama|Thriller': [12, 6, 17],
          'Adventure|Drama|Western': [12, 6, 7],
          'Adventure|Fantasy': [12, 11],
          'Adventure|Fantasy|Romance': [12, 11, 3],
          'Adventure|Fantasy|Sci-Fi': [12, 11, 18],
          'Adventure|Musical': [12, 10],
          'Adventure|Musical|Romance': [12, 10, 3],
          'Adventure|Romance': [12, 3],
          'Adventure|Romance|Sci-Fi': [12, 3, 18],
          'Adventure|Sci-Fi': [12, 18],
          'Adventure|Sci-Fi|Thriller': [12, 18, 17],
          'Adventure|Thriller': [12, 17],
          'Adventure|War': [12, 5],
          'Adventure|Western': [12, 7],
          'Animation': [15],
          "Animation|Children's": [15, 16],
          "Animation|Children's|Comedy": [15, 16, 1],
          "Animation|Children's|Comedy|Musical": [15, 16, 1, 10],
          "Animation|Children's|Comedy|Musical|Romance": [15, 16, 1, 10, 3],
          "Animation|Children's|Comedy|Romance": [15, 16, 1, 3],
          "Animation|Children's|Drama|Fantasy": [15, 16, 6, 11],
          "Animation|Children's|Fantasy|Musical": [15, 16, 11, 10],
          "Animation|Children's|Fantasy|War": [15, 16, 11, 5],
          "Animation|Children's|Musical": [15, 16, 10],
          "Animation|Children's|Musical|Romance": [15, 16, 10, 3],
          'Animation|Comedy': [15, 1],
          'Animation|Comedy|Thriller': [15, 1, 17],
          'Animation|Musical': [15, 10],
          'Animation|Mystery': [15, 2],
          'Animation|Sci-Fi': [15, 18],
          "Children's": [16],
          "Children's|Comedy": [16, 1],
          "Children's|Comedy|Drama": [16, 1, 6],
          "Children's|Comedy|Fantasy": [16, 1, 11],
          "Children's|Comedy|Musical": [16, 1, 10],
          "Children's|Comedy|Mystery": [16, 1, 2],
          "Children's|Comedy|Sci-Fi": [16, 1, 18],
          "Children's|Comedy|Western": [16, 1, 7],
          "Children's|Drama": [16, 6],
          "Children's|Drama|Fantasy": [16, 6, 11],
          "Children's|Drama|Fantasy|Sci-Fi": [16, 6, 11, 18],
          "Children's|Fantasy": [16, 11],
          "Children's|Fantasy|Musical": [16, 11, 10],
          "Children's|Fantasy|Sci-Fi": [16, 11, 18],
          "Children's|Horror": [16, 8],
          "Children's|Musical": [16, 10],
          "Children's|Sci-Fi": [16, 18],
          'Comedy': [1],
          'Comedy|Crime': [1, 4],
          'Comedy|Crime|Drama': [1, 4, 6],
          'Comedy|Crime|Drama|Mystery': [1, 4, 6, 2],
          'Comedy|Crime|Fantasy': [1, 4, 11],
          'Comedy|Crime|Horror': [1, 4, 8],
          'Comedy|Crime|Mystery|Thriller': [1, 4, 2, 17],
          'Comedy|Crime|Thriller': [1, 4, 17],
          'Comedy|Documentary': [1, 14],
          'Comedy|Drama': [1, 6],
          'Comedy|Drama|Musical': [1, 6, 10],
          'Comedy|Drama|Romance': [1, 6, 3],
          'Comedy|Drama|Sci-Fi': [1, 6, 18],
          'Comedy|Drama|Thriller': [1, 6, 17],
          'Comedy|Drama|War': [1, 6, 5],
          'Comedy|Drama|Western': [1, 6, 7],
          'Comedy|Fantasy': [1, 11],
          'Comedy|Fantasy|Romance': [1, 11, 3],
          'Comedy|Fantasy|Romance|Sci-Fi': [1, 11, 3, 18],
          'Comedy|Film-Noir|Thriller': [1, 13, 17],
          'Comedy|Horror': [1, 8],
          'Comedy|Horror|Musical': [1, 8, 10],
          'Comedy|Horror|Musical|Sci-Fi': [1, 8, 10, 18],
          'Comedy|Horror|Sci-Fi': [1, 8, 18],
          'Comedy|Horror|Thriller': [1, 8, 17],
          'Comedy|Musical': [1, 10],
          'Comedy|Musical|Romance': [1, 10, 3],
          'Comedy|Mystery': [1, 2],
          'Comedy|Mystery|Romance': [1, 2, 3],
          'Comedy|Mystery|Romance|Thriller': [1, 2, 3, 17],
          'Comedy|Mystery|Thriller': [1, 2, 17],
          'Comedy|Romance': [1, 3],
          'Comedy|Romance|Sci-Fi': [1, 3, 18],
          'Comedy|Romance|Thriller': [1, 3, 17],
          'Comedy|Romance|War': [1, 3, 5],
          'Comedy|Sci-Fi': [1, 18],
          'Comedy|Sci-Fi|Western': [1, 18, 7],
          'Comedy|Thriller': [1, 17],
          'Comedy|War': [1, 5],
          'Comedy|Western': [1, 7],
          'Crime': [4],
          'Crime|Drama': [4, 6],
          'Crime|Drama|Film-Noir': [4, 6, 13],
          'Crime|Drama|Film-Noir|Thriller': [4, 6, 13, 17],
          'Crime|Drama|Mystery': [4, 6, 2],
          'Crime|Drama|Mystery|Thriller': [4, 6, 2, 17],
          'Crime|Drama|Romance': [4, 6, 3],
          'Crime|Drama|Romance|Thriller': [4, 6, 3, 17],
          'Crime|Drama|Sci-Fi': [4, 6, 18],
          'Crime|Drama|Thriller': [4, 6, 17],
          'Crime|Film-Noir': [4, 13],
          'Crime|Film-Noir|Mystery': [4, 13, 2],
          'Crime|Film-Noir|Mystery|Thriller': [4, 13, 2, 17],
          'Crime|Film-Noir|Thriller': [4, 13, 17],
          'Crime|Horror': [4, 8],
          'Crime|Horror|Mystery|Thriller': [4, 8, 2, 17],
          'Crime|Horror|Thriller': [4, 8, 17],
          'Crime|Mystery': [4, 2],
          'Crime|Thriller': [4, 17],
          'Documentary': [14],
          'Documentary|Drama': [14, 6],
          'Documentary|Musical': [14, 10],
          'Documentary|War': [14, 5],
          'Drama': [6],
          'Drama|Fantasy': [6, 11],
          'Drama|Fantasy|Romance|Thriller': [6, 11, 3, 17],
          'Drama|Film-Noir': [6, 13],
          'Drama|Film-Noir|Thriller': [6, 13, 17],
          'Drama|Horror': [6, 8],
          'Drama|Horror|Thriller': [6, 8, 17],
          'Drama|Musical': [6, 10],
          'Drama|Musical|War': [6, 10, 5],
          'Drama|Mystery': [6, 2],
          'Drama|Mystery|Romance': [6, 2, 3],
          'Drama|Mystery|Sci-Fi|Thriller': [6, 2, 18, 17],
          'Drama|Mystery|Thriller': [6, 2, 17],
          'Drama|Romance': [6, 3],
          'Drama|Romance|Sci-Fi': [6, 3, 18],
          'Drama|Romance|Thriller': [6, 3, 17],
          'Drama|Romance|War': [6, 3, 5],
          'Drama|Romance|War|Western': [6, 3, 5, 7],
          'Drama|Romance|Western': [6, 3, 7],
          'Drama|Sci-Fi': [6, 18],
          'Drama|Sci-Fi|Thriller': [6, 18, 17],
          'Drama|Thriller': [6, 17],
          'Drama|Thriller|War': [6, 17, 5],
          'Drama|War': [6, 5],
          'Drama|Western': [6, 7],
          'Fantasy': [11],
          'Fantasy|Sci-Fi': [11, 18],
          'Film-Noir': [13],
          'Film-Noir|Horror': [13, 8],
          'Film-Noir|Mystery': [13, 2],
          'Film-Noir|Mystery|Thriller': [13, 2, 17],
          'Film-Noir|Romance|Thriller': [13, 3, 17],
          'Film-Noir|Sci-Fi': [13, 18],
          'Film-Noir|Sci-Fi|Thriller': [13, 18, 17],
          'Film-Noir|Thriller': [13, 17],
          'Horror': [8],
          'Horror|Mystery': [8, 2],
          'Horror|Mystery|Thriller': [8, 2, 17],
          'Horror|Romance': [8, 3],
          'Horror|Sci-Fi': [8, 18],
          'Horror|Sci-Fi|Thriller': [8, 18, 17],
          'Horror|Thriller': [8, 17],
          'Musical': [10],
          'Musical|Romance': [10, 3],
          'Musical|Romance|War': [10, 3, 5],
          'Musical|War': [10, 5],
          'Mystery': [2],
          'Mystery|Romance|Thriller': [2, 3, 17],
          'Mystery|Sci-Fi': [2, 18],
          'Mystery|Sci-Fi|Thriller': [2, 18, 17],
          'Mystery|Thriller': [2, 17],
          'Romance': [3],
          'Romance|Thriller': [3, 17],
          'Romance|War': [3, 5],
          'Romance|Western': [3, 7],
          'Sci-Fi': [18],
          'Sci-Fi|Thriller': [18, 17],
          'Sci-Fi|Thriller|War': [18, 17, 5],
          'Sci-Fi|War': [18, 5],
          'Thriller': [17],
          'War': [5],
          'Western': [7]\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{genres\PYZus{}map}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}遍历属性map里的key}
             \PY{k}{for} \PY{n}{cnt} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{max}\PY{p}{(}\PY{n}{genres2int}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{genres\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}针对所有可能出现的属性的数量减去当前属性对应属性便签编码数字数量}
                 \PY{n}{genres\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{genres\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{n}{cnt}\PY{p}{,}\PY{n}{genres2int}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{}在对应key的value的list后面加入相同数量的}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{genres\PYZus{}map}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:} \{'Action': [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Adventure': [9, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Adventure|Animation': [9,
           12,
           15,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Adventure|Animation|Children's|Fantasy": [9,
           12,
           15,
           16,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Animation|Horror|Sci-Fi': [9,
           12,
           15,
           8,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Adventure|Children's": [9,
           12,
           16,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Adventure|Children's|Comedy": [9,
           12,
           16,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Adventure|Children's|Fantasy": [9,
           12,
           16,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Adventure|Children's|Sci-Fi": [9,
           12,
           16,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy': [9,
           12,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy|Crime': [9,
           12,
           1,
           4,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy|Horror': [9,
           12,
           1,
           8,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy|Horror|Sci-Fi': [9,
           12,
           1,
           8,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy|Romance': [9,
           12,
           1,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy|Sci-Fi': [9,
           12,
           1,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Comedy|War': [9,
           12,
           1,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Crime': [9,
           12,
           4,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Crime|Drama': [9,
           12,
           4,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Crime|Thriller': [9,
           12,
           4,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Drama': [9,
           12,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Drama|Romance': [9,
           12,
           6,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Drama|Sci-Fi|War': [9,
           12,
           6,
           18,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Drama|Thriller': [9,
           12,
           6,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Fantasy': [9,
           12,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Fantasy|Sci-Fi': [9,
           12,
           11,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Horror': [9,
           12,
           8,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Horror|Thriller': [9,
           12,
           8,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Mystery': [9,
           12,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Mystery|Sci-Fi': [9,
           12,
           2,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Romance': [9,
           12,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Romance|Sci-Fi|War': [9,
           12,
           3,
           18,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Romance|Thriller': [9,
           12,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Romance|War': [9,
           12,
           3,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Sci-Fi': [9,
           12,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Sci-Fi|Thriller': [9,
           12,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Sci-Fi|Thriller|War': [9,
           12,
           18,
           17,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Sci-Fi|War': [9,
           12,
           18,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Thriller': [9,
           12,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|War': [9,
           12,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Adventure|Western': [9,
           12,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Animation|Children's|Sci-Fi|Thriller|War": [9,
           15,
           16,
           18,
           17,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Action|Children's": [9, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Action|Children's|Fantasy": [9,
           16,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy': [9, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Comedy|Crime': [9, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Comedy|Crime|Drama': [9,
           1,
           4,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Crime|Horror|Thriller': [9,
           1,
           4,
           8,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Drama': [9, 1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Comedy|Fantasy': [9,
           1,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Musical': [9,
           1,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Musical|Sci-Fi': [9,
           1,
           10,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Romance|Thriller': [9,
           1,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Sci-Fi|Thriller': [9,
           1,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|Sci-Fi|War': [9,
           1,
           18,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Comedy|War': [9, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Comedy|Western': [9,
           1,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Crime': [9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Crime|Drama': [9, 4, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Crime|Drama|Thriller': [9,
           4,
           6,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Crime|Mystery': [9,
           4,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Crime|Mystery|Thriller': [9,
           4,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Crime|Romance': [9,
           4,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Crime|Sci-Fi': [9,
           4,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Crime|Thriller': [9,
           4,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama': [9, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Drama|Fantasy|Romance': [9,
           6,
           11,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Mystery': [9,
           6,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Mystery|Romance|Thriller': [9,
           6,
           2,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Romance': [9,
           6,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Romance|Thriller': [9,
           6,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Sci-Fi|Thriller': [9,
           6,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Thriller': [9,
           6,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|Thriller|War': [9,
           6,
           17,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Drama|War': [9, 6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Drama|Western': [9,
           6,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Horror': [9, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Horror|Sci-Fi': [9,
           8,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Horror|Sci-Fi|Thriller': [9,
           8,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Horror|Thriller': [9,
           8,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Mystery|Romance|Thriller': [9,
           2,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Mystery|Sci-Fi|Thriller': [9,
           2,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Mystery|Thriller': [9,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Romance': [9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Romance|Sci-Fi': [9,
           3,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Romance|Thriller': [9,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Romance|War': [9, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Sci-Fi': [9, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Sci-Fi|Thriller': [9,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Sci-Fi|Thriller|War': [9,
           18,
           17,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Sci-Fi|Thriller|Western': [9,
           18,
           17,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Sci-Fi|War': [9, 18, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Sci-Fi|Western': [9,
           18,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|Thriller': [9, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Thriller|War': [9,
           17,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Action|War': [9, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Action|Western': [9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure': [12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Adventure|Animation|Children's": [12,
           15,
           16,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Animation|Children's|Comedy|Fantasy": [12,
           15,
           16,
           1,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Animation|Children's|Comedy|Musical": [12,
           15,
           16,
           1,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Animation|Children's|Fantasy": [12,
           15,
           16,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Animation|Children's|Musical": [12,
           15,
           16,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Animation|Children's|Sci-Fi": [12,
           15,
           16,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Animation|Film-Noir': [12,
           15,
           13,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Animation|Sci-Fi': [12,
           15,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Animation|Sci-Fi|Thriller': [12,
           15,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's": [12,
           16,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Comedy": [12,
           16,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Comedy|Fantasy": [12,
           16,
           1,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Comedy|Fantasy|Romance": [12,
           16,
           1,
           11,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Comedy|Fantasy|Sci-Fi": [12,
           16,
           1,
           11,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Comedy|Musical": [12,
           16,
           1,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Drama": [12,
           16,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Drama|Musical": [12,
           16,
           6,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Drama|Romance": [12,
           16,
           6,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Fantasy": [12,
           16,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Fantasy|Sci-Fi": [12,
           16,
           11,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Musical": [12,
           16,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Romance": [12,
           16,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Adventure|Children's|Sci-Fi": [12,
           16,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Comedy': [12, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Comedy|Drama': [12,
           1,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Comedy|Musical': [12,
           1,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Comedy|Romance': [12,
           1,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Comedy|Sci-Fi': [12,
           1,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Crime|Sci-Fi|Thriller': [12,
           4,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Drama': [12, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Drama|Romance': [12,
           6,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Drama|Romance|Sci-Fi': [12,
           6,
           3,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Drama|Thriller': [12,
           6,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Drama|Western': [12,
           6,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Fantasy': [12, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Fantasy|Romance': [12,
           11,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Fantasy|Sci-Fi': [12,
           11,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Musical': [12, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Musical|Romance': [12,
           10,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Romance': [12, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Romance|Sci-Fi': [12,
           3,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Sci-Fi': [12, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Sci-Fi|Thriller': [12,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|Thriller': [12,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Adventure|War': [12, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Adventure|Western': [12, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Animation': [15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Animation|Children's": [15,
           16,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Comedy": [15,
           16,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Comedy|Musical": [15,
           16,
           1,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Comedy|Musical|Romance": [15,
           16,
           1,
           10,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Comedy|Romance": [15,
           16,
           1,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Drama|Fantasy": [15,
           16,
           6,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Fantasy|Musical": [15,
           16,
           11,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Fantasy|War": [15,
           16,
           11,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Musical": [15,
           16,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Animation|Children's|Musical|Romance": [15,
           16,
           10,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Animation|Comedy': [15, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Animation|Comedy|Thriller': [15,
           1,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Animation|Musical': [15, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Animation|Mystery': [15, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Animation|Sci-Fi': [15, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Children's": [16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Children's|Comedy": [16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Children's|Comedy|Drama": [16,
           1,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Comedy|Fantasy": [16,
           1,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Comedy|Musical": [16,
           1,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Comedy|Mystery": [16,
           1,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Comedy|Sci-Fi": [16,
           1,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Comedy|Western": [16,
           1,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Drama": [16, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Children's|Drama|Fantasy": [16,
           6,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Drama|Fantasy|Sci-Fi": [16,
           6,
           11,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Fantasy": [16,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Fantasy|Musical": [16,
           11,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Fantasy|Sci-Fi": [16,
           11,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Horror": [16, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          "Children's|Musical": [16,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          "Children's|Sci-Fi": [16, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Crime': [1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Crime|Drama': [1, 4, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Crime|Drama|Mystery': [1,
           4,
           6,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Crime|Fantasy': [1,
           4,
           11,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Crime|Horror': [1, 4, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Crime|Mystery|Thriller': [1,
           4,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Crime|Thriller': [1,
           4,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Documentary': [1, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Drama': [1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Drama|Musical': [1,
           6,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Drama|Romance': [1,
           6,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Drama|Sci-Fi': [1,
           6,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Drama|Thriller': [1,
           6,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Drama|War': [1, 6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Drama|Western': [1,
           6,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Fantasy': [1, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Fantasy|Romance': [1,
           11,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Fantasy|Romance|Sci-Fi': [1,
           11,
           3,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Film-Noir|Thriller': [1,
           13,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Horror': [1, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Horror|Musical': [1,
           8,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Horror|Musical|Sci-Fi': [1,
           8,
           10,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Horror|Sci-Fi': [1,
           8,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Horror|Thriller': [1,
           8,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Musical': [1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Musical|Romance': [1,
           10,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Mystery': [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Mystery|Romance': [1,
           2,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Mystery|Romance|Thriller': [1,
           2,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Mystery|Thriller': [1,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Romance': [1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Romance|Sci-Fi': [1,
           3,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Romance|Thriller': [1,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Romance|War': [1, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Sci-Fi': [1, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Sci-Fi|Western': [1,
           18,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Comedy|Thriller': [1, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|War': [1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Comedy|Western': [1, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime': [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Drama': [4, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Drama|Film-Noir': [4,
           6,
           13,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Drama|Film-Noir|Thriller': [4,
           6,
           13,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Drama|Mystery': [4, 6, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Drama|Mystery|Thriller': [4,
           6,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Drama|Romance': [4, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Drama|Romance|Thriller': [4,
           6,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Drama|Sci-Fi': [4, 6, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Drama|Thriller': [4,
           6,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Film-Noir': [4, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Film-Noir|Mystery': [4,
           13,
           2,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Film-Noir|Mystery|Thriller': [4,
           13,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Film-Noir|Thriller': [4,
           13,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Horror': [4, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Horror|Mystery|Thriller': [4,
           8,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Horror|Thriller': [4,
           8,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Crime|Mystery': [4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Crime|Thriller': [4, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Documentary': [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Documentary|Drama': [14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Documentary|Musical': [14,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Documentary|War': [14, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama': [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Fantasy': [6, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Fantasy|Romance|Thriller': [6,
           11,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Film-Noir': [6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Film-Noir|Thriller': [6,
           13,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Horror': [6, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Horror|Thriller': [6,
           8,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Musical': [6, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Musical|War': [6, 10, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Mystery': [6, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Mystery|Romance': [6,
           2,
           3,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Mystery|Sci-Fi|Thriller': [6,
           2,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Mystery|Thriller': [6,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Romance': [6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Romance|Sci-Fi': [6,
           3,
           18,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Romance|Thriller': [6,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Romance|War': [6, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Romance|War|Western': [6,
           3,
           5,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Romance|Western': [6,
           3,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Sci-Fi': [6, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Sci-Fi|Thriller': [6,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Drama|Thriller': [6, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Thriller|War': [6, 17, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|War': [6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Drama|Western': [6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Fantasy': [11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Fantasy|Sci-Fi': [11, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Film-Noir': [13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Film-Noir|Horror': [13, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Film-Noir|Mystery': [13, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Film-Noir|Mystery|Thriller': [13,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Film-Noir|Romance|Thriller': [13,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Film-Noir|Sci-Fi': [13, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Film-Noir|Sci-Fi|Thriller': [13,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Film-Noir|Thriller': [13,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Horror': [8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Horror|Mystery': [8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Horror|Mystery|Thriller': [8,
           2,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Horror|Romance': [8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Horror|Sci-Fi': [8, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Horror|Sci-Fi|Thriller': [8,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Horror|Thriller': [8, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Musical': [10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Musical|Romance': [10, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Musical|Romance|War': [10,
           3,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Musical|War': [10, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Mystery': [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Mystery|Romance|Thriller': [2,
           3,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Mystery|Sci-Fi': [2, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Mystery|Sci-Fi|Thriller': [2,
           18,
           17,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Mystery|Thriller': [2, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Romance': [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Romance|Thriller': [3, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Romance|War': [3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Romance|Western': [3, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Sci-Fi': [18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Sci-Fi|Thriller': [18, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Sci-Fi|Thriller|War': [18,
           17,
           5,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0],
          'Sci-Fi|War': [18, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Thriller': [17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'War': [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
          'Western': [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{genres\PYZus{}map}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{movies}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:}    MovieID                         Title  \textbackslash{}
         0        1                    Toy Story    
         1        2                      Jumanji    
         2        3             Grumpier Old Men    
         3        4            Waiting to Exhale    
         4        5  Father of the Bride Part II    
         
                                                       Genres  
         0  [15, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}  
         1  [12, 16, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         2  [1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         3  [1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
\end{Verbatim}
            
    \textbf{电影Title转数字字典}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{title\PYZus{}set} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
         \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{n}{title\PYZus{}set}\PY{o}{.}\PY{n}{update}\PY{p}{(}\PY{n}{val}\PY{p}{)}
         
         \PY{n}{title\PYZus{}list} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{title\PYZus{}set}\PY{p}{)}
         \PY{n}{title\PYZus{}list}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{title2int} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{ii} \PY{k}{for} \PY{n}{ii}\PY{p}{,} \PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{title\PYZus{}list}\PY{p}{)}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{}总计可能出现的单词有}
         \PY{n+nb}{len}\PY{p}{(}\PY{n}{title2int}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}16}]:} 5215
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{}将电影Title转成等长数字列表，长度是15}
         \PY{n}{title\PYZus{}count} \PY{o}{=} \PY{l+m+mi}{15}
         \PY{n}{title\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{p}{[}\PY{n}{title2int}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{val}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
         \PY{c+c1}{\PYZsh{}title2int为文字转int对应字典}
         \PY{c+c1}{\PYZsh{}对应标题内val ，val变体对应字典}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{title\PYZus{}map}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} \{'King of Masks, The (Bian Lian) ': [712, 1187, 1146, 4721, 1547, 1878],
          'American Strays ': [646, 1490],
          "Autumn Tale, An (Conte d'automne) ": [125, 4292, 2491, 2285, 1048],
          'Light It Up ': [715, 1226, 2149],
          'Brokedown Palace ': [2269, 1137],
          'Tales from the Hood ': [3410, 660, 4975, 35],
          'Auntie Mame ': [3553, 5124],
          'Nurse Betty ': [2266, 4218],
          'Transformers: The Movie, The ': [3204, 4721, 2917, 4721],
          'Castle, The ': [3244, 4721],
          'Rosewood ': [4169],
          'Kazaam ': [623],
          'Morning After, The ': [294, 3997, 4721],
          'South Park: Bigger, Longer and Uncut ': [4895, 1267, 3706, 3638, 3119, 4616],
          'Oliver! ': [501],
          'Blue in the Face ': [1481, 1417, 4975, 3690],
          'Giant ': [1917],
          'People vs. Larry Flynt, The ': [1892, 2950, 887, 656, 4721],
          'Bronco Billy ': [611, 3197],
          "Amityville 1992: It's About Time ": [1206, 3960, 116, 503, 5164],
          'Free Willy ': [440, 2075],
          'Asfour Stah ': [4841, 2861],
          'Elstree Calling ': [4761, 1747],
          'Drop Dead Fred ': [4379, 325, 3998],
          "Krippendorf's Tribe ": [2630, 2915],
          'Slumber Party Massacre II, The ': [4650, 3915, 4343, 3597, 4721],
          'What About Bob? ': [2753, 503, 1759],
          'eXistenZ ': [2922],
          'Stefano Quantestorie ': [1214, 2460],
          'Stop! Or My Mom Will Shoot ': [2195, 2162, 2526, 4560, 5131, 836],
          'Dorado, El ': [3472, 2546],
          'Cold Fever (� k鰈dum klaka) ': [407, 1430, 2355, 967, 5195],
          'Permanent Midnight ': [592, 1729],
          'Lay of the Land, The ': [322, 1187, 4975, 3931, 4721],
          'Welcome to Woop-Woop ': [4635, 4070, 2573],
          'Super Mario Bros. ': [639, 5093, 4266],
          'Demolition Man ': [3782, 4433],
          '7th Voyage of Sinbad, The ': [4682, 192, 1187, 3756, 4721],
          'Bear, The ': [4768, 4721],
          'NeverEnding Story II: The Next Chapter, The ': [1557,
           3945,
           333,
           4721,
           5037,
           819,
           4721],
          'Time of the Gypsies (Dom za vesanje) ': [5164,
           1187,
           4975,
           4669,
           495,
           2831,
           2241],
          'Swing Kids ': [4661, 2957],
          'In \& Out ': [3786, 2580, 2625],
          'Small Wonders ': [2298, 4806],
          "I'm Not Rappaport ": [2291, 1502, 5081],
          'Inherit the Wind ': [3869, 4975, 1538],
          'War Stories ': [1632, 2406],
          'Adventures of Rocky and Bullwinkle, The ': [5036,
           1187,
           410,
           3119,
           2786,
           4721],
          'Mrs. Parker and the Vicious Circle ': [5140, 3171, 3119, 4975, 5204, 1612],
          'Quarry, The ': [1073, 4721],
          'All Over Me ': [3739, 2651, 605],
          'Harmonists, The ': [663, 4721],
          'Devil Rides Out, The ': [2159, 857, 3722, 4721],
          'Passion of Mind ': [73, 1187, 3656],
          'Trixie ': [4201],
          'Angel on My Shoulder ': [1891, 3538, 2526, 4026],
          'Shining, The ': [1297, 4721],
          'Falling in Love Again ': [2176, 1417, 3179, 2517],
          'Nemesis 2: Nebula ': [2518, 5120, 525],
          '20 Dates ': [2973, 1383],
          'This World, Then the Fireworks ': [4224, 1144, 695, 4975, 4234],
          'Slipper and the Rose, The ': [1608, 3119, 4975, 2008, 4721],
          'Walking and Talking ': [2127, 3119, 4187],
          'Return to Paradise ': [2660, 4070, 3133],
          'Exotica ': [4604],
          'Player, The ': [2655, 4721],
          'Flubber ': [370],
          'D2: The Mighty Ducks ': [2955, 4721, 4556, 3031],
          'Menace II Society ': [1725, 4155, 2272],
          'Legal Deceit ': [621, 818],
          'Indiana Jones and the Temple of Doom ': [2284,
           2642,
           3119,
           4975,
           588,
           1187,
           3818],
          'Devil and Max Devlin, The ': [2159, 3119, 2715, 3874, 4721],
          'Not One Less (Yi ge dou bu neng shao) ': [1502,
           300,
           4997,
           2458,
           1540,
           3698,
           1816,
           687,
           4723],
          'Breakfast of Champions ': [820, 1187, 738],
          'Heat ': [3284],
          'Batman ': [4130],
          'Amistad ': [2116],
          'Unstrung Heroes ': [2854, 3150],
          'Endless Summer, The ': [3792, 3297, 4721],
          'Return of Martin Guerre, The (Retour de Martin Guerre, Le) ': [2660,
           1187,
           1185,
           4401,
           4721,
           4845,
           4117,
           1185,
           4401,
           1979],
          'Way of the Gun, The ': [856, 1187, 4975, 2898, 4721],
          'Brandon Teena Story, The ': [3302, 563, 1077, 4721],
          'Keeping the Faith ': [2076, 4975, 4194],
          'Little Buddha ': [2254, 4964],
          'Misery ': [4175],
          'L.A. Confidential ': [3135, 3829],
          'Last Time I Saw Paris, The ': [3933, 5164, 921, 4846, 2087, 4721],
          'American Werewolf in Paris, An ': [646, 490, 1417, 2087, 2491],
          'Grease 2 ': [4630, 1708],
          'Steal This Movie! ': [2107, 4224, 3041],
          'Hangmen Also Die ': [2694, 1112, 2496],
          'Police Academy 5: Assignment: Miami Beach ': [3901,
           1970,
           730,
           4868,
           778,
           2216],
          'Rude ': [871],
          'Footloose ': [3022],
          'Kagemusha ': [4374],
          'Species ': [1075],
          'Pi ': [3919],
          'Decline of Western Civilization Part II: The Metal Years, The ': [2228,
           1187,
           1321,
           2962,
           1880,
           333,
           4721,
           1278,
           3164,
           4721],
          'Fierce Creatures ': [3226, 3840],
          'Never Been Kissed ': [4370, 3631, 3495],
          'Down in the Delta ': [3761, 1417, 4975, 4359],
          'Gothic ': [3747],
          'Lamerica ': [706],
          'Candyman ': [2678],
          'Doctor Dolittle ': [649, 858],
          'Henry Fool ': [4273, 4576],
          'Pocahontas ': [4941],
          'Mina Tannenbaum ': [1046, 5020],
          'Hand That Rocks the Cradle, The ': [2358, 4071, 1411, 4975, 2788, 4721],
          'Myth of Fingerprints, The ': [3273, 1187, 1436, 4721],
          'Son of Dracula ': [2271, 1187, 4689],
          'Thin Line Between Love and Hate, A ': [4610,
           3938,
           4923,
           3179,
           3119,
           4605,
           4328],
          'Wild Wild West ': [571, 571, 972],
          'Shadow, The ': [5044, 4721],
          'Shooting Fish ': [3751, 1809],
          'Bad Taste ': [4319, 346],
          'Horseman on the Roof, The (Hussard sur le toit, Le) ': [1918,
           3538,
           4975,
           1195,
           4721,
           3517,
           4376,
           1773,
           1634,
           1979],
          'X-Files: Fight the Future, The ': [1814, 84, 4975, 883, 4721],
          'Avengers, The ': [242, 4721],
          'Titan A.E. ': [872, 3354],
          'Three Colors: Red ': [627, 3474, 4769],
          'Hunt for Red October, The ': [2297, 1318, 4769, 2615, 4721],
          'End of the Affair, The ': [2509, 1187, 4975, 1284, 4721],
          'Promise, The (La Promesse) ': [1471, 4721, 368, 729],
          'Brothers in Trouble ': [4249, 1417, 1364],
          'Carnosaur ': [1219],
          'Invisible Man, The ': [3555, 3014, 4721],
          'Gone with the Wind ': [5045, 1987, 4975, 1538],
          'Hanging Up ': [4656, 2149],
          "Rich Man's Wife, The ": [2836, 1777, 2322, 4721],
          'Birdcage, The ': [5192, 4721],
          'High Art ': [3595, 4142],
          'Aladdin and the King of Thieves ': [2132, 3119, 4975, 712, 1187, 906],
          'Female Perversions ': [5108, 1974],
          'And the Ship Sails On (E la nave va) ': [3644,
           4975,
           3358,
           3535,
           3236,
           1413,
           1125,
           5207,
           1679],
          'African Queen, The ': [2481, 2934, 4721],
          'Mask, The ': [213, 4721],
          'Next Friday ': [5037, 1426],
          'Perils of Pauline, The ': [1674, 1187, 813, 4721],
          'Son of Frankenstein ': [2271, 1187, 1109],
          'Trick or Treat ': [3445, 3115, 1819],
          "Midsummer Night's Dream, A ": [3097, 3355, 4410, 4328],
          'Cool Hand Luke ': [1598, 2358, 3411],
          'Stop Making Sense ': [1456, 4043, 310],
          'Dangerous Liaisons ': [1468, 1659],
          'Strawberry and Chocolate (Fresa y chocolate) ': [4540,
           3119,
           617,
           683,
           3483,
           1157],
          "She's So Lovely ": [2128, 5052, 1236],
          "What's Eating Gilbert Grape ": [4501, 1178, 1406, 5129],
          'Abyss, The ': [2230, 4721],
          'Brassed Off ': [4966, 427],
          'Hilary and Jackie ': [742, 3119, 390],
          'Taste of Cherry ': [346, 1187, 3810],
          'Palookaville ': [3674],
          'Virgin Suicides, The ': [277, 303, 4721],
          'Nina Takes a Lover ': [2485, 5087, 3808, 2262],
          'U Turn ': [3927, 3075],
          'Two Jakes, The ': [3340, 3218, 4721],
          'Naked Gun: From the Files of Police Squad!, The ': [1076,
           4358,
           4177,
           4975,
           3699,
           1187,
           3901,
           2174,
           4721],
          'Blink ': [2229],
          'Good Will Hunting ': [764, 5131, 2669],
          'Night of the Comet ': [2814, 1187, 4975, 2370],
          'Parenthood ': [209],
          'Scout, The ': [4639, 4721],
          "Those Who Love Me Can Take the Train (Ceux qui m'aiment prendront le train) ": [3662,
           1289,
           3179,
           605,
           1045,
           269,
           4975,
           4145,
           3776,
           2933,
           305,
           2784,
           1773,
           1390],
          "Eye of Vichy, The (Oeil de Vichy, L') ": [899,
           1187,
           3166,
           4721,
           1197,
           4117,
           3166,
           2181],
          'Sarafina! ': [385],
          'He Walked by Night ': [3887, 4970, 4667, 2814],
          'It Came from Outer Space ': [1226, 4706, 660, 4936, 1240],
          'Two Family House ': [3340, 1166, 3228],
          'Jonah Who Will Be 25 in the Year 2000 ': [3212,
           1289,
           5131,
           4392,
           1621,
           1417,
           4975,
           1449,
           5135],
          'Dirty Dozen, The ': [3013, 493, 4721],
          'Double Team ': [1861, 648],
          'Ring, The ': [389, 4721],
          'Hot Shots! Part Deux ': [3846, 1420, 1880, 5041],
          'Harriet the Spy ': [2587, 4975, 4709],
          'Dead Man Walking ': [325, 4433, 2127],
          'Who Framed Roger Rabbit? ': [1289, 933, 2826, 2991],
          'From the Journals of Jean Seberg ': [4177, 4975, 3806, 1187, 2823, 3156],
          'In Search of the Castaways ': [3786, 873, 1187, 4975, 4457],
          'Office Space ': [3102, 1240],
          'New Rose Hotel ': [4843, 2739, 851],
          'Low Down Dirty Shame, A ': [3628, 3761, 3013, 1438, 4328],
          "All the King's Men ": [3739, 4975, 5154, 2964],
          'Howards End ': [3471, 2509],
          'Bastard Out of Carolina ': [4775, 2625, 1187, 5],
          'Brazil ': [1180],
          'Penny Serenade ': [4826, 2828],
          'Meatballs Part II ': [741, 1880, 4155],
          'Fatal Attraction ': [1768, 2682],
          'Gumby: The Movie ': [2294, 4721, 2356],
          'Kiss Me, Guido ': [3700, 3455, 1272],
          'Angel Baby ': [1891, 3580],
          'Blade ': [520],
          'Twisted ': [4123],
          'Maximum Risk ': [3561, 2003],
          'Anna ': [3048],
          'Galaxy Quest ': [2600, 336],
          'Siege, The ': [753, 4721],
          'Last Temptation of Christ, The ': [3933, 4502, 1187, 147, 4721],
          "Citizen's Band (a.k.a. Handle with Care) ": [3709,
           2589,
           90,
           2622,
           1987,
           445],
          'With Honors ': [951, 1524],
          'To Sir with Love ': [885, 2732, 1987, 3179],
          'Gate II: Trespassers, The ': [1215, 333, 3606, 4721],
          'Drunken Master (Zui quan) ': [4077, 2140, 2578, 4354],
          'Ed Wood ': [1320, 2892],
          'Gnome-Mobile, The ': [1095, 4721],
          'Affliction ': [1688],
          'Identification of a Woman (Identificazione di una donna) ': [205,
           1187,
           3808,
           1583,
           1491,
           363,
           2165,
           4391],
          'Robocop ': [876],
          'Horror Express ': [3198, 5160],
          'Velvet Goldmine ': [259, 3286],
          'Great Day in Harlem, A ': [4428, 4286, 1417, 4186, 4328],
          'Soldier ': [57],
          'Room with a View, A ': [4373, 1987, 3808, 4127, 4328],
          'Children of Heaven, The (Bacheha-Ye Aseman) ': [923,
           1187,
           2429,
           4721,
           3345,
           4083],
          'They Bite ': [3797, 388],
          'Purple Noon ': [2046, 3525],
          'Nineteen Eighty-Four ': [5072, 597],
          'Cinema Paradiso ': [1063, 3025],
          'Tall Tale ': [2713, 4079],
          'On Golden Pond ': [3236, 3581, 1279],
          'Postman Always Rings Twice, The ': [1143, 2545, 276, 1654, 4721],
          'Next Karate Kid, The ': [5037, 1078, 4414, 4721],
          'Cat Ballou ': [866, 927],
          'Family Thing, A ': [1166, 2741, 4328],
          'Starship Troopers ': [383, 4037],
          'Paris Was a Woman ': [2279, 1909, 3808, 1583],
          'Apple Dumpling Gang, The ': [2867, 356, 335, 4721],
          'Army of Darkness ': [3444, 1187, 4489],
          'Cutting Edge, The ': [4927, 1107, 4721],
          'Willy Wonka and the Chocolate Factory ': [2075, 3737, 3119, 4975, 617, 3475],
          "Child's Play ": [3046, 3899],
          'Clue ': [4600],
          'Little Women ': [2254, 992],
          'Brother from Another Planet, The ': [1622, 660, 4237, 4369, 4721],
          'Winter Guest, The ': [2527, 4545, 4721],
          'Mystery Men ': [1720, 2964],
          'Sinbad and the Eye of the Tiger ': [4947, 3119, 4975, 899, 1187, 4975, 879],
          'Time Regained (Le Temps Retrouv�) ': [5164, 4176, 628, 4072, 1596],
          'Out-of-Towners, The ': [2756, 4721],
          'Lady Vanishes, The ': [4281, 4598, 4721],
          'Pink Flamingos ': [4978, 3188],
          'Wolf Man, The ': [1139, 3014, 4721],
          'Ride ': [1758],
          'Gods and Monsters ': [4045, 3119, 4707],
          'Amityville Horror, The ': [1206, 3673, 4721],
          'Lured ': [583],
          'Better Living ': [1346, 920],
          'Full Speed ': [282, 1343],
          'Frank and Ollie ': [4404, 3119, 2850],
          'Barefoot in the Park ': [4787, 1417, 4975, 4861],
          'Leather Jacket Love Story ': [2591, 2797, 3179, 3945],
          'Best Man, The (Il Testimone dello sposo) ': [5105,
           3014,
           4721,
           3996,
           4910,
           4558,
           1953],
          'All the Vermeers in New York ': [3739, 4975, 636, 1417, 4843, 4348],
          'Jagged Edge ': [1802, 3393],
          'Hidden, The ': [1609, 4721],
          'Entertaining Angels: The Dorothy Day Story ': [2638,
           614,
           4721,
           3435,
           4286,
           3945],
          'Adventures in Babysitting ': [5036, 1417, 3619],
          'Blood \& Wine ': [3743, 2580, 4456],
          "Mummy's Hand, The ": [1301, 2522, 4721],
          'Ladybird Ladybird ': [1665, 1665],
          'Shane ': [2238],
          'Playing God ': [672, 4132],
          'Client, The ': [4033, 4721],
          'Odessa File, The ': [4310, 3772, 4721],
          'Life with Mikey ': [4528, 1987, 3948],
          'Toy Story 2 ': [2121, 3945, 1708],
          'Air Bud: Golden Receiver ': [1559, 2096, 3581, 4884],
          'Criminal Lovers (Les Amants Criminels) ': [4837, 3837, 4365, 4233, 2416],
          'No Small Affair ': [41, 2298, 4893],
          'Anna Karenina ': [3048, 4652],
          'Rocky IV ': [410, 3326],
          'Moonstruck ': [4046],
          'Good Earth, The ': [764, 3824, 4721],
          'Gremlins ': [1492],
          'Halloween III: Season of the Witch ': [3635, 3039, 4530, 1187, 4975, 3630],
          'Children of the Damned ': [923, 1187, 4975, 4805],
          'Taxman ': [4601],
          'Far and Away ': [4860, 3119, 2838],
          'Bean ': [3986],
          'They Made Me a Criminal ': [3797, 2331, 605, 3808, 4837],
          'Falcon and the Snowman, The ': [776, 3119, 4975, 4409, 4721],
          'Vagabond (Sans toit ni loi) ': [1295, 4631, 680, 2999, 3925],
          'Easy Virtue ': [1414, 1552],
          'Opposite of Sex, The ': [5101, 1187, 1713, 4721],
          'Last September, The ': [3933, 2145, 4721],
          'Indochine ': [2808],
          'Chairman of the Board ': [1939, 1187, 4975, 2],
          "Gentleman's Agreement ": [4363, 1967],
          'Pok閙on: The First Movie ': [2111, 4721, 1743, 2356],
          'Gabbeh ': [2199],
          'Liebelei ': [4183],
          'Karate Kid III, The ': [1078, 4629, 4180, 4721],
          'Apostle, The ': [838, 4721],
          'Five Senses, The ': [2557, 651, 4721],
          'Tommy ': [3099],
          'Simpatico ': [488],
          'Wag the Dog ': [1728, 4975, 4942],
          'Cotton Mary ': [3034, 2089],
          'Outlaw Josey Wales, The ': [2884, 1794, 1817, 4721],
          'Striking Distance ': [2293, 4],
          'Condo Painting ': [2316, 200],
          'And God Created Woman ': [3644, 4132, 4928, 1583],
          'Hav Plenty ': [3279, 539],
          "Kid in King Arthur's Court, A ": [4629, 1417, 712, 3754, 3290, 4328],
          'Amos \& Andrew ': [5162, 2580, 3120],
          'That Old Feeling ': [4071, 1233, 4524],
          'M*A*S*H ': [1281],
          'Golden Earrings ': [3581, 3487],
          'Twice Upon a Yesterday ': [949, 4749, 3808, 2865],
          'Further Gesture, A ': [338, 1733, 4328],
          'Seven (Se7en) ': [2901, 3848],
          "Pharaoh's Army ": [4588, 3444],
          "Killer's Kiss ": [1008, 3700],
          'Shadow of Angels (Schatten der Engel) ': [1163, 1187, 278, 773, 4152, 763],
          'Walkabout ': [146],
          'One True Thing ': [300, 1489, 610],
          'Blues Brothers, The ': [494, 4491, 4721],
          'Amityville Curse, The ': [1206, 4776, 4721],
          'Mirror Has Two Faces, The ': [20, 4581, 3340, 2996, 4721],
          'Ideal Husband, An ': [5015, 3500, 2491],
          'Prick Up Your Ears ': [1501, 2149, 4090, 4014],
          "She's All That ": [2128, 3739, 4071],
          'Clubland ': [2963],
          'Slums of Beverly Hills, The ': [1755, 1187, 2288, 1121, 4721],
          'Tokyo Fist ': [3658, 460],
          'Dick ': [1820],
          'Dudley Do-Right ': [2403, 1110],
          'Knockout ': [1784],
          'Happy Go Lovely ': [4190, 5210, 1236],
          'River Runs Through It, A ': [5122, 4078, 4002, 2410, 4328],
          'Once Upon a Time in America ': [2184, 4749, 3808, 5164, 1417, 4577],
          'Killer (Bulletproof Heart) ': [1705, 4067, 2960],
          'Captives ': [432],
          'Oscar and Lucinda (a.k.a. Oscar \& Lucinda) ': [1526,
           3119,
           4517,
           90,
           1526,
           2580,
           2896],
          'Saving Grace ': [3609, 3844],
          'Close Shave, A ': [701, 941, 4328],
          'Watership Down ': [3991, 3761],
          'Browning Version, The ': [4316, 4646, 4721],
          'Conformist, The (Il Conformista) ': [2351, 4721, 3996, 2346],
          'Goya in Bordeaux (Goya en Bodeos) ': [5187, 1417, 4594, 1912, 136, 1991],
          'Fear and Loathing in Las Vegas ': [3944, 3119, 2503, 1417, 1299, 3098],
          'Hamlet ': [4950],
          'Inspector Gadget ': [227, 3984],
          'Batman: Mask of the Phantasm ': [3392, 2180, 1187, 4975, 2735],
          'Meatballs ': [741],
          'Caddyshack ': [3832],
          'Boy Called Hate, A ': [3427, 4870, 4605, 4328],
          'Hugo Pool ': [1081, 4191],
          'Arguing the World ': [2446, 4975, 4091],
          'Rules of Engagement ': [3350, 1187, 4881],
          'Secret Garden, The ': [10, 1772, 4721],
          'Little Lord Fauntleroy ': [2254, 4161, 2014],
          'Illuminata ': [512],
          'Circle of Friends ': [1612, 1187, 4163],
          'Dead Again ': [325, 2517],
          'Happy, Texas ': [246, 3109],
          'Yojimbo ': [913],
          'Emperor and the Assassin, The (Jing ke ci qin wang) ': [330,
           3119,
           4975,
           3402,
           4721,
           3073,
           847,
           2189,
           3890,
           4866],
          'Batman Returns ': [4130, 4935],
          'Death in Brunswick ': [71, 1417, 3408],
          'Story of Us, The ': [3945, 1187, 2893, 4721],
          'Rambo III ': [2606, 2494],
          'Young Frankenstein ': [2137, 1109],
          'Eden ': [5094],
          'Silence of the Lambs, The ': [3122, 1187, 4975, 794, 4721],
          "Blood For Dracula (Andy Warhol's Dracula) ": [3743,
           2244,
           4689,
           2418,
           653,
           4293],
          "Lilian's Story ": [4780, 3945],
          'Do the Right Thing ': [2537, 4975, 2997, 610],
          'Saturn 3 ': [2790, 350],
          'Friday the 13th ': [1426, 4975, 986],
          "Mummy's Curse, The ": [1301, 4776, 4721],
          'Broadway Damage ': [536, 499],
          'Scarlet Letter, The ': [210, 5085, 4721],
          'Effect of Gamma Rays on Man-in-the-Moon Marigolds, The ': [4380,
           1187,
           2560,
           1564,
           3538,
           697,
           4099,
           4721],
          'Judge Dredd ': [4303, 5148],
          'Stand and Deliver ': [2374, 3119, 99],
          'Mamma Roma ': [2135, 2026],
          'Three Kings ': [627, 1629],
          'Ruthless People ': [1965, 1892],
          'Ruling Class, The ': [169, 3634, 4721],
          'Replacements, The ': [4757, 4721],
          'Sheltering Sky, The ': [4102, 1056, 4721],
          'Vacation ': [928],
          'Frighteners, The ': [929, 4721],
          'From Russia with Love ': [4177, 1673, 1987, 3179],
          'Any Number Can Win (M閘odie en sous-sol ) ': [4149,
           392,
           1045,
           1315,
           3600,
           136,
           4137,
           1838],
          'His Girl Friday ': [2010, 987, 1426],
          'Marked for Death ': [4786, 1318, 71],
          'Little Indian, Big City (Un indien dans la ville) ': [2254,
           2456,
           1256,
           157,
           413,
           1475,
           3144,
           1125,
           4013],
          'Beneath the Planet of the Apes ': [4297, 4975, 3853, 1187, 4975, 4296],
          'Hype! ': [1421],
          'Stanley \& Iris ': [3292, 2580, 2131],
          'Nighthawks ': [4859],
          'Fatal Instinct ': [1768, 2876],
          'In Crowd, The ': [3786, 955, 4721],
          'Gone in 60 Seconds ': [5045, 1417, 2115, 4738],
          'Inheritors, The (Die Siebtelbauern) ': [713, 4721, 1675, 925],
          'Vertigo ': [1058],
          'Labyrinth ': [3971],
          'Tender Mercies ': [3501, 4283],
          'Gossip ': [1657],
          'All Dogs Go to Heaven 2 ': [3739, 4508, 5210, 4070, 4506, 1708],
          'Barefoot Executive, The ': [4787, 2562, 4721],
          'Sesame Street Presents Follow That Bird ': [1867,
           1347,
           4958,
           3066,
           4071,
           2925],
          'Sticky Fingers of Time, The ': [59, 2905, 1187, 723, 4721],
          'Bullets Over Broadway ': [94, 2651, 536],
          'Raiders of the Lost Ark ': [3214, 1187, 4975, 3857, 537],
          'Natural Born Killers ': [1282, 4347, 95],
          'Long Goodbye, The ': [3719, 1294, 4721],
          'Executive Decision ': [1984, 3878],
          'Late August, Early September (Fin ao鹴, d閎ut septembre) ': [1386,
           1230,
           5201,
           4418,
           4609,
           3134,
           1582,
           4888],
          'Wirey Spindell ': [3524, 1851],
          'Tie That Binds, The ': [3433, 4071, 4907, 4721],
          'Pump Up the Volume ': [3011, 2149, 4975, 4093],
          'Daughters of the Dust ': [341, 1187, 4975, 232],
          'Ten Benny ': [3054, 5034],
          'Beyond Rangoon ': [1648, 1369],
          'Hoosiers ': [954],
          'Dangerous Ground ': [1468, 4716],
          'Aliens ': [531],
          'Jails, Hospitals \& Hip-Hop ': [3745, 4561, 2580, 4103],
          'Sleeping Beauty ': [235, 466],
          'Love Serenade ': [3179, 2828],
          'Living Out Loud ': [920, 2625, 1992],
          'Minnie and Moskowitz ': [4492, 3119, 3856],
          'Pink Floyd - The Wall ': [4978, 133, 3253, 4721, 4040],
          "Some Mother's Son ": [3322, 2224, 2271],
          'Tex ': [2200],
          'Sanjuro ': [3859],
          'Liberty Heights ': [4408, 793],
          'Bye-Bye ': [4238],
          'Winnie the Pooh and the Blustery Day ': [3254,
           4975,
           3520,
           3119,
           4975,
           2479,
           4286],
          'Steel ': [3090],
          "It's My Party ": [116, 2526, 3915],
          'Net, The ': [4096, 4721],
          'Late Bloomers ': [1386, 4592],
          'Shadow of a Doubt ': [1163, 1187, 3808, 1312],
          'N閚ette et Boni ': [626, 783, 4627],
          'Mariachi, El ': [1433, 2546],
          'Flower of My Secret, The (La Flor de Mi Secreto) ': [2258,
           1187,
           2526,
           367,
           4721,
           368,
           542,
           4117,
           4272,
           4948],
          'Crimes of the Heart ': [4705, 1187, 4975, 1569],
          'Savage Nights (Nuits fauves, Les) ': [2975, 2639, 3906, 4905, 1427],
          'Jude ': [2278],
          'Four Weddings and a Funeral ': [2675, 1119, 3119, 3808, 3809],
          'Dancer in the Dark ': [2049, 1417, 4975, 3693],
          'Superman IV: The Quest for Peace ': [4217, 2085, 4721, 336, 1318, 912],
          'Time Code ': [5164, 3451],
          "Pyromaniac's Love Story, A ": [968, 3179, 1077, 4328],
          'Smoke Signals ': [3964, 5104],
          'Guantanamera ': [3477],
          'Sliding Doors ': [4813, 93],
          'Joe the King ': [3594, 4975, 712],
          'Dunston Checks In ': [4832, 4603, 3786],
          'Lawnmower Man, The ': [4743, 3014, 4721],
          'Phantom of the Opera, The ': [4937, 1187, 4975, 2599, 4721],
          'Little Rascals, The ': [2254, 562, 4721],
          'Toy Story ': [2121, 3945],
          'Of Mice and Men ': [162, 4402, 3119, 2964],
          'Day the Sun Turned Cold, The (Tianguo niezi) ': [4286,
           4975,
           785,
           573,
           115,
           4721,
           357,
           4074],
          'Poltergeist II: The Other Side ': [3143, 333, 4721, 2801, 2762],
          'Twin Falls Idaho ': [4552, 4420, 4678],
          'Mass Transit ': [1102, 601],
          'Fletch ': [3371],
          'Happy Weekend ': [4190, 652],
          'Golden Bowl, The ': [3581, 1388, 4721],
          'Fish Called Wanda, A ': [1809, 4870, 4437, 4328],
          'Nothing But Trouble ': [2467, 3425, 1364],
          'Saludos Amigos ': [3593, 602],
          'Play it to the Bone ': [3899, 4244, 4070, 4975, 1004],
          "Bug's Life, A ": [688, 2048, 4328],
          'Talk of Angels ': [4443, 1187, 278],
          'Teenage Mutant Ninja Turtles ': [3804, 481, 2789, 4867],
          'Burglar ': [5172],
          'Love Affair ': [3179, 4893],
          'Kiss of Death ': [3700, 1187, 71],
          'Eat Drink Man Woman ': [2663, 221, 4433, 1583],
          'Small Faces ': [2298, 1307],
          'Anywhere But Here ': [4793, 3425, 2203],
          'Daylight ': [2534],
          'Dangerous Game ': [1468, 3047],
          'Star Trek: The Wrath of Khan ': [1597, 864, 4721, 5145, 1187, 834],
          'Sweet and Lowdown ': [4128, 3119, 408],
          'Ballad of Narayama, The (Narayama Bushiko) ': [295,
           1187,
           4852,
           4721,
           1037,
           842],
          'Star Wars: Episode V - The Empire Strikes Back ': [1597,
           1376,
           2080,
           319,
           3253,
           4721,
           3534,
           3871,
           3414],
          'Being Human ': [194, 2992],
          'Space Cowboys ': [1240, 1486],
          'Jewel of the Nile, The ': [1213, 1187, 4975, 4381, 4721],
          'Other Sister, The ': [2801, 263, 4721],
          'Mr. Smith Goes to Washington ': [4908, 3886, 3805, 4070, 5065],
          'Smoke ': [3964],
          'Black and White ': [552, 3119, 2404],
          'Sunset Blvd. (a.k.a. Sunset Boulevard) ': [1238, 1460, 90, 1238, 312],
          'Baby, The ': [3235, 4721],
          'Interiors ': [2432],
          "Brother's Kiss, A ": [985, 948, 4328],
          'Sleepaway Camp ': [1224, 3283],
          'Great Mouse Detective, The ': [4428, 2971, 4197, 4721],
          'Jeffrey ': [5199],
          'For Love of the Game ': [2244, 3179, 1187, 4975, 3047],
          'Hackers ': [5111],
          'Magnolia ': [1893],
          'Red Dwarf, The (Le Nain rouge) ': [4769, 1833, 4721, 628, 2755, 4626],
          'Wisdom of Crocodiles, The (a.k.a. Immortality) ': [5136,
           1187,
           1031,
           4721,
           90,
           2341],
          'Erin Brockovich ': [1529, 530],
          'Roman Holiday ': [2461, 722],
          'She-Devil ': [1193],
          'Saint, The ': [3735, 4721],
          'Wild Bunch, The ': [571, 3424, 4721],
          'Heart and Souls ': [1569, 3119, 1571],
          'Gate, The ': [792, 4721],
          'Six Degrees of Separation ': [4995, 405, 1187, 4567],
          'To Live (Huozhe) ': [885, 2275, 4305],
          'Stuart Little ': [2411, 2254],
          'One False Move ': [300, 4416, 3199],
          'Body Shots ': [4876, 2749],
          'Bottle Rocket ': [2523, 4027],
          'Grandfather, The (El Abuelo) ': [498, 4721, 896, 4262],
          'Grease ': [4630],
          'Designated Mourner, The ': [70, 775, 4721],
          'On Any Sunday ': [3236, 4149, 3183],
          'Smiling Fish and Goat on Fire ': [1250, 1809, 3119, 231, 3538, 4698],
          'Ugly, The ': [1443, 4721],
          'Muppets From Space ': [2879, 4177, 1240],
          'Crying Game, The ': [2751, 302, 4721],
          'Across the Sea of Time ': [3012, 4975, 1766, 1187, 5164],
          'Farewell My Concubine ': [456, 2526, 2582],
          'Rawhead Rex ': [3282, 381],
          'Great Expectations ': [4428, 890],
          'Different for Girls ': [3494, 1318, 1776],
          'McCullochs, The ': [3157, 4721],
          'Fantasia ': [2387],
          'If Lucy Fell ': [2320, 1623, 3457],
          'Mortal Kombat ': [2249, 2077],
          'Braddock: Missing in Action III ': [2093, 4302, 1417, 943, 2494],
          'Federal Hill ': [4712, 2431],
          'American Tail, An ': [646, 839, 2491],
          "Schindler's List ": [2748, 2998],
          'River Wild, The ': [5122, 3614, 4721],
          'Star Maps ': [1597, 3026],
          'Die Hard 2 ': [2496, 4994, 1708],
          'Lethal Weapon 3 ': [43, 384, 350],
          'My Crazy Life (Mi vida loca) ': [2526, 5138, 4528, 4247, 940, 4871],
          'Full Metal Jacket ': [282, 1278, 2797],
          'Cradle Will Rock, The ': [386, 5131, 2438, 4721],
          'Two if by Sea ': [3340, 418, 4667, 1766],
          'Spitfire Grill, The ': [323, 4903, 4721],
          'Happiness Is in the Field ': [956, 1019, 1417, 4975, 286],
          'Native Son ': [4579, 2271],
          'JFK ': [2888],
          'Love and Death on Long Island ': [3179, 3119, 71, 3538, 3719, 3800],
          'Thumbelina ': [5181],
          'Scorta, La ': [1738, 3791],
          '8 Seconds ': [4520, 4738],
          'Some Folks Call It a Sling Blade ': [3322, 4724, 719, 1226, 3808, 270, 520],
          'Red Firecracker, Green Firecracker ': [4769, 3141, 669, 3884],
          'Gambler, The (A J醫閗os) ': [1394, 4721, 1158, 4983],
          'Wild Reeds ': [571, 4389],
          'New Jersey Drive ': [4843, 3610, 5092],
          'Reluctant Debutante, The ': [4732, 3126, 4721],
          'Before and After ': [4148, 3119, 2683],
          'Shooter, The ': [1304, 4721],
          'Frisk ': [362],
          'Tequila Sunrise ': [2155, 3551],
          'Replacement Killers, The ': [2347, 2988, 4721],
          'Graveyard Shift ': [4088, 4676],
          'Simply Irresistible ': [2944, 1765],
          'Mr. Wonderful ': [4908, 2088],
          'Apple, The (Sib) ': [396, 4721, 1116],
          'Losing Isaiah ': [2820, 1288],
          'Battling Butler ': [1787, 981],
          'Kissed ': [3495],
          'Welcome to the Dollhouse ': [4635, 4070, 4975, 3533],
          'Amadeus ': [1513],
          'Last Dance ': [3933, 4156],
          'Young Sherlock Holmes ': [2137, 4789, 3920],
          'Following ': [3678],
          'Where Eagles Dare ': [1968, 620, 3618],
          'Persuasion ': [1242],
          'Circus, The ': [3992, 4721],
          'Dadetown ': [123],
          'Lost Weekend, The ': [3857, 4557, 4721],
          'Papillon ': [4339],
          'Glass Shield, The ': [1409, 3170, 4721],
          'Houseguest ': [5127],
          'Bambi ': [4534],
          'Rain ': [3346],
          'Repossessed ': [3603],
          'Pagemaster, The ': [2937, 4721],
          "Billy's Holiday ": [2462, 722],
          'Devil Girl From Mars ': [2159, 987, 4177, 4411],
          'Girl on the Bridge, The (La Fille sur le Pont) ': [987,
           3538,
           4975,
           1736,
           4721,
           368,
           1087,
           4376,
           1773,
           1404],
          'Sixth Sense, The ': [3688, 1296, 4721],
          'Touch of Evil ': [4215, 1187, 1890],
          'Carmen ': [27],
          'Jungle Book, The ': [5188, 2961, 4721],
          'Playing by Heart ': [672, 4667, 1569],
          'Kissing a Fool ': [4971, 3808, 4576],
          'Mille bolle blu ': [2816, 1175, 3443],
          'Flashdance ': [1888],
          'Peggy Sue Got Married ': [3234, 5175, 2209, 5184],
          "Stacy's Knights ": [1719, 2873],
          'Deceiver ': [1899],
          'Mad Dog Time ': [2686, 4942, 5164],
          'House ': [3228],
          'Hurricane, The ': [1948, 4721],
          "Jesus' Son ": [2069, 2271],
          'Arsenic and Old Lace ': [4844, 3119, 1233, 3482],
          'Tess of the Storm Country ': [3055, 1187, 4975, 2931, 3902],
          'Bat, The ': [244, 4721],
          'Force 10 from Navarone ': [3880, 2583, 660, 1875],
          'Star Is Born, A ': [1597, 1019, 14, 4328],
          'Tales from the Crypt Presents: Bordello of Blood ': [3410,
           660,
           4975,
           2016,
           5054,
           4331,
           1187,
           3743],
          'Nightwatch ': [238],
          'Life Is Beautiful (La Vita � bella) ': [4528,
           1019,
           321,
           368,
           2215,
           2765,
           1554],
          'Kama Sutra: A Tale of Love ': [3221, 2473, 4328, 4079, 1187, 3179],
          'Glimmer Man, The ': [678, 3014, 4721],
          'Condition Red ': [4246, 4769],
          'Homeward Bound II: Lost in San Francisco ': [3206,
           2881,
           333,
           3857,
           1417,
           165,
           840],
          'Three to Tango ': [627, 4070, 4873],
          'Stalingrad ': [1821],
          'Deconstructing Harry ': [4960, 1],
          'Insider, The ': [837, 4721],
          'My Tutor ': [2526, 5114],
          'Blown Away ': [1790, 2838],
          'Poltergeist III ': [3143, 2494],
          "Muriel's Wedding ": [3519, 332],
          'Snow White and the Seven Dwarfs ': [2468, 2404, 3119, 4975, 2901, 3065],
          'Marie Baie Des Anges ': [3970, 720, 3460, 4421],
          'Savior ': [4608],
          'Babymother ': [2750],
          "Legend of 1900, The (Leggenda del pianista sull'oceano) ": [2405,
           1187,
           4352,
           4721,
           1005,
           1812,
           2948,
           691],
          'Inspector General, The ': [227, 4559, 4721],
          'Bonnie and Clyde ': [4986, 3119, 505],
          'Sound of Music, The ': [2480, 1187, 2413, 4721],
          'Friday the 13th Part VIII: Jason Takes Manhattan ': [1426,
           4975,
           986,
           1880,
           1065,
           1161,
           5087,
           1651],
          'Thomas Crown Affair, The ': [2547, 2264, 1284, 4721],
          'English Patient, The ': [2450, 1600, 4721],
          "Kestrel's Eye (Falkens 鰃a) ": [5064, 899, 3168, 2747],
          'Some Kind of Wonderful ': [3322, 1786, 1187, 2088],
          'Volunteers ': [2214],
          "You Can't Take It With You ": [908, 3068, 269, 1226, 951, 908],
          'Double Jeopardy ': [1861, 3213],
          'Abbott and Costello Meet Frankenstein ': [2995, 3119, 581, 1710, 1109],
          'Something Wicked This Way Comes ': [1895, 757, 4224, 856, 889],
          'Celestial Clockwork ': [301, 3404],
          'Gods Must Be Crazy, The ': [4045, 3897, 4392, 2225, 4721],
          'Urban Legend ': [693, 2405],
          'Sea Wolves, The ': [1766, 65, 4721],
          "Besieged (L' Assedio) ": [2422, 4504, 4018],
          "Men Don't Leave ": [2964, 3521, 3527],
          'Halloween II ': [3635, 4155],
          'Jack Frost ': [1536, 262],
          'Farinelli: il castrato ': [1190, 4185, 17],
          'Aiqing wansui ': [4315, 3400],
          'Secret Agent ': [10, 176],
          'Trial, The (Le Proc鑣) ': [1926, 4721, 628, 4284],
          'Out of the Past ': [2625, 1187, 4975, 1053],
          'Santa with Muscles ': [4977, 1987, 2862],
          'Picture Bride ': [1543, 4742],
          'Official Story, The (La Historia Oficial) ': [1326,
           1077,
           4721,
           368,
           2197,
           5149],
          'House on Haunted Hill, The ': [3228, 3538, 2037, 1266, 4721],
          'Airheads ': [1854],
          'Yards, The ': [1905, 4721],
          'My Name Is Joe ': [2526, 2084, 1019, 3594],
          'For the Love of Benji ': [2244, 4975, 3179, 1187, 2954],
          'What Happened Was{\ldots} ': [2753, 1083, 441],
          'Nell ': [3973],
          "Gridlock'd ": [296],
          'My Fellow Americans ': [2526, 3264, 4098],
          'Irma la Douce ': [2910, 1125, 4254],
          'White Sands ': [2404, 853],
          'Primal Fear ': [721, 3944],
          'Autumn Sonata (H鰏tsonaten ) ': [125, 3413, 2654, 1838],
          'Cocoon ': [2023],
          'Just Cause ': [2791, 4353],
          'Addams Family Values ': [710, 1166, 129],
          'Urbania ': [2601],
          'Jerky Boys, The ': [2210, 206, 4721],
          'Gigi ': [2280],
          'Home Page ': [3862, 984],
          'Monkey Shines ': [226, 2412],
          'On the Beach ': [3236, 4975, 2216],
          'King of the Hill ': [712, 1187, 4975, 2431],
          'Butch Cassidy and the Sundance Kid ': [1064, 4894, 3119, 4975, 825, 4629],
          'Associate, The ': [1439, 4721],
          'American in Paris, An ': [646, 1417, 2087, 2491],
          'Stir of Echoes ': [4006, 1187, 3835],
          'Wrongfully Accused ': [5102, 47],
          'Damsel in Distress, A ': [1373, 1417, 609, 4328],
          'Greatest Show on Earth, The ': [4265, 3293, 3538, 3824, 4721],
          'Feeling Minnesota ': [4524, 3103],
          'Davy Crockett, King of the Wild Frontier ': [4857,
           2508,
           712,
           1187,
           4975,
           571,
           4472],
          'Beverly Hills Cop III ': [2288, 881, 2202, 2494],
          'Steal Big, Steal Little ': [2107, 4840, 2107, 2254],
          'Maximum Overdrive ': [3561, 5032],
          'Billy Madison ': [3197, 1338],
          'My Cousin Vinny ': [2526, 5191, 4120],
          'Airplane II: The Sequel ': [229, 333, 4721, 4521],
          "Margaret's Museum ": [3061, 4794],
          'Emma ': [4048],
          'Johnny 100 Pesos ': [905, 2328, 4553],
          'Assassins ': [1319],
          'Chinese Box ': [1666, 511],
          'Apt Pupil ': [606, 2829],
          'Anastasia ': [4332],
          'Rising Sun ': [354, 785],
          'Benji ': [2954],
          'Hoodlum ': [4912],
          'House of Frankenstein ': [3228, 1187, 1109],
          'Girl 6 ': [987, 1098],
          "'burbs, The ": [4511, 4721],
          'Hud ': [1716],
          'Thin Man, The ': [4610, 3014, 4721],
          'Perfect World, A ': [4925, 1144, 4328],
          'Original Kings of Comedy, The ': [482, 1629, 1187, 1047, 4721],
          'Crimson Pirate, The ': [3819, 3010, 4721],
          'Heartbreak Ridge ': [1704, 2930],
          'It Could Happen to You ': [1226, 153, 2585, 4070, 908],
          'Tarantella ': [4636],
          'Detroit 9000 ': [2691, 2053],
          'Last Summer in the Hamptons ': [3933, 334, 1417, 4975, 3778],
          'NeverEnding Story, The ': [1557, 1077, 4721],
          'Young Doctors in Love ': [2137, 2237, 1417, 3179],
          'Pollyanna ': [52],
          'Cabinet of Dr. Ramirez, The ': [516, 1187, 3802, 2717, 4721],
          'So I Married an Axe Murderer ': [5052, 921, 5184, 4863, 714, 2941],
          'East Palace West Palace (Dong gong xi gong) ': [4151,
           1137,
           972,
           1137,
           1829,
           1425,
           256,
           5137],
          'Grifters, The ': [152, 4721],
          'Bells, The ': [3262, 4721],
          'Forbidden Planet ': [5205, 3853],
          'Lord of Illusions ': [4161, 1187, 698],
          'Rob Roy ': [5212, 4731],
          'Champ, The ': [616, 4721],
          'Gaslight ': [2191],
          'Bad Company ': [4319, 4934],
          'Rough Magic ': [75, 2646],
          'Midnight Run ': [1729, 3153],
          'Walk in the Sun, A ': [625, 1417, 4975, 4327, 4328],
          'Only Angels Have Wings ': [4131, 278, 2435, 4741],
          'Last Time I Committed Suicide, The ': [3933, 5164, 921, 2945, 1681, 4721],
          'Princess Mononoke, The (Mononoke Hime) ': [3162, 4495, 4721, 915, 4106],
          'First Kid ': [1743, 4629],
          'Love Stinks ': [3179, 2099],
          'Fighting Seabees, The ': [1669, 3020, 4721],
          'Friday the 13th Part 3: 3D ': [1426, 4975, 986, 1880, 2052, 2287],
          'Strike! (a.k.a. All I Wanna Do, The Hairy Bird) ': [3432,
           90,
           3739,
           921,
           3781,
           2859,
           4721,
           4009,
           2396],
          'Nightmare Before Christmas, The ': [5074, 4148, 3639, 4721],
          'Harry and the Hendersons ': [1, 3119, 4975, 1027],
          'Perez Family, The ': [3556, 4275, 4721],
          'Ghost ': [1614],
          'Rock, The ': [2438, 4721],
          'Malcolm X ': [1370, 144],
          'Crow: City of Angels, The ': [4395, 157, 1187, 4963, 4721],
          'Major Payne ': [4816, 3210],
          'Sonic Outlaws ': [1587, 4084],
          'Raging Bull ': [3450, 187],
          "Who's Harry Crumb? ": [4294, 1, 1026],
          'Black Cat, White Cat (Crna macka, beli macor) ': [552,
           1038,
           2404,
           866,
           2811,
           1644,
           5206,
           4193],
          'Man Who Knew Too Much, The ': [4433, 1289, 5146, 983, 3301, 4721],
          'Up at the Villa ': [2149, 2182, 4975, 1105],
          'Popeye ': [2754],
          'Slam ': [87],
          "Bram Stoker's Dracula ": [1503, 2283, 4689],
          'Anne Frank Remembered ': [1694, 4404, 2090],
          'Omega Man, The ': [1962, 3014, 4721],
          'Napoleon and Samantha ': [4773, 3119, 2821],
          'Princess Caraboo ': [3162, 2530],
          'They Might Be Giants ': [3797, 3910, 4392, 4523],
          'Sleepover ': [4854],
          'Lonely Are the Brave ': [4447, 1079, 4975, 1014],
          'Quatermass and the Pit ': [2365, 3119, 4975, 150],
          'Fistful of Dollars, A ': [759, 1187, 3401, 4328],
          'Muppets Take Manhattan, The ': [2879, 269, 5177, 4721],
          'Journey of Natty Gann, The ': [1865, 1187, 1943, 1886, 4721],
          'Zed \& Two Noughts, A ': [428, 2580, 3340, 2314, 4328],
          'Beyond Silence ': [1648, 3122],
          'Without Limits ': [3278, 1592],
          'As Good As It Gets ': [4355, 764, 4355, 1226, 3803],
          'MURDER and murder ': [2704, 3119, 5039],
          'Free Enterprise ': [440, 3574],
          'Paper Chase, The ': [884, 4796, 4721],
          'Unforgiven ': [2819],
          'Sugarland Express, The ': [5165, 959, 4721],
          'Superman III ': [4217, 2494],
          'Jerry Maguire ': [3936, 3269],
          'Psycho ': [3148],
          'Alive ': [5073],
          'Substitute, The ': [1487, 4721],
          'Guys and Dolls ': [4469, 3119, 2321],
          'From Dusk Till Dawn ': [4177, 2100, 3744, 716],
          'Glen or Glenda ': [4153, 3115, 3946],
          'See the Sea (Regarde la mer) ': [3175, 4975, 1766, 2612, 1125, 1668],
          'Assault on Precinct 13 ': [841, 3538, 1205, 2106],
          'Fools Rush In ': [4615, 3616, 3786],
          'Meet the Parents ': [1710, 4975, 3755],
          'Suddenly, Last Summer ': [4525, 3933, 334],
          'Rocky ': [410],
          "Concorde: Airport '79, The ": [3493, 1322, 2989, 4721],
          'Maybe, Maybe Not (Bewegte Mann, Der) ': [2325, 4080, 1502, 478, 812, 4019],
          'Private Benjamin ': [848, 4317],
          'Amityville II: The Possession ': [1206, 333, 4721, 164],
          'Summer of Sam ': [334, 1187, 3876],
          'Midnight Cowboy ': [1729, 21],
          'Cider House Rules, The ': [1132, 3228, 4055, 4721],
          'Burnt Offerings ': [1145, 2198],
          'Hate (Haine, La) ': [3740, 3877, 311],
          'Three Caballeros, The ': [627, 2233, 4721],
          'Tales of Terror ': [3410, 1187, 1864],
          "Things to Do in Denver when You're Dead ": [657,
           4070,
           2537,
           1417,
           3185,
           3834,
           3975,
           325],
          'Celebration, The (Festen) ': [4407, 4721, 2803],
          'Nightmare on Elm Street 4: The Dream Master, A ': [5074,
           3538,
           2124,
           1347,
           5123,
           4721,
           3442,
           2205,
           4328],
          'Squeeze ': [434],
          'Scream ': [2870],
          'Messenger: The Story of Joan of Arc, The ': [2604,
           4721,
           3945,
           1187,
           1424,
           1187,
           4478,
           4721],
          'D閖� Vu ': [1940, 4993],
          'Autumn Heart ': [125, 1569],
          '8 1/2 ': [4520, 4992],
          'Trouble in Paradise ': [1364, 1417, 3133],
          'House II: The Second Story ': [3228, 333, 4721, 438, 3945],
          'Incredibly True Adventure of Two Girls in Love, The ': [2033,
           1489,
           4974,
           1187,
           3340,
           1776,
           1417,
           4464,
           4721],
          'Two Much ': [3340, 422],
          'Being There ': [194, 2942],
          'Little City ': [2254, 157],
          'Apollo 13 ': [2227, 2106],
          'Kalifornia ': [4109],
          'When a Man Loves a Woman ': [5180, 3808, 4433, 1308, 3808, 1583],
          'Kolya ': [4543],
          'Delicatessen ': [3383],
          'Zachariah ': [3865],
          'Next Stop, Wonderland ': [5037, 1868, 3563],
          'Double Indemnity ': [1861, 3384],
          'Broken English ': [16, 2450],
          'Renaissance Man ': [4172, 4433],
          'Father of the Bride ': [1221, 1187, 4975, 4742],
          'Dragonheart ': [1588],
          'My Left Foot ': [2526, 376, 1842],
          'Dingo ': [3702],
          'Baby Geniuses ': [3580, 3259],
          'Glory Daze ': [2856, 705],
          'Instinct ': [2876],
          'American Graffiti ': [646, 2303],
          'Death Wish II ': [71, 2866, 4155],
          'Bicycle Thief, The (Ladri di biciclette) ': [700,
           4057,
           4721,
           4800,
           363,
           3328],
          'Prancer ': [2027],
          'Jaws 2 ': [214, 1708],
          'Slaves to the Underground ': [4372, 4070, 4975, 3180],
          'Tarzan and the Lost City ': [675, 3119, 4975, 3857, 157],
          'Limbo ': [612],
          'Tetsuo II: Body Hammer ': [3741, 333, 4876, 291],
          'Buffy the Vampire Slayer ': [3895, 4975, 2880, 177],
          'Dersu Uzala ': [1177, 3750],
          'Outsiders, The ': [4512, 4721],
          'Hairspray ': [5040],
          'Garcu, Le ': [4181, 489],
          'Photographer (Fotoamator) ': [3641, 3366],
          'Education of Little Tree, The ': [261, 1187, 2254, 4544, 4721],
          'Night of the Living Dead ': [2814, 1187, 4975, 920, 325],
          'Hurlyburly ': [953],
          'Parent Trap, The ': [3158, 2571, 4721],
          'One Crazy Summer ': [300, 5138, 334],
          'Confessional, The (Le Confessionnal) ': [4980, 4721, 628, 5169],
          'Digimon: The Movie ': [5078, 4721, 2356],
          'Force of Evil ': [3880, 1187, 1890],
          'Shop Around the Corner, The ': [682, 2270, 4975, 3447, 4721],
          'Texas Chainsaw Massacre, The ': [3109, 3769, 2091, 4721],
          'Short Cuts ': [1068, 2561],
          'Tic Code, The ': [2031, 4280, 4721],
          'Married to the Mob ': [5184, 4070, 4975, 1223],
          'Blood In, Blood Out (a.k.a. Bound by Honor) ': [3743,
           1227,
           3743,
           2625,
           90,
           2881,
           4667,
           708],
          'Head Above Water ': [5002, 1573, 4760],
          "Jupiter's Wife ": [4550, 3155],
          'Sleepwalkers ': [509],
          'Doors, The ': [3458, 4721],
          'Race the Sun ': [1405, 4975, 785],
          'Little Big Man ': [2254, 1256, 4433],
          'Woo ': [1204],
          'Crow: Salvation, The ': [4395, 3613, 4721],
          'Two or Three Things I Know About Her ': [3340,
           3115,
           627,
           657,
           921,
           3255,
           503,
           3016],
          'Max Dugan Returns ': [2715, 1845, 4935],
          'Raw Deal ': [892, 808],
          'Prince of Tides, The ': [2117, 1187, 2097, 4721],
          'Blue Lagoon, The ': [1481, 988, 4721],
          'Sister Act ': [63, 5077],
          'Saphead, The ': [817, 4721],
          'Career Girls ': [4200, 1776],
          'Airplane! ': [3069],
          'Sweet Nothing ': [4128, 2467],
          'Mirror, The (Zerkalo) ': [4435, 4721, 749],
          'Encino Man ': [718, 4433],
          "Soldier's Daughter Never Cries, A ": [2681, 4835, 4370, 1018, 4328],
          'Barcelona ': [1831],
          'Limey, The ': [4171, 4721],
          'Birds, The ': [5166, 4721],
          'Beach Party ': [2216, 3915],
          'Twister ': [203],
          'Regret to Inform ': [728, 4070, 1771],
          'Fisher King, The ': [4745, 3961, 4721],
          'Terror in a Texas Town ': [1864, 1417, 3808, 3109, 1274],
          'Once Were Warriors ': [2184, 4718, 3714],
          'Hard-Boiled (Lashou shentan) ': [3959, 2692, 4384],
          'Brother, Can You Spare a Dime? ': [4271, 1045, 908, 1619, 3808, 1035],
          '8 1/2 Women ': [4520, 4992, 992],
          'Glengarry Glen Ross ': [5080, 4153, 2633],
          'Year of Living Dangerously ': [1449, 1187, 920, 3752],
          'X: The Unknown ': [3532, 4721, 2372],
          'Time to Kill, A ': [5164, 4070, 3437, 4328],
          'When the Cats Away (Chacun cherche son chat) ': [5180,
           4975,
           1586,
           2838,
           4219,
           1945,
           3526,
           1548],
          'Unforgotten: Twenty-Five Years After Willowbrook ': [2078,
           2190,
           2936,
           2683,
           1938],
          'Problem Child ': [252, 83],
          "Hang 'em High ": [2577, 1096, 3595],
          'Night at the Roxbury, A ': [2814, 2182, 4975, 3256, 4328],
          "Don't Look in the Basement! ": [3521, 5068, 1417, 4975, 349],
          'North ': [731],
          'Cool as Ice ': [1598, 5084, 2336],
          'Ridicule ': [3557],
          'Nadine ': [2698],
          'Carnal Knowledge ': [2709, 1181],
          'Bats ': [3191],
          'All Dogs Go to Heaven ': [3739, 4508, 5210, 4070, 4506],
          'Return of Jafar, The ': [2660, 1187, 2603, 4721],
          'Grand Illusion (Grande illusion, La) ': [2194, 2812, 1698, 4210, 311],
          "I Can't Sleep (J'ai pas sommeil) ": [921, 3068, 2095, 2951, 156, 380],
          'Psycho Beach Party ': [3148, 2216, 3915],
          'Victor/Victoria ': [1739],
          'Dances with Wolves ': [355, 1987, 2273],
          'Art of War, The ': [4142, 1187, 3905, 4721],
          'Never Cry Wolf ': [4370, 4300, 1139],
          "Angela's Ashes ": [747, 1365],
          'Godzilla (Gojira) ': [5038, 4032],
          'From Here to Eternity ': [4177, 2203, 4070, 4956],
          'Get Bruce ': [2353, 443],
          'Suspicion ': [3246],
          "Peter's Friends ": [2333, 4163],
          'Monty Python and the Holy Grail ': [3518, 1467, 3119, 4975, 3764, 3953],
          'Nothing Personal ': [2467, 803],
          'Prince of Central Park, The ': [2117, 1187, 1199, 3503, 4721],
          'Mad Max ': [2686, 2715],
          'Stranger Than Paradise ': [2326, 4164, 3133],
          'Stepford Wives, The ': [442, 2673, 4721],
          'On the Waterfront ': [3236, 4975, 750],
          "Clara's Heart ": [1998, 1569],
          'In Too Deep ': [3786, 983, 4170],
          'Perfect Murder, A ': [4925, 3854, 4328],
          'Tom Jones ': [684, 2642],
          'Long Walk Home, The ': [3719, 625, 4734, 4721],
          'Fast Times at Ridgemont High ': [2911, 1811, 2182, 2947, 3595],
          'Frequency ': [3663],
          'Zone 39 ': [290, 3232],
          'Family Plot ': [1166, 1234],
          'What Dreams May Come ': [2753, 4086, 2624, 2662],
          'Son of the Sheik, The ': [2271, 1187, 4975, 3362, 4721],
          "National Lampoon's Senior Trip ": [1624, 4891, 3942, 4542],
          'Coyote Ugly ': [151, 1508],
          'Moonlight and Valentino ': [3489, 3119, 4076],
          'Ben-Hur ': [2769],
          'Albino Alligator ': [1367, 3049],
          'Carmen Miranda: Bananas Is My Business ': [27, 2774, 5153, 1019, 2526, 3541],
          'Police Academy 3: Back in Training ': [3901, 1970, 2052, 3414, 1417, 2855],
          'Topsy-Turvy ': [415],
          'Escape from the Planet of the Apes ': [4578,
           660,
           4975,
           3853,
           1187,
           4975,
           4296],
          'Muppet Treasure Island ': [351, 2976, 3800],
          'Oxygen ': [1435],
          "Bustin' Loose ": [1636, 564],
          'Night to Remember, A ': [2814, 4070, 2777, 4328],
          'Grapes of Wrath, The ': [1403, 1187, 3873, 4721],
          'Surviving Picasso ': [327, 4322],
          'Day of the Beast, The (El D韆 de la bestia) ': [4286,
           1187,
           4975,
           79,
           4721,
           896,
           2148,
           4117,
           1125,
           3724],
          "Dead Men Don't Wear Plaid ": [325, 2964, 3521, 4778, 170],
          'Steam: The Turkish Bath (Hamam) ': [917, 4721, 3542, 736, 1796],
          'Sleepers ': [4321],
          'Wallace \& Gromit: The Best of Aardman Animation ': [1057,
           2580,
           4932,
           4721,
           5105,
           1187,
           1631,
           3578],
          'Blue Sky ': [1481, 4473],
          'Supernova ': [686],
          "Romy and Michele's High School Reunion ": [4236,
           3119,
           2047,
           3595,
           4555,
           1474],
          'Algiers ': [4455],
          "Joe Gould's Secret ": [3594, 3407, 10],
          'Full Tilt Boogie ': [282, 457, 1151],
          'Twelve Monkeys ': [1677, 2536],
          'Bonheur, Le ': [2042, 489],
          'Odd Couple, The ': [4034, 4619, 4721],
          'Reality Bites ': [998, 1442],
          'Beefcake ': [2767],
          "Microcosmos (Microcosmos: Le peuple de l'herbe) ": [3359,
           5076,
           489,
           1171,
           4117,
           3567],
          'Rough Night in Jericho ': [75, 2814, 1417, 2588],
          'Ghostbusters II ': [5005, 4155],
          'Joyriders, The ': [1687, 4721],
          "Widows' Peak ": [30, 3847],
          'Girlfight ': [1910],
          'Son in Law ': [2271, 1417, 373],
          'Smile Like Yours, A ': [3826, 952, 53, 4328],
          'Best in Show ': [5105, 1417, 3293],
          'Teenage Mutant Ninja Turtles II: The Secret of the Ooze ': [3804,
           481,
           2789,
           4867,
           333,
           4721,
           10,
           1187,
           4975,
           3507],
          'Velocity of Gary, The ': [3021, 1187, 2000, 4721],
          'Searching for Bobby Fischer ': [3623, 1318, 3491, 1625],
          'Solaris (Solyaris) ': [3117, 3163],
          'Kidnapped ': [3582],
          'Philadelphia ': [2082],
          'Mr. Saturday Night ': [4908, 4452, 2814],
          'Blood and Sand (Sangre y Arena) ': [3743, 3119, 1074, 556, 3483, 267],
          {\ldots}\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{}   补零}
         \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{title\PYZus{}map}\PY{p}{:}
             \PY{k}{for} \PY{n}{cnt} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{title\PYZus{}count} \PY{o}{\PYZhy{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{n}{title\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{n}{cnt}\PY{p}{,}\PY{n}{title2int}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{movies}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:}    MovieID                                              Title  \textbackslash{}
         0        1  [2121, 3945, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1        2    [353, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   
         2        3  [2060, 1233, 2964, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         3        4  [3982, 4070, 1276, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         4        5  [1221, 1187, 4975, 4742, 1880, 4155, 0, 0, 0, {\ldots}   
         
                                                       Genres  
         0  [15, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}  
         1  [12, 16, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         2  [1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         3  [1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
\end{Verbatim}
            
    MovieID是类别字段，Title是文本，Genres也是类别字段

    \subsubsection{评分数据}\label{ux8bc4ux5206ux6570ux636e}

分别有用户ID、电影ID、评分和时间戳等字段。

数据中的格式：UserID::MovieID::Rating::Timestamp

\begin{itemize}
\tightlist
\item
  UserIDs range between 1 and 6040
\item
  MovieIDs range between 1 and 3952
\item
  Ratings are made on a 5-star scale (whole-star ratings only)
\item
  Timestamp is represented in seconds since the epoch as returned by
  time(2)
\item
  Each user has at least 20 ratings
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{ratings\PYZus{}title} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MovieID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ratings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{timestamps}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{ratings} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./ml\PYZhy{}1m/ratings.dat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{ratings\PYZus{}title}\PY{p}{,} \PY{n}{engine} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ratings}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:}    UserID  MovieID  ratings  timestamps
         0       1     1193        5   978300760
         1       1      661        3   978302109
         2       1      914        3   978301968
         3       1     3408        4   978300275
         4       1     2355        5   978824291
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{ratings} \PY{o}{=} \PY{n}{ratings}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{n}{regex}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID|MovieID|ratings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}过滤只保留前三项不保留时间数据}
         \PY{n}{ratings}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}23}]:}    UserID  MovieID  ratings
         0       1     1193        5
         1       1      661        3
         2       1      914        3
         3       1     3408        4
         4       1     2355        5
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{c+c1}{\PYZsh{}合并三个表}
         \PY{c+c1}{\PYZsh{}匹配用户 电影 和评分}
         \PY{n}{data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{ratings}\PY{p}{,} \PY{n}{users}\PY{p}{)}\PY{p}{,} \PY{n}{movies}\PY{p}{)}
         \PY{n}{data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}24}]:}    UserID  MovieID  ratings  Gender  Age  \textbackslash{}
         0       1     1193        5       0    0   
         1       2     1193        5       1    5   
         2      12     1193        4       1    6   
         3      15     1193        4       1    6   
         4      17     1193        5       1    3   
         
                                                        Title  \textbackslash{}
         0  [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         1  [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         2  [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         3  [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         4  [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         
                                                       Genres  
         0  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         2  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         3  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         4  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
\end{Verbatim}
            
    评分字段Rating就是我们要学习的targets，时间戳字段我们不使用。

    \textbf{训练数据中特征与目标的划分}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{target\PYZus{}fields} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ratings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{targets\PYZus{}pd} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{n}{target\PYZus{}fields}\PY{p}{]}
         \PY{n}{features\PYZus{}pd} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{target\PYZus{}fields}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \subsection{来说说数据预处理}\label{ux6765ux8bf4ux8bf4ux6570ux636eux9884ux5904ux7406}

    \begin{itemize}
\tightlist
\item
  UserID、Occupation和MovieID不用变。
\item
  Gender字段：需要将`F'和`M'转换成0和1。
\item
  Age字段：要转成7个连续数字0\textasciitilde{}6。
\item
  Genres字段：是分类字段，要转成数字。首先将Genres中的类别转成字符串到数字的字典，然后再将每个电影的Genres字段转成数字列表，因为有些电影是多个Genres的组合。
\item
  Title字段：处理方式跟Genres字段一样，首先创建文本到数字的字典，然后将Title中的描述转成数字的列表。另外Title中的年份也需要去掉。
\item
  Genres和Title字段需要将长度统一，这样在神经网络中方便处理。空白部分用`\textless{}
  PAD \textgreater{}'对应的数字填充。
\end{itemize}

    \subsection{实现数据预处理(综合函数)}\label{ux5b9eux73b0ux6570ux636eux9884ux5904ux7406ux7efcux5408ux51fdux6570}

    \section{改动关于补零}\label{ux6539ux52a8ux5173ux4e8eux8865ux96f6}

genres\_set.add('') genres2int = \{val:ii for ii, val in
enumerate(genres\_set)\}\#

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Load Dataset from File}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{c+c1}{\PYZsh{}读取User数据}
             \PY{n}{users\PYZus{}title} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{JobID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Zip\PYZhy{}code}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
             \PY{n}{users} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./ml\PYZhy{}1m/users.dat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{users\PYZus{}title}\PY{p}{,} \PY{n}{engine} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{users} \PY{o}{=} \PY{n}{users}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{n}{regex}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID|Gender|Age|JobID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{users\PYZus{}orig} \PY{o}{=} \PY{n}{users}\PY{o}{.}\PY{n}{values}
             \PY{c+c1}{\PYZsh{}改变User数据中性别和年龄}
             \PY{n}{gender\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
             \PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{gender\PYZus{}map}\PY{p}{)}
         
             \PY{n}{age\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{ii} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
             \PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{users}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{age\PYZus{}map}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}读取Movie数据集}
             \PY{n}{movies\PYZus{}title} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MovieID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
             \PY{n}{movies} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./ml\PYZhy{}1m/movies.dat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{movies\PYZus{}title}\PY{p}{,} \PY{n}{engine} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{movies\PYZus{}orig} \PY{o}{=} \PY{n}{movies}\PY{o}{.}\PY{n}{values}
             \PY{c+c1}{\PYZsh{}将Title中的年份去掉}
             \PY{n}{pattern} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZca{}(.*)}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{((}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{d+)}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{)\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{n}{title\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{pattern}\PY{o}{.}\PY{n}{match}\PY{p}{(}\PY{n}{val}\PY{p}{)}\PY{o}{.}\PY{n}{group}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
             \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}电影类型转数字字典}
             \PY{n}{genres\PYZus{}set} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
             \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                 \PY{n}{genres\PYZus{}set}\PY{o}{.}\PY{n}{update}\PY{p}{(}\PY{n}{val}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}     genres\PYZus{}set.add(\PYZsq{}\PYZlt{}PAD\PYZgt{}\PYZsq{})}
         \PY{c+c1}{\PYZsh{}     genres2int = \PYZob{}val:ii for ii, val in enumerate(genres\PYZus{}set)\PYZcb{}}
             \PY{n}{genres\PYZus{}list} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{genres\PYZus{}set}\PY{p}{)}
             \PY{n}{genres\PYZus{}list}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{}作为0等级对应}
             \PY{n}{genres2int} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{ii} \PY{k}{for} \PY{n}{ii}\PY{p}{,} \PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{genres\PYZus{}list}\PY{p}{)}\PY{p}{\PYZcb{}}
             
             \PY{c+c1}{\PYZsh{}将电影类型转成等长数字列表，长度是18}
             \PY{n}{genres\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{p}{[}\PY{n}{genres2int}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{val}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
         
             \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{genres\PYZus{}map}\PY{p}{:}
                 \PY{k}{for} \PY{n}{cnt} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{max}\PY{p}{(}\PY{n}{genres2int}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{genres\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                     \PY{n}{genres\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{genres\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{n}{cnt}\PY{p}{,}\PY{n}{genres2int}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             
             \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Genres}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{genres\PYZus{}map}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}电影Title转数字字典}
             \PY{n}{title\PYZus{}set} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
             \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                 \PY{n}{title\PYZus{}set}\PY{o}{.}\PY{n}{update}\PY{p}{(}\PY{n}{val}\PY{p}{)}
             
             \PY{n}{title\PYZus{}list} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{title\PYZus{}set}\PY{p}{)}
             \PY{n}{title\PYZus{}list}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{title2int} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{n}{ii} \PY{k}{for} \PY{n}{ii}\PY{p}{,} \PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{title\PYZus{}list}\PY{p}{)}\PY{p}{\PYZcb{}}
         
             \PY{c+c1}{\PYZsh{}将电影Title转成等长数字列表，长度是15}
             \PY{n}{title\PYZus{}count} \PY{o}{=} \PY{l+m+mi}{15}
             \PY{n}{title\PYZus{}map} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{:}\PY{p}{[}\PY{n}{title2int}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{k}{for} \PY{n}{row} \PY{o+ow}{in} \PY{n}{val}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{]} \PY{k}{for} \PY{n}{ii}\PY{p}{,}\PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZcb{}}
             
             \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{title\PYZus{}map}\PY{p}{:}
                 \PY{k}{for} \PY{n}{cnt} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{title\PYZus{}count} \PY{o}{\PYZhy{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                     \PY{n}{title\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{o}{.}\PY{n}{insert}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{[}\PY{n}{key}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{n}{cnt}\PY{p}{,}\PY{n}{title2int}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZlt{}PAD\PYZgt{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             
             \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Title}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{title\PYZus{}map}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}读取评分数据集}
             \PY{n}{ratings\PYZus{}title} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MovieID}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ratings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{timestamps}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
             \PY{n}{ratings} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}table}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./ml\PYZhy{}1m/ratings.dat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{::}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{ratings\PYZus{}title}\PY{p}{,} \PY{n}{engine} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{ratings} \PY{o}{=} \PY{n}{ratings}\PY{o}{.}\PY{n}{filter}\PY{p}{(}\PY{n}{regex}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UserID|MovieID|ratings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{}合并三个表}
             \PY{c+c1}{\PYZsh{}匹配用户 电影 和评分}
             \PY{n}{data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{ratings}\PY{p}{,} \PY{n}{users}\PY{p}{)}\PY{p}{,} \PY{n}{movies}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{}将数据分成X和y两张表}
             \PY{n}{target\PYZus{}fields} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ratings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
             \PY{n}{features\PYZus{}pd}\PY{p}{,} \PY{n}{targets\PYZus{}pd} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{target\PYZus{}fields}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{data}\PY{p}{[}\PY{n}{target\PYZus{}fields}\PY{p}{]}
             
             \PY{n}{features} \PY{o}{=} \PY{n}{features\PYZus{}pd}\PY{o}{.}\PY{n}{values}
             \PY{n}{targets\PYZus{}values} \PY{o}{=} \PY{n}{targets\PYZus{}pd}\PY{o}{.}\PY{n}{values}
             
             \PY{k}{return} \PY{n}{title\PYZus{}count}\PY{p}{,} \PY{n}{title\PYZus{}set}\PY{p}{,} \PY{n}{genres2int}\PY{p}{,} \PY{n}{features}\PY{p}{,} \PY{n}{targets\PYZus{}values}\PY{p}{,} \PY{n}{ratings}\PY{p}{,} \PY{n}{users}\PY{p}{,} \PY{n}{movies}\PY{p}{,} \PY{n}{data}\PY{p}{,} \PY{n}{movies\PYZus{}orig}\PY{p}{,} \PY{n}{users\PYZus{}orig}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{features\PYZus{}pd}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:}          UserID  MovieID  Gender  Age  \textbackslash{}
         0             1     1193       0    0   
         1             2     1193       1    5   
         2            12     1193       1    6   
         3            15     1193       1    6   
         4            17     1193       1    3   
         5            18     1193       0    4   
         6            19     1193       1    0   
         7            24     1193       0    6   
         8            28     1193       0    6   
         9            33     1193       1    2   
         10           39     1193       1    4   
         11           42     1193       1    6   
         12           44     1193       1    2   
         13           47     1193       1    4   
         14           48     1193       1    6   
         15           49     1193       1    4   
         16           53     1193       1    6   
         17           54     1193       1    3   
         18           58     1193       1    6   
         19           59     1193       0    3   
         20           62     1193       0    1   
         21           80     1193       1    5   
         22           81     1193       0    6   
         23           88     1193       0    2   
         24           89     1193       0    5   
         25           95     1193       1    2   
         26           96     1193       0    6   
         27           99     1193       0    0   
         28          102     1193       1    1   
         29          104     1193       1    6   
         {\ldots}         {\ldots}      {\ldots}     {\ldots}  {\ldots}   
         1000179    4933     3084       1    6   
         1000180    4802     2218       1    5   
         1000181    4812     2308       1    4   
         1000182    4874      624       0    6   
         1000183    5059     1434       1    2   
         1000184    5947     1434       0    2   
         1000185    5077     1868       1    6   
         1000186    5944     1868       0    4   
         1000187    5105      404       1    3   
         1000188    5185      404       0    1   
         1000189    5532      404       1    6   
         1000190    5543      404       1    6   
         1000191    5220     2543       1    6   
         1000192    5754     2543       0    4   
         1000193    5227      591       1    4   
         1000194    5795      591       1    6   
         1000195    5313     3656       1    5   
         1000196    5328     2438       0    6   
         1000197    5334     3323       0    5   
         1000198    5334      127       0    5   
         1000199    5334     3382       0    5   
         1000200    5420     1843       0    0   
         1000201    5433      286       0    1   
         1000202    5494     3530       0    1   
         1000203    5556     2198       1    2   
         1000204    5949     2198       1    4   
         1000205    5675     2703       1    1   
         1000206    5780     2845       1    4   
         1000207    5851     3607       0    4   
         1000208    5938     2909       1    6   
         
                                                              Title  \textbackslash{}
         0        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         1        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         2        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         3        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         4        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         5        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         6        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         7        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         8        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         9        [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         10       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         11       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         12       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         13       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         14       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         15       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         16       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         17       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         18       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         19       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         20       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         21       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         22       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         23       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         24       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         25       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         26       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         27       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         28       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         29       [300, 1807, 2651, 4975, 2943, 569, 0, 0, 0, 0,{\ldots}   
         {\ldots}                                                    {\ldots}   
         1000179  [3862, 984, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}   
         1000180  [1563, 3119, 1254, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000181  [2691, 2053, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000182  [4246, 4769, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000183  [3349, 4721, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000184  [3349, 4721, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000185  [4821, 4721, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000186  [4821, 4721, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000187  [1622, 2206, 4721, 1170, 1187, 1370, 144, 0, 0{\ldots}   
         1000188  [1622, 2206, 4721, 1170, 1187, 1370, 144, 0, 0{\ldots}   
         1000189  [1622, 2206, 4721, 1170, 1187, 1370, 144, 0, 0{\ldots}   
         1000190  [1622, 2206, 4721, 1170, 1187, 1370, 144, 0, 0{\ldots}   
         1000191  [4995, 1466, 4070, 3183, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000192  [4995, 1466, 4070, 3183, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000193  [4687, 3119, 1482, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000194  [4687, 3119, 1482, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000195    [583, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   
         1000196  [2248, 138, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}   
         1000197  [1441, 1187, 4615, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000198  [3122, 1187, 4975, 1344, 4721, 3784, 1066, 422{\ldots}   
         1000199  [3903, 1187, 4883, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000200  [2729, 3119, 4975, 4788, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000201  [2518, 5120, 525, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}   
         1000202  [1950, 347, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}   
         1000203   [4490, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   
         1000204   [4490, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   
         1000205  [16, 1401, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   
         1000206  [2404, 4124, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}   
         1000207  [300, 2254, 1764, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}   
         1000208  [2557, 2673, 627, 1349, 3119, 605, 0, 0, 0, 0,{\ldots}   
         
                                                             Genres  
         0        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         2        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         3        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         4        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         5        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         6        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         7        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         8        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         9        [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         10       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         11       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         12       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         13       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         14       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         15       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         16       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         17       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         18       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         19       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         20       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         21       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         22       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         23       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         24       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         25       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         26       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         27       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         28       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         29       [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         {\ldots}                                                    {\ldots}  
         1000179  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000180  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000181  [9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000182  [9, 6, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000183  [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000184  [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000185  [6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000186  [6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000187  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000188  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000189  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000190  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000191  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000192  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000193  [9, 6, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000194  [9, 6, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000195  [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000196  [6, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000197  [1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000198  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000199  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000200  [16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000201  [9, 18, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0{\ldots}  
         1000202  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000203  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000204  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         1000205  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000206  [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000207  [1, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, {\ldots}  
         1000208  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,{\ldots}  
         
         [1000209 rows x 6 columns]
\end{Verbatim}
            
    \subsubsection{加载数据并保存到本地}\label{ux52a0ux8f7dux6570ux636eux5e76ux4fddux5b58ux5230ux672cux5730}

    \begin{itemize}
\tightlist
\item
  title\_count：Title字段的长度（15）
\item
  title\_set：Title文本的集合
\item
  genres2int：电影类型转数字的字典
\item
  features：是输入X
\item
  targets\_values：是学习目标y
\item
  ratings：评分数据集的Pandas对象
\item
  users：用户数据集的Pandas对象
\item
  movies：电影数据的Pandas对象
\item
  data：三个数据集组合在一起的Pandas对象
\item
  movies\_orig：没有做数据处理的原始电影数据
\item
  users\_orig：没有做数据处理的原始用户数据
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{title\PYZus{}count}\PY{p}{,} \PY{n}{title\PYZus{}set}\PY{p}{,} \PY{n}{genres2int}\PY{p}{,} \PY{n}{features}\PY{p}{,} \PY{n}{targets\PYZus{}values}\PY{p}{,} \PY{n}{ratings}\PY{p}{,} \PY{n}{users}\PY{p}{,} \PY{n}{movies}\PY{p}{,} \PY{n}{data}\PY{p}{,} \PY{n}{movies\PYZus{}orig}\PY{p}{,} \PY{n}{users\PYZus{}orig} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{p}{(}\PY{n}{title\PYZus{}count}\PY{p}{,} \PY{n}{title\PYZus{}set}\PY{p}{,} \PY{n}{genres2int}\PY{p}{,} \PY{n}{features}\PY{p}{,} \PY{n}{targets\PYZus{}values}\PY{p}{,} \PY{n}{ratings}\PY{p}{,} \PY{n}{users}\PY{p}{,} \PY{n}{movies}\PY{p}{,} \PY{n}{data}\PY{p}{,} \PY{n}{movies\PYZus{}orig}\PY{p}{,} \PY{n}{users\PYZus{}orig}\PY{p}{)}\PY{p}{,} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{preprocess.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{targets\PYZus{}values}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}29}]:} array([[5],
                [5],
                [4],
                {\ldots},
                [1],
                [5],
                [4]], dtype=int64)
\end{Verbatim}
            
    \subsubsection{从本地存储数据}\label{ux4eceux672cux5730ux5b58ux50a8ux6570ux636e}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{title\PYZus{}count}\PY{p}{,} \PY{n}{title\PYZus{}set}\PY{p}{,} \PY{n}{genres2int}\PY{p}{,} \PY{n}{features}\PY{p}{,} \PY{n}{targets\PYZus{}values}\PY{p}{,} \PY{n}{ratings}\PY{p}{,} \PY{n}{users}\PY{p}{,} \PY{n}{movies}\PY{p}{,} \PY{n}{data}\PY{p}{,} \PY{n}{movies\PYZus{}orig}\PY{p}{,} \PY{n}{users\PYZus{}orig} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{preprocess.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsection{模型设计}\label{ux6a21ux578bux8bbeux8ba1}

    \begin{figure}
\centering
\includegraphics{attachment:\%E5\%9B\%BE\%E7\%89\%87.png}
\caption{\%E5\%9B\%BE\%E7\%89\%87.png}
\end{figure}

    通过研究数据集中的字段类型，我们发现有一些是类别字段，通常的处理是将这些字段转成one
hot编码，但是像UserID、MovieID这样的字段就会变成非常的稀疏，输入的维度急剧膨胀，这是我们不愿意见到的，毕竟我这小笔记本不像大厂动辄能处理数以亿计维度的输入：）

\textbf{预处理数据时}

\begin{itemize}
\item
  将UserID、MovieID转成了数字，我们用这个数字当做嵌入矩阵的索引，在网络的第一层使用了嵌入层，维度是（N，32）和（N，16）。
\item
  电影类型的处理要多一步，有时一个电影有多个电影类型，这样从嵌入矩阵索引出来是一个（n，32）的矩阵，因为有多个类型嘛，我们要将这个矩阵求和，变成（1，32）的向量。
\item
  电影名的处理比较特殊，没有使用循环神经网络，而是用了文本卷积网络，下文会进行说明。
\end{itemize}

\textbf{简单模型设计}

从嵌入层索引出特征以后，将各特征传入全连接层，将输出再次传入全连接层

最终分别得到（1，200）的用户特征和电影特征两个特征向量。

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

我们的目的就是要训练出用户特征和电影特征，在实现推荐功能时使用。得到这两个特征以后，就可以选择任意的方式来拟合评分了。
我使用了两种方式，一个是上图中画出的将两个特征做向量乘法，将结果与真实评分做回归，采用MSE优化损失。因为本质上这是一个回归问题

另一种方式是，将两个特征作为输入，再次传入全连接层，输出一个值，将输出值回归到真实评分，采用MSE优化损失。

实际上第二个方式的MSE loss在0.8附近，第一个方式在1附近，5次迭代的结果。

    \subsubsection{嵌入矩阵 Embedding
matrix}\label{ux5d4cux5165ux77e9ux9635-embedding-matrix}

Word2Vec词嵌入矩阵：基于神经网络来训练得到的，每个词拥有一个向量来表征它，词和词之间可以通过向量来求相似性，并且向量是非离散的

初始化： 例如对于userid 有m个user
随机生成一个m*n维的矩阵，数字大小-1\textasciitilde{}1随机初始化

对于第i个人，对应到矩阵里的第i行作为嵌入向量embedding向量（相当于用一个向量代表一个user）

    \subsubsection{文本卷积网络}\label{ux6587ux672cux5377ux79efux7f51ux7edc}

网络看起来像下面这样

    \includegraphics{attachment:\%E5\%9B\%BE\%E7\%89\%87.png} 图片来自Kim
Yoon的论文：\href{https://arxiv.org/abs/1408.5882}{\texttt{Convolutional\ Neural\ Networks\ for\ Sentence\ Classification}}

将卷积神经网络用于文本的文章建议你阅读\href{http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/}{\texttt{Understanding\ Convolutional\ Neural\ Networks\ for\ NLP}}

    网络的第一层是词嵌入层，由每一个单词的嵌入向量组成的嵌入矩阵。下一层使用多个不同尺寸（窗口大小）的卷积核在嵌入矩阵上做卷积，窗口大小指的是每次卷积覆盖几个单词。这里跟对图像做卷积不太一样，图像的卷积通常用2x2、3x3、5x5之类的尺寸，而文本卷积要覆盖整个单词的嵌入向量，所以尺寸是（单词数，向量维度），比如每次滑动3个，4个或者5个单词。第三层网络是max
pooling得到一个长向量，最后使用dropout做正则化，最终得到了电影Title的特征。

    \subsection{辅助函数}\label{ux8f85ux52a9ux51fdux6570}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
         \PY{k+kn}{import} \PY{n+nn}{os}
         \PY{k+kn}{import} \PY{n+nn}{pickle}
         
         \PY{k}{def} \PY{n+nf}{save\PYZus{}params}\PY{p}{(}\PY{n}{params}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Save parameters to file}
         \PY{l+s+sd}{    将结果数据流写入到文件对象中}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{params}\PY{p}{,} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{params.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         
         
         \PY{k}{def} \PY{n+nf}{load\PYZus{}params}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Load parameters from file}
         \PY{l+s+sd}{    读取结果数据流}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{k}{return} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{params.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsection{编码实现}\label{ux7f16ux7801ux5b9eux73b0}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{c+c1}{\PYZsh{}嵌入矩阵的维度}
         \PY{n}{embed\PYZus{}dim} \PY{o}{=} \PY{l+m+mi}{32}
         \PY{c+c1}{\PYZsh{}用户ID个数}
         \PY{n}{uid\PYZus{}max} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{features}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} 6040}
         \PY{c+c1}{\PYZsh{}性别个数}
         \PY{n}{gender\PYZus{}max} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{features}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} 1 + 1 = 2}
         \PY{c+c1}{\PYZsh{}年龄类别个数}
         \PY{n}{age\PYZus{}max} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{features}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} 6 + 1 = 7}
         \PY{c+c1}{\PYZsh{}职业个数}
         \PY{n}{job\PYZus{}max} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{features}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1}\PY{c+c1}{\PYZsh{} 20 + 1 = 21}
         
         \PY{c+c1}{\PYZsh{}电影ID个数}
         \PY{n}{movie\PYZus{}id\PYZus{}max} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{features}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} 3952}
         \PY{c+c1}{\PYZsh{}电影类型个数}
         \PY{n}{movie\PYZus{}categories\PYZus{}max} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{genres2int}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} 18 + 1 = 19}
         \PY{c+c1}{\PYZsh{}电影名单词个数}
         \PY{n}{movie\PYZus{}title\PYZus{}max} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{title\PYZus{}set}\PY{p}{)} \PY{c+c1}{\PYZsh{} 5216}
         
         \PY{c+c1}{\PYZsh{}对电影类型嵌入向量做加和操作的标志，考虑过使用mean做平均，但是没实现mean}
         \PY{n}{combiner} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sum}\PY{l+s+s2}{\PYZdq{}}
         
         \PY{c+c1}{\PYZsh{}电影名长度}
         \PY{n}{sentences\PYZus{}size} \PY{o}{=} \PY{n}{title\PYZus{}count} \PY{c+c1}{\PYZsh{} = 15}
         \PY{c+c1}{\PYZsh{}文本卷积滑动窗口，分别滑动2, 3, 4, 5个单词}
         \PY{n}{window\PYZus{}sizes} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{\PYZcb{}}
         \PY{c+c1}{\PYZsh{}文本卷积核数量}
         \PY{n}{filter\PYZus{}num} \PY{o}{=} \PY{l+m+mi}{8}
         
         \PY{c+c1}{\PYZsh{}电影ID转下标的字典，数据集中电影ID跟下标不一致，比如第5行的数据电影ID不一定是5}
         \PY{n}{movieid2idx} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{val}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{:}\PY{n}{i} \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{val} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \subsubsection{超参}\label{ux8d85ux53c2}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{c+c1}{\PYZsh{} Number of Epochs}
         \PY{n}{num\PYZus{}epochs} \PY{o}{=} \PY{l+m+mi}{5}
         \PY{c+c1}{\PYZsh{} Batch Size}
         \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{256}
         
         \PY{n}{dropout\PYZus{}keep} \PY{o}{=} \PY{l+m+mf}{0.5}
         \PY{c+c1}{\PYZsh{} Learning Rate}
         \PY{n}{learning\PYZus{}rate} \PY{o}{=} \PY{l+m+mf}{0.0001}
         \PY{c+c1}{\PYZsh{} Show stats for every n number of batches}
         \PY{n}{show\PYZus{}every\PYZus{}n\PYZus{}batches} \PY{o}{=} \PY{l+m+mi}{20}
         
         \PY{n}{save\PYZus{}dir} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./save}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}


    \subsubsection{输入}\label{ux8f93ux5165}

    定义输入的占位符

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{c+c1}{\PYZsh{}生成基于占位符}
         \PY{c+c1}{\PYZsh{}[None, 1]默认输入任意数*1维的数据}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}inputs}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}tf.placeholder(dtype, shape=None, name=None)}
             \PY{n}{uid} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
             \PY{n}{movie\PYZus{}id} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}id}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{movie\PYZus{}categories} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}categories}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{movie\PYZus{}titles} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}titles}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{targets} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{targets}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{LearningRate} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LearningRate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{dropout\PYZus{}keep\PYZus{}prob} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dropout\PYZus{}keep\PYZus{}prob}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{uid}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{LearningRate}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob}
\end{Verbatim}


    \subsection{构建神经网络}\label{ux6784ux5efaux795eux7ecfux7f51ux7edc}

    \paragraph{定义User的嵌入矩阵}\label{ux5b9aux4e49userux7684ux5d4cux5165ux77e9ux9635}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{c+c1}{\PYZsh{}输入userid （6039）[None, 1]}
         \PY{c+c1}{\PYZsh{}返回对应id随机生成的嵌入向量embedding（32）}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}user\PYZus{}embedding}\PY{p}{(}\PY{n}{uid}\PY{p}{)}\PY{p}{:}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{user\PYZus{}embedding}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}tf.name\PYZus{}scope命名一个作用域}
                 \PY{c+c1}{\PYZsh{}可以让变量有相同的命名，只是限于tf.Variable的变量}
                 \PY{n}{uid\PYZus{}embed\PYZus{}matrix} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{random\PYZus{}uniform}\PY{p}{(}\PY{p}{[}\PY{n}{uid\PYZus{}max}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{]}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uid\PYZus{}embed\PYZus{}matrix}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}返回user人数*对应嵌入矩阵维度的矩阵（6040*32）}
                 \PY{c+c1}{\PYZsh{}产生于\PYZhy{}1和1之间，产生的值是均匀分布的。}
                 \PY{c+c1}{\PYZsh{}对userid进行嵌入向量处理     }
                 \PY{n}{uid\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{embedding\PYZus{}lookup}\PY{p}{(}\PY{n}{uid\PYZus{}embed\PYZus{}matrix}\PY{p}{,} \PY{n}{uid}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uid\PYZus{}embed\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}tf.nn.embedding\PYZus{}lookup函数的用法主要是选取一个张量里面索引对应的元素}
                 \PY{c+c1}{\PYZsh{}将生成的Variable常数矩阵输入，将uid与矩阵里的第i行的元素相对应相对应}
             \PY{k}{return} \PY{n}{uid\PYZus{}embed\PYZus{}layer}
\end{Verbatim}


    \paragraph{将User的嵌入矩阵一起全连接生成User的特征}\label{ux5c06userux7684ux5d4cux5165ux77e9ux9635ux4e00ux8d77ux5168ux8fdeux63a5ux751fux6210userux7684ux7279ux5f81}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{c+c1}{\PYZsh{}将useri的嵌入向量输（32）}
         \PY{c+c1}{\PYZsh{}输出特征向量，和特征向量经过200维输出平整化（200）}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}user\PYZus{}feature\PYZus{}layer}\PY{p}{(}\PY{n}{uid\PYZus{}embed\PYZus{}layer}\PY{p}{)}\PY{p}{:}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{user\PYZus{}fc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}第一层全连接，设定激活函数维relu}
                 \PY{c+c1}{\PYZsh{}对应大小维uid\PYZus{}embed\PYZus{}layer, embed\PYZus{}dim}
                 \PY{n}{uid\PYZus{}fc\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{dense}\PY{p}{(}\PY{n}{uid\PYZus{}embed\PYZus{}layer}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uid\PYZus{}fc\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}全连接层全连接层的每一个结点都与上一层的所有结点相连}
                 \PY{c+c1}{\PYZsh{}输入useid的嵌入向量（32），输出维度为嵌入矩阵的维度（32）}
                 
                 \PY{c+c1}{\PYZsh{}第二层全连接}
                 \PY{c+c1}{\PYZsh{}激活函数采用tanh与\PYZhy{}1到1对应}
                 \PY{n}{user\PYZus{}combine\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n}{uid\PYZus{}fc\PYZus{}layer}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{)}  \PY{c+c1}{\PYZsh{}(?, 1, 200)}
                 \PY{c+c1}{\PYZsh{}输入为上一层全连接层的输入（32），输出200维特征向量}
                 
                 \PY{c+c1}{\PYZsh{}两种类型本质上是相同的tf.contrib.layers.fully\PYZus{}connected和tf.layers.dense，后者称之为前者。然而，除了Keras之外，tf.contrib.fully\PYZus{}connected还增加了一些功能dense，特别是在参数中传递归一化和激活的可能性}
             
                 \PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{user\PYZus{}combine\PYZus{}layer}\PY{p}{,} \PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}reshape确认输出层大小维}
                 \PY{c+c1}{\PYZsh{}\PYZhy{}1，就是缺省值，数字由其他定，总数除以其他几个的乘积，}
             \PY{k}{return} \PY{n}{user\PYZus{}combine\PYZus{}layer}\PY{p}{,} \PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat}
\end{Verbatim}


    \paragraph{定义Movie
ID的嵌入矩阵}\label{ux5b9aux4e49movie-idux7684ux5d4cux5165ux77e9ux9635}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{c+c1}{\PYZsh{}对应movieid采用和userid 相同的方法（3952） [None, 1]}
         \PY{c+c1}{\PYZsh{}输入movieid 的索引}
         \PY{c+c1}{\PYZsh{}对应movie的嵌入向量（32）}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}movie\PYZus{}id\PYZus{}embed\PYZus{}layer}\PY{p}{(}\PY{n}{movie\PYZus{}id}\PY{p}{)}\PY{p}{:}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}embedding}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}matrix} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{random\PYZus{}uniform}\PY{p}{(}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}max}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{]}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}id\PYZus{}embed\PYZus{}matrix}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{embedding\PYZus{}lookup}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}matrix}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer}
\end{Verbatim}


    \paragraph{对电影类型的多个嵌入向量做加和}\label{ux5bf9ux7535ux5f71ux7c7bux578bux7684ux591aux4e2aux5d4cux5165ux5411ux91cfux505aux52a0ux548c}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{a} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{n}{a}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}38}]:} array([[1, 2, 3],
                [2, 3, 4]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{n}{a}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}39}]:} (2, 3)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{n}{a}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{keepdims}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}40}]:} (1, 3)
\end{Verbatim}
            
    \textbf{对axis=1的简单理解，对应axis=i,就会将shape的第i个形状参数置为1}
axis=0按列操作 axis=1按行操作

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{c+c1}{\PYZsh{}对电影类型的处理}
         \PY{c+c1}{\PYZsh{}输入电影类型属性（18类）[None, 18]}
         \PY{c+c1}{\PYZsh{}输出对应属性的嵌入向量（None, 1，32）}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}movie\PYZus{}categories\PYZus{}layers}\PY{p}{(}\PY{n}{movie\PYZus{}categories}\PY{p}{)}\PY{p}{:}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}categories\PYZus{}layers}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{n}{movie\PYZus{}categories\PYZus{}embed\PYZus{}matrix} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{random\PYZus{}uniform}\PY{p}{(}\PY{p}{[}\PY{n}{movie\PYZus{}categories\PYZus{}max}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{]}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}categories\PYZus{}embed\PYZus{}matrix}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}电影类型嵌入矩阵}
                 \PY{c+c1}{\PYZsh{}movie\PYZus{}categories\PYZus{}max* embed\PYZus{}dim ，电影类型的属性向量（18）*嵌入矩阵维度（32）}
                 \PY{n}{movie\PYZus{}categories\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{embedding\PYZus{}lookup}\PY{p}{(}\PY{n}{movie\PYZus{}categories\PYZus{}embed\PYZus{}matrix}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}categories\PYZus{}embed\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}从movie\PYZus{}categories\PYZus{}embed\PYZus{}matrix矩阵中抽取对应movie\PYZus{}categories(n, 18)的嵌入向量（n,18,  32）}
                 \PY{c+c1}{\PYZsh{}tf.nn.embedding\PYZus{}lookup理论上应该对应[None, 18]=[ [18个数字]]}
                 \PY{k}{if} \PY{n}{combiner} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
                     \PY{n}{movie\PYZus{}categories\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{movie\PYZus{}categories\PYZus{}embed\PYZus{}layer}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}对代表一个类型的嵌入向量求和movie\PYZus{}categories\PYZus{}embed\PYZus{}layer，将属性值对应的}
                 \PY{c+c1}{\PYZsh{}嵌入矩阵索引出来是一个（n，32）的矩阵，因为有多个类型嘛，我们要将这个矩阵求和，变成（n, 1，32）的向量。}
                 \PY{c+c1}{\PYZsh{}axis=1是对应第n个18维相加}
             \PY{c+c1}{\PYZsh{}     elif combiner == \PYZdq{}mean\PYZdq{}:}
         
             \PY{k}{return} \PY{n}{movie\PYZus{}categories\PYZus{}embed\PYZus{}layer}
\end{Verbatim}


    ** 占位符(分解认识)**

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{c+c1}{\PYZsh{}tf.nn.embedding\PYZus{}lookup测试}
         \PY{n}{t} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{int32}\PY{p}{,} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
         
         \PY{n}{c} \PY{o}{=}   \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{random\PYZus{}uniform}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{]}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{b} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{embedding\PYZus{}lookup}\PY{p}{(}\PY{n}{c}\PY{p}{,}\PY{n}{t}\PY{p}{)}
         \PY{n}{d} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{b}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
          
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{initialize\PYZus{}all\PYZus{}variables}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{b}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{t}\PY{p}{:} \PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{====}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{c}\PY{p}{)}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{====}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{d}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{t}\PY{p}{:} \PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:tensorflow:From <ipython-input-42-7125f58fd536>:7: calling reduce\_sum (from tensorflow.python.ops.math\_ops) with keep\_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep\_dims is deprecated, use keepdims instead
WARNING:tensorflow:From C:\textbackslash{}Users\textbackslash{}tree\textbackslash{}AppData\textbackslash{}Local\textbackslash{}conda\textbackslash{}conda\textbackslash{}envs\textbackslash{}tensorflow\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}tensorflow\textbackslash{}python\textbackslash{}util\textbackslash{}tf\_should\_use.py:118: initialize\_all\_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global\_variables\_initializer` instead.
[[[-0.92541075 -0.7655592   0.07017684]
  [ 0.84239125 -0.2345376   0.5002718 ]
  [-0.07166004  0.5848782  -0.84181666]
  [-0.07166004  0.5848782  -0.84181666]
  [-0.07166004  0.5848782  -0.84181666]]]
====
[[-0.07166004  0.5848782  -0.84181666]
 [-0.92541075 -0.7655592   0.07017684]
 [ 0.84239125 -0.2345376   0.5002718 ]
 [-0.6961844  -0.0888288  -0.17667103]
 [ 0.6390643  -0.65862226 -0.1552031 ]]
====
[[[-0.29799962  0.7545378  -1.9550014 ]]]

    \end{Verbatim}

    \paragraph{Movie
Title的文本卷积网络实现}\label{movie-titleux7684ux6587ux672cux5377ux79efux7f51ux7edcux5b9eux73b0}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{c+c1}{\PYZsh{}文本处理}
         \PY{c+c1}{\PYZsh{}输入电影标题的文字list}
         \PY{c+c1}{\PYZsh{}输出对应经过文字卷积处理的1*1*32向量}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}movie\PYZus{}cnn\PYZus{}layer}\PY{p}{(}\PY{n}{movie\PYZus{}titles}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}从嵌入矩阵中得到电影名对应的各个单词的嵌入向量}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}embedding}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{n}{movie\PYZus{}title\PYZus{}embed\PYZus{}matrix} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{random\PYZus{}uniform}\PY{p}{(}\PY{p}{[}\PY{n}{movie\PYZus{}title\PYZus{}max}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{]}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}title\PYZus{}embed\PYZus{}matrix}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}电影标题title单词出现中类（5216）*嵌入维度（32）}
                 \PY{n}{movie\PYZus{}title\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{embedding\PYZus{}lookup}\PY{p}{(}\PY{n}{movie\PYZus{}title\PYZus{}embed\PYZus{}matrix}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}title\PYZus{}embed\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}对应标题文字，对应的标题嵌入词向量（None, 15, 32）}
                 \PY{n}{movie\PYZus{}title\PYZus{}embed\PYZus{}layer\PYZus{}expand} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{movie\PYZus{}title\PYZus{}embed\PYZus{}layer}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}在第axis位置增加一个维度，在后面加上一个维度（None, 15, 32, 1）}
             
             \PY{c+c1}{\PYZsh{}对文本嵌入层使用不同尺寸的卷积核做卷积和最大池化}
             \PY{c+c1}{\PYZsh{}文本嵌入层输入一个（32，1）维的嵌入向量}
             \PY{n}{pool\PYZus{}layer\PYZus{}lst} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{window\PYZus{}size} \PY{o+ow}{in} \PY{n}{window\PYZus{}sizes}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} window\PYZus{}sizes分别以\PYZob{}2, 3, 4, 5\PYZcb{}}
                 \PY{c+c1}{\PYZsh{}每次滑动2， 3个，4个或者5个单词}
                 \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}txt\PYZus{}conv\PYZus{}maxpool\PYZus{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{window\PYZus{}size}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                     \PY{n}{filter\PYZus{}weights} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{truncated\PYZus{}normal}\PY{p}{(}\PY{p}{[}\PY{n}{window\PYZus{}size}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{filter\PYZus{}num}\PY{p}{]}\PY{p}{,}\PY{n}{stddev}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{,}\PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{filter\PYZus{}weights}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}生成卷积核的权重（正太分布随机初始化卷积核权重）}
                     \PY{c+c1}{\PYZsh{}tf.truncated\PYZus{}normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)}
                     \PY{c+c1}{\PYZsh{}mean: 正态分布的均值（默认为0）。stddev: 正态分布的标准差。}
                     \PY{c+c1}{\PYZsh{}[window\PYZus{}size, embed\PYZus{}dim, 1, filter\PYZus{}num]=shape对应输出的张量大小为window\PYZus{}size（2/3/4/5）*embed\PYZus{}dim（32）*1*filter\PYZus{}num（8）}
                     \PY{c+c1}{\PYZsh{}从截断的正态分布中输出随机值。 生成的值服从具有指定平均值和标准偏差的正态分布，如果生成的值大于平均值2个标准偏差的值则丢弃重新选择。}
                     \PY{n}{filter\PYZus{}bias} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{constant}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{[}\PY{n}{filter\PYZus{}num}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{filter\PYZus{}bias}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}生成卷积核的偏差shape=[filter\PYZus{}num]对应卷积核数量=8}
                     \PY{c+c1}{\PYZsh{}当window\PYZus{}size=2}
                     \PY{c+c1}{\PYZsh{}对2*32*1*8}
                     
                     \PY{n}{conv\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{conv2d}\PY{p}{(}\PY{n}{movie\PYZus{}title\PYZus{}embed\PYZus{}layer\PYZus{}expand}\PY{p}{,} \PY{n}{filter\PYZus{}weights}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VALID}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{conv\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}tf.nn.conv2d实现卷积}
                     \PY{c+c1}{\PYZsh{}tf.nn.conv2d(input, filter, strides, padding, use\PYZus{}cudnn\PYZus{}on\PYZus{}gpu=None, name=None)}
                     \PY{c+c1}{\PYZsh{}输入movie\PYZus{}title\PYZus{}embed\PYZus{}layer\PYZus{}expand，电影文字的32维嵌入向量（None, 15, 32, 1）}
                     \PY{c+c1}{\PYZsh{}filter\PYZus{}weights卷积核权重， 例如2*32*1*8}
                     \PY{c+c1}{\PYZsh{}strides=[1,1,1,1]：卷积时在图像每一维的步长，这是一个一维的向量，长度4、、}
                     \PY{c+c1}{\PYZsh{}conv\PYZus{}layer 输出维度维}
                     \PY{c+c1}{\PYZsh{}（None, 15, 32, 1）卷积2*32*1*8 padding=\PYZdq{}VALID\PYZdq{}输出14*1*1*8（filter）}
                     \PY{c+c1}{\PYZsh{}（None, 15, 32, 1）卷积3*32*1*8 padding=\PYZdq{}VALID\PYZdq{}输出13*1*1*8（filter）}
                     
                     \PY{n}{relu\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{bias\PYZus{}add}\PY{p}{(}\PY{n}{conv\PYZus{}layer}\PY{p}{,}\PY{n}{filter\PYZus{}bias}\PY{p}{)}\PY{p}{,} \PY{n}{name} \PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}conv\PYZus{}layer加上偏差和激活函数relu}
                     
                     \PY{n}{maxpool\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{max\PYZus{}pool}\PY{p}{(}\PY{n}{relu\PYZus{}layer}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{n}{sentences\PYZus{}size} \PY{o}{\PYZhy{}} \PY{n}{window\PYZus{}size} \PY{o}{+} \PY{l+m+mi}{1} \PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{VALID}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{maxpool\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}最大池化}
                     \PY{c+c1}{\PYZsh{}\PYZdq{}VALID\PYZdq{} = without padding:不在卷积边缘扩充}
                     \PY{c+c1}{\PYZsh{}[1,sentences\PYZus{}size（15）\PYZhy{} window\PYZus{}size（2） + 1 ,1,1]}
                      \PY{c+c1}{\PYZsh{}14*1*1*8池化卷积1*14*1*1 输出1*1*1*8}
                     
                     \PY{n}{pool\PYZus{}layer\PYZus{}lst}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{maxpool\PYZus{}layer}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}pool\PYZus{}layer\PYZus{}lst为对应window\PYZus{}sizes分别以\PYZob{}2, 3, 4, 5\PYZcb{}的层的集合，输出1*1*1*8}
         
             \PY{c+c1}{\PYZsh{}Dropout层（过拟合）}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pool\PYZus{}dropout}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{n}{pool\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{n}{pool\PYZus{}layer\PYZus{}lst}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{n}{name} \PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pool\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{} tf.concat(values, axis,name=\PYZsq{}concat)values应该是一个tensor的list或者tuple。axis则是我们想要连接的维度。}
                 \PY{c+c1}{\PYZsh{}对应第三个维度将由window\PYZus{}sizes分别以\PYZob{}2, 3, 4, 5\PYZcb{}输出的1*1*1*8相连接的1*1*4*8}
                 
                 \PY{n}{max\PYZus{}num} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{window\PYZus{}sizes}\PY{p}{)} \PY{o}{*} \PY{n}{filter\PYZus{}num}\PY{c+c1}{\PYZsh{}4*8的矩阵}
                 \PY{n}{pool\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{pool\PYZus{}layer} \PY{p}{,} \PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{max\PYZus{}num}\PY{p}{]}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pool\PYZus{}layer\PYZus{}flat}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{}fallten归一化1*1*32}
             
                 \PY{n}{dropout\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{dropout}\PY{p}{(}\PY{n}{pool\PYZus{}layer\PYZus{}flat}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dropout\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{}以dropout\PYZus{}keep\PYZus{}prob概率进行dropout}
                 \PY{c+c1}{\PYZsh{}每个神经元都要参加运算，但其输出要乘以概率p}
             \PY{k}{return} \PY{n}{pool\PYZus{}layer\PYZus{}flat}\PY{p}{,} \PY{n}{dropout\PYZus{}layer}
\end{Verbatim}


    \paragraph{将Movie的各个层一起做全连接}\label{ux5c06movieux7684ux5404ux4e2aux5c42ux4e00ux8d77ux505aux5168ux8fdeux63a5}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{c+c1}{\PYZsh{}电影id的对应嵌入向量}
         \PY{c+c1}{\PYZsh{}经过两层全连接层}
         \PY{c+c1}{\PYZsh{}输出电影对应的200维特征向量}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}movie\PYZus{}feature\PYZus{}layer}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer}\PY{p}{)}\PY{p}{:}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}fc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}第一层全连接}
                 \PY{n}{movie\PYZus{}id\PYZus{}fc\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{dense}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer}\PY{p}{,} \PY{n}{embed\PYZus{}dim}\PY{p}{,} \PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}id\PYZus{}fc\PYZus{}layer}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{relu}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{}第二层全连接}
                 \PY{n}{movie\PYZus{}combine\PYZus{}layer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{contrib}\PY{o}{.}\PY{n}{layers}\PY{o}{.}\PY{n}{fully\PYZus{}connected}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}fc\PYZus{}layer}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{)}  \PY{c+c1}{\PYZsh{}(?, 1, 200)}
             
                 \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{movie\PYZus{}combine\PYZus{}layer}\PY{p}{,} \PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{)}
             \PY{k}{return} \PY{n}{movie\PYZus{}combine\PYZus{}layer}\PY{p}{,} \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat}
\end{Verbatim}


    \subsection{构建计算图}\label{ux6784ux5efaux8ba1ux7b97ux56fe}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{c+c1}{\PYZsh{}利用tf.reset\PYZus{}default\PYZus{}graph()重置清空default graph计算图以及nodes节点}
         \PY{n}{tf}\PY{o}{.}\PY{n}{reset\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}声明一个计算图}
         \PY{n}{train\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}
         \PY{k}{with} \PY{n}{train\PYZus{}graph}\PY{o}{.}\PY{n}{as\PYZus{}default}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}获取输入占位符}
             \PY{n}{uid}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob} \PY{o}{=} \PY{n}{get\PYZus{}inputs}\PY{p}{(}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}\PYZsh{}返回对应id随机生成的嵌入向量embedding（32）}
             \PY{n}{uid\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{get\PYZus{}user\PYZus{}embedding}\PY{p}{(}\PY{n}{uid}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}得到对应id的用户特征}
             \PY{n}{user\PYZus{}combine\PYZus{}layer}\PY{p}{,} \PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{get\PYZus{}user\PYZus{}feature\PYZus{}layer}\PY{p}{(}\PY{n}{uid\PYZus{}embed\PYZus{}layer}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}获取电影ID的嵌入向量（32）}
             \PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer} \PY{o}{=} \PY{n}{get\PYZus{}movie\PYZus{}id\PYZus{}embed\PYZus{}layer}\PY{p}{(}\PY{n}{movie\PYZus{}id}\PY{p}{)}
             
         \PY{c+c1}{\PYZsh{}     获取电影类型的嵌入向量}
         \PY{c+c1}{\PYZsh{}     movie\PYZus{}categories\PYZus{}embed\PYZus{}layer = get\PYZus{}movie\PYZus{}categories\PYZus{}layers(movie\PYZus{}categories)}
         \PY{c+c1}{\PYZsh{}     获取电影名的特征向量}
         \PY{c+c1}{\PYZsh{}     pool\PYZus{}layer\PYZus{}flat, dropout\PYZus{}layer = get\PYZus{}movie\PYZus{}cnn\PYZus{}layer(movie\PYZus{}titles)}
             
             \PY{c+c1}{\PYZsh{}得到电影特征输出电影对应的200维特征向量}
             \PY{n}{movie\PYZus{}combine\PYZus{}layer}\PY{p}{,} \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{get\PYZus{}movie\PYZus{}feature\PYZus{}layer}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}embed\PYZus{}layer}\PY{p}{)}
             
             
             \PY{c+c1}{\PYZsh{}计算出评分，要注意两个不同的方案，inference的名字（name值）是不一样的，后面做推荐时要根据name取得tensor}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{inference}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}将用户特征和电影特征作为输入，经过全连接，输出一个值的方案}
         \PY{c+c1}{\PYZsh{}         inference\PYZus{}layer = tf.concat([user\PYZus{}combine\PYZus{}layer\PYZus{}flat, movie\PYZus{}combine\PYZus{}layer\PYZus{}flat], 1)  \PYZsh{}(?, 200)}
         \PY{c+c1}{\PYZsh{}         inference = tf.layers.dense(inference\PYZus{}layer, 1,}
         \PY{c+c1}{\PYZsh{}                                     kernel\PYZus{}initializer=tf.truncated\PYZus{}normal\PYZus{}initializer(stddev=0.01), }
         \PY{c+c1}{\PYZsh{}                                     kernel\PYZus{}regularizer=tf.nn.l2\PYZus{}loss, name=\PYZdq{}inference\PYZdq{})}
                 \PY{c+c1}{\PYZsh{}简单的将用户特征和电影特征做矩阵乘法得到一个预测评分}
         \PY{c+c1}{\PYZsh{}        inference = tf.matmul(user\PYZus{}combine\PYZus{}layer\PYZus{}flat, tf.transpose(movie\PYZus{}combine\PYZus{}layer\PYZus{}flat))}
                 \PY{n}{inference} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{*} \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{}直接相乘}
                 \PY{c+c1}{\PYZsh{} \PYZsh{}得到对应id的用户特征200维*得到电影特征输出电影对应的200维特征向量}
                 \PY{n}{inference} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{inference}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}在第axis=1位置增加一个维度}
         
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{name\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} MSE损失，将计算值回归到评分}
                 \PY{n}{cost} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{losses}\PY{o}{.}\PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{targets}\PY{p}{,} \PY{n}{inference} \PY{p}{)}
                 \PY{n}{loss} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{cost}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}loss详见求平均}
             \PY{c+c1}{\PYZsh{} 优化损失 }
         \PY{c+c1}{\PYZsh{}     train\PYZus{}op = tf.train.AdamOptimizer(lr).minimize(loss)  \PYZsh{}cost}
             \PY{n}{global\PYZus{}step} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{global\PYZus{}step}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{trainable}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
             \PY{n}{optimizer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{AdamOptimizer}\PY{p}{(}\PY{n}{lr}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}lr= 0.11的Adam优化算法：是一个寻找全局最优点的优化算法，引入了二次方梯度校正。优化器}
             \PY{n}{gradients} \PY{o}{=} \PY{n}{optimizer}\PY{o}{.}\PY{n}{compute\PYZus{}gradients}\PY{p}{(}\PY{n}{loss}\PY{p}{)}  
             \PY{c+c1}{\PYZsh{}对var\PYZus{}list中的变量计算loss的梯度该函数为函数minimize()的第一部分，返回一个以元组(gradient, variable)组成的列表}
             \PY{c+c1}{\PYZsh{}optimize， 计算cost中可训练的var\PYZus{}list中的梯度}
             \PY{n}{train\PYZus{}op} \PY{o}{=} \PY{n}{optimizer}\PY{o}{.}\PY{n}{apply\PYZus{}gradients}\PY{p}{(}\PY{n}{gradients}\PY{p}{,} \PY{n}{global\PYZus{}step}\PY{o}{=}\PY{n}{global\PYZus{}step}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}optimize，optimizer.apply\PYZus{}gradients利用梯度进行更新}
             \PY{c+c1}{\PYZsh{}将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global\PYZus{}step做自增操作}
             
\end{Verbatim}


    \subsection{取得batch}\label{ux53d6ux5f97batch}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{c+c1}{\PYZsh{}根据batch分布投入数据训练}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}batches}\PY{p}{(}\PY{n}{Xs}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
             \PY{k}{for} \PY{n}{start} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{Xs}\PY{p}{)}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                 \PY{n}{end} \PY{o}{=} \PY{n+nb}{min}\PY{p}{(}\PY{n}{start} \PY{o}{+} \PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{Xs}\PY{p}{)}\PY{p}{)}
                 \PY{k}{yield} \PY{n}{Xs}\PY{p}{[}\PY{n}{start}\PY{p}{:}\PY{n}{end}\PY{p}{]}\PY{p}{,} \PY{n}{ys}\PY{p}{[}\PY{n}{start}\PY{p}{:}\PY{n}{end}\PY{p}{]}
                 \PY{c+c1}{\PYZsh{}yield的功能类似于return，但是不同之处在于它返回的是生成器}
                 \PY{c+c1}{\PYZsh{}生成器是通过一个或多个yield表达式构成的函数，每一个生成器都是一个迭代器（但是迭代器不一定是生成器）}
\end{Verbatim}


    \subsection{训练网络}\label{ux8badux7ec3ux7f51ux7edc}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
         \PY{o}{\PYZpc{}}\PY{k}{config} InlineBackend.figure\PYZus{}format = \PYZsq{}retina\PYZsq{}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{time}
         \PY{k+kn}{import} \PY{n+nn}{datetime}
         
         \PY{n}{losses} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{p}{]}\PY{p}{\PYZcb{}}
         
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{train\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}调用设计好的train\PYZus{}graph计算图}
             
             \PY{c+c1}{\PYZsh{}搜集数据给tensorBoard用}
             \PY{c+c1}{\PYZsh{} Keep track of gradient values and sparsity}
             \PY{n}{grad\PYZus{}summaries} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{g}\PY{p}{,} \PY{n}{v} \PY{o+ow}{in} \PY{n}{gradients}\PY{p}{:} \PY{c+c1}{\PYZsh{}读取梯度，gradients维返回一个以元组(gradient, variable)组成的列表}
                 \PY{k}{if} \PY{n}{g} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:} \PY{c+c1}{\PYZsh{}如果梯度存在， }
                     \PY{n}{grad\PYZus{}hist\PYZus{}summary} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{histogram}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{/grad/hist}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{v}\PY{o}{.}\PY{n}{name}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{g}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}tf.summary.histogram(): 输出一个直方图的Summary protocol buffer .将梯度输出为直方图，}
                     \PY{n}{sparsity\PYZus{}summary} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{scalar}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{/grad/sparsity}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{v}\PY{o}{.}\PY{n}{name}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{nn}\PY{o}{.}\PY{n}{zero\PYZus{}fraction}\PY{p}{(}\PY{n}{g}\PY{p}{)}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}将输入的Tensor中0元素在所有元素中所占的比例计算并返回，因为relu激活函数有时会大面积的将输入参数设为0，所以此函数可以有效衡量relu激活函数的有效性}
                     \PY{c+c1}{\PYZsh{}tf.summary.scalar用来显示标量信息}
                     \PY{n}{grad\PYZus{}summaries}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{grad\PYZus{}hist\PYZus{}summary}\PY{p}{)}
                     \PY{n}{grad\PYZus{}summaries}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{sparsity\PYZus{}summary}\PY{p}{)}
             \PY{n}{grad\PYZus{}summaries\PYZus{}merged} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{grad\PYZus{}summaries}\PY{p}{)}
                 
                 
             \PY{c+c1}{\PYZsh{} Output directory for models and summaries}
             \PY{n}{timestamp} \PY{o}{=} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{int}\PY{p}{(}\PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{out\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{abspath}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{curdir}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{runs}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{timestamp}\PY{p}{)}\PY{p}{)}\PY{c+c1}{\PYZsh{}对应时间的文件写入}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Writing to }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{out\PYZus{}dir}\PY{p}{)}\PY{p}{)}\PY{c+c1}{\PYZsh{}写入文件到。。。}
              
             \PY{c+c1}{\PYZsh{} Summaries for loss and accuracy}
             \PY{n}{loss\PYZus{}summary} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{scalar}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{loss}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}\PYZsh{}tf.summary.scalar用来显示标量信息}
         
             \PY{c+c1}{\PYZsh{} Train Summaries训练集}
             \PY{n}{train\PYZus{}summary\PYZus{}op} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{p}{[}\PY{n}{loss\PYZus{}summary}\PY{p}{,} \PY{n}{grad\PYZus{}summaries\PYZus{}merged}\PY{p}{]}\PY{p}{)}
             \PY{n}{train\PYZus{}summary\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{out\PYZus{}dir}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{summaries}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{train\PYZus{}summary\PYZus{}writer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{FileWriter}\PY{p}{(}\PY{n}{train\PYZus{}summary\PYZus{}dir}\PY{p}{,} \PY{n}{sess}\PY{o}{.}\PY{n}{graph}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Inference summaries测试集}
             \PY{n}{inference\PYZus{}summary\PYZus{}op} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{p}{[}\PY{n}{loss\PYZus{}summary}\PY{p}{]}\PY{p}{)}
             \PY{n}{inference\PYZus{}summary\PYZus{}dir} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{out\PYZus{}dir}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{summaries}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{inference}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{inference\PYZus{}summary\PYZus{}writer} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{summary}\PY{o}{.}\PY{n}{FileWriter}\PY{p}{(}\PY{n}{inference\PYZus{}summary\PYZus{}dir}\PY{p}{,} \PY{n}{sess}\PY{o}{.}\PY{n}{graph}\PY{p}{)}
         
             
             
             \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{global\PYZus{}variables\PYZus{}initializer}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{c+c1}{\PYZsh{}初始化模型的参数}
             \PY{n}{saver} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{Saver}\PY{p}{(}\PY{p}{)}
             \PY{k}{for} \PY{n}{epoch\PYZus{}i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{)}\PY{p}{:}
                 
                 \PY{c+c1}{\PYZsh{}将数据集分成训练集和测试集，随机种子不固定}
                 \PY{n}{train\PYZus{}X}\PY{p}{,}\PY{n}{test\PYZus{}X}\PY{p}{,} \PY{n}{train\PYZus{}y}\PY{p}{,} \PY{n}{test\PYZus{}y} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{features}\PY{p}{,}  
                                                                    \PY{n}{targets\PYZus{}values}\PY{p}{,}  
                                                                    \PY{n}{test\PYZus{}size} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{,}  
                                                                    \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}  
                 
                 \PY{c+c1}{\PYZsh{}设定训练集和测试集的batch迭代生成器}
                 \PY{n}{train\PYZus{}batches} \PY{o}{=} \PY{n}{get\PYZus{}batches}\PY{p}{(}\PY{n}{train\PYZus{}X}\PY{p}{,} \PY{n}{train\PYZus{}y}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}
                 \PY{n}{test\PYZus{}batches} \PY{o}{=} \PY{n}{get\PYZus{}batches}\PY{p}{(}\PY{n}{test\PYZus{}X}\PY{p}{,} \PY{n}{test\PYZus{}y}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}
             
                 \PY{c+c1}{\PYZsh{}训练的迭代，保存训练损失}
                 \PY{k}{for} \PY{n}{batch\PYZus{}i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}X}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                     \PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n+nb}{next}\PY{p}{(}\PY{n}{train\PYZus{}batches}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}不断输入batch的数据}
                     
                     \PY{c+c1}{\PYZsh{}初始化一个batch\PYZus{}size的类别向量}
                     \PY{n}{categories} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{]}\PY{p}{)}
                     \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                         \PY{n}{categories}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                         \PY{c+c1}{\PYZsh{}axis = 1 对用按索引axis}
                         \PY{c+c1}{\PYZsh{}对每一个向量设定提取指定索引位置的数据,并以一维数组或者矩阵返回(主要取决axis)}
                         \PY{c+c1}{\PYZsh{}类别向量对应特征的第6列}
         
                     \PY{n}{titles} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n}{sentences\PYZus{}size}\PY{p}{]}\PY{p}{)}
                     \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                         \PY{n}{titles}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                         \PY{c+c1}{\PYZsh{}titles对应特征第5列}
         
                     \PY{n}{feed} \PY{o}{=} \PY{p}{\PYZob{}}
                         \PY{n}{uid}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                         \PY{n}{movie\PYZus{}id}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                         \PY{n}{movie\PYZus{}categories}\PY{p}{:} \PY{n}{categories}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(6,1)}
                         \PY{n}{movie\PYZus{}titles}\PY{p}{:} \PY{n}{titles}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(5,1)}
                         \PY{n}{targets}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                         \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{:} \PY{n}{dropout\PYZus{}keep}\PY{p}{,} \PY{c+c1}{\PYZsh{}dropout\PYZus{}keep}
                         \PY{n}{lr}\PY{p}{:} \PY{n}{learning\PYZus{}rate}\PY{p}{\PYZcb{}}
         
                     \PY{n}{step}\PY{p}{,} \PY{n}{train\PYZus{}loss}\PY{p}{,} \PY{n}{summaries}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{global\PYZus{}step}\PY{p}{,} \PY{n}{loss}\PY{p}{,} \PY{n}{train\PYZus{}summary\PYZus{}op}\PY{p}{,} \PY{n}{train\PYZus{}op}\PY{p}{]}\PY{p}{,} \PY{n}{feed}\PY{p}{)}  \PY{c+c1}{\PYZsh{}cost}
                     \PY{c+c1}{\PYZsh{}loss}
                     \PY{c+c1}{\PYZsh{}global\PYZus{}step次数}
                     \PY{c+c1}{\PYZsh{}train\PYZus{}summary\PYZus{}op = tf.summary.merge([loss\PYZus{}summary, grad\PYZus{}summaries\PYZus{}merged])loss，梯度，}
                     \PY{c+c1}{\PYZsh{} train\PYZus{}op = optimizer.apply\PYZus{}gradients(gradients, global\PYZus{}step=global\PYZus{}step)优化器将梯度进行训练的值}
                     \PY{n}{losses}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{train\PYZus{}loss}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}train\PYZus{}loss将每一次batch\PYZus{}i的loss存储}
                     \PY{n}{train\PYZus{}summary\PYZus{}writer}\PY{o}{.}\PY{n}{add\PYZus{}summary}\PY{p}{(}\PY{n}{summaries}\PY{p}{,} \PY{n}{step}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
                     
                     \PY{c+c1}{\PYZsh{} Show every \PYZlt{}show\PYZus{}every\PYZus{}n\PYZus{}batches\PYZgt{} batches}
                     \PY{k}{if} \PY{p}{(}\PY{n}{epoch\PYZus{}i} \PY{o}{*} \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}X}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)} \PY{o}{+} \PY{n}{batch\PYZus{}i}\PY{p}{)} \PY{o}{\PYZpc{}} \PY{n}{show\PYZus{}every\PYZus{}n\PYZus{}batches} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                         \PY{n}{time\PYZus{}str} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{isoformat}\PY{p}{(}\PY{p}{)}
                         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: Epoch }\PY{l+s+si}{\PYZob{}:\PYZgt{}3\PYZcb{}}\PY{l+s+s1}{ Batch }\PY{l+s+si}{\PYZob{}:\PYZgt{}4\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{   train\PYZus{}loss = }\PY{l+s+si}{\PYZob{}:.3f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
                             \PY{n}{time\PYZus{}str}\PY{p}{,}
                             \PY{n}{epoch\PYZus{}i}\PY{p}{,}
                             \PY{n}{batch\PYZus{}i}\PY{p}{,}
                             \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{train\PYZus{}X}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{,}
                             \PY{n}{train\PYZus{}loss}\PY{p}{)}\PY{p}{)}
                         
                 \PY{c+c1}{\PYZsh{}使用测试数据的迭代}
                 \PY{k}{for} \PY{n}{batch\PYZus{}i}  \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{test\PYZus{}X}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                     \PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n+nb}{next}\PY{p}{(}\PY{n}{test\PYZus{}batches}\PY{p}{)}
                     
                     \PY{n}{categories} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{]}\PY{p}{)}
                     \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                         \PY{n}{categories}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{n}{i}\PY{p}{]} 
                     \PY{c+c1}{\PYZsh{}categories类别属性向量}
         
                     \PY{n}{titles} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{n}{sentences\PYZus{}size}\PY{p}{]}\PY{p}{)}
                     \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                         \PY{n}{titles}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{n}{i}\PY{p}{]}
                   
         
                     \PY{n}{feed} \PY{o}{=} \PY{p}{\PYZob{}}
                         \PY{n}{uid}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                         \PY{n}{movie\PYZus{}id}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                         \PY{n}{movie\PYZus{}categories}\PY{p}{:} \PY{n}{categories}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(6,1)}
                         \PY{n}{movie\PYZus{}titles}\PY{p}{:} \PY{n}{titles}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(5,1)}
                         \PY{n}{targets}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{y}\PY{p}{,} \PY{p}{[}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                         \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{,}
                         \PY{n}{lr}\PY{p}{:} \PY{n}{learning\PYZus{}rate}\PY{p}{\PYZcb{}}
                     
                     \PY{n}{step}\PY{p}{,} \PY{n}{test\PYZus{}loss}\PY{p}{,} \PY{n}{summaries} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{global\PYZus{}step}\PY{p}{,} \PY{n}{loss}\PY{p}{,} \PY{n}{inference\PYZus{}summary\PYZus{}op}\PY{p}{]}\PY{p}{,} \PY{n}{feed}\PY{p}{)}  \PY{c+c1}{\PYZsh{}cost}
         
                     \PY{c+c1}{\PYZsh{}保存测试损失}
                     \PY{n}{losses}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{test\PYZus{}loss}\PY{p}{)}
                     \PY{n}{inference\PYZus{}summary\PYZus{}writer}\PY{o}{.}\PY{n}{add\PYZus{}summary}\PY{p}{(}\PY{n}{summaries}\PY{p}{,} \PY{n}{step}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
         
                     \PY{n}{time\PYZus{}str} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{isoformat}\PY{p}{(}\PY{p}{)}
                     \PY{k}{if} \PY{p}{(}\PY{n}{epoch\PYZus{}i} \PY{o}{*} \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{test\PYZus{}X}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)} \PY{o}{+} \PY{n}{batch\PYZus{}i}\PY{p}{)} \PY{o}{\PYZpc{}} \PY{n}{show\PYZus{}every\PYZus{}n\PYZus{}batches} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{: Epoch }\PY{l+s+si}{\PYZob{}:\PYZgt{}3\PYZcb{}}\PY{l+s+s1}{ Batch }\PY{l+s+si}{\PYZob{}:\PYZgt{}4\PYZcb{}}\PY{l+s+s1}{/}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{   test\PYZus{}loss = }\PY{l+s+si}{\PYZob{}:.3f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}
                             \PY{n}{time\PYZus{}str}\PY{p}{,}
                             \PY{n}{epoch\PYZus{}i}\PY{p}{,}
                             \PY{n}{batch\PYZus{}i}\PY{p}{,}
                             \PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{test\PYZus{}X}\PY{p}{)} \PY{o}{/}\PY{o}{/} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{,}
                             \PY{n}{test\PYZus{}loss}\PY{p}{)}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Save Model}
             \PY{n}{saver}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{save\PYZus{}dir}\PY{p}{)}  \PY{c+c1}{\PYZsh{}, global\PYZus{}step=epoch\PYZus{}i}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model Trained and Saved}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Writing to C:\textbackslash{}Users\textbackslash{}tree\textbackslash{}PycharmProjects\textbackslash{}recommendation\textbackslash{}SecondWeek1202\textbackslash{}runs\textbackslash{}1544253954

2018-12-08T15:25:56.328152: Epoch   0 Batch    0/3125   train\_loss = 13.566
2018-12-08T15:25:56.650505: Epoch   0 Batch   20/3125   train\_loss = 10.295
2018-12-08T15:25:56.980273: Epoch   0 Batch   40/3125   train\_loss = 7.102
2018-12-08T15:25:57.300651: Epoch   0 Batch   60/3125   train\_loss = 4.327
2018-12-08T15:25:57.630249: Epoch   0 Batch   80/3125   train\_loss = 3.053
2018-12-08T15:25:57.960353: Epoch   0 Batch  100/3125   train\_loss = 2.444
2018-12-08T15:25:58.280442: Epoch   0 Batch  120/3125   train\_loss = 2.350
2018-12-08T15:25:58.600715: Epoch   0 Batch  140/3125   train\_loss = 2.500
2018-12-08T15:25:58.930528: Epoch   0 Batch  160/3125   train\_loss = 1.893
2018-12-08T15:25:59.251923: Epoch   0 Batch  180/3125   train\_loss = 2.005
2018-12-08T15:25:59.570326: Epoch   0 Batch  200/3125   train\_loss = 2.246
2018-12-08T15:25:59.917268: Epoch   0 Batch  220/3125   train\_loss = 1.964
2018-12-08T15:26:00.242536: Epoch   0 Batch  240/3125   train\_loss = 1.965
2018-12-08T15:26:00.565462: Epoch   0 Batch  260/3125   train\_loss = 1.935
2018-12-08T15:26:00.890369: Epoch   0 Batch  280/3125   train\_loss = 2.027
2018-12-08T15:26:01.214342: Epoch   0 Batch  300/3125   train\_loss = 2.008
2018-12-08T15:26:01.551393: Epoch   0 Batch  320/3125   train\_loss = 1.800
2018-12-08T15:26:01.861147: Epoch   0 Batch  340/3125   train\_loss = 1.933
2018-12-08T15:26:02.190310: Epoch   0 Batch  360/3125   train\_loss = 1.876
2018-12-08T15:26:02.510402: Epoch   0 Batch  380/3125   train\_loss = 1.823
2018-12-08T15:26:02.840719: Epoch   0 Batch  400/3125   train\_loss = 1.705
2018-12-08T15:26:03.169579: Epoch   0 Batch  420/3125   train\_loss = 1.708
2018-12-08T15:26:03.500315: Epoch   0 Batch  440/3125   train\_loss = 1.603
2018-12-08T15:26:03.820498: Epoch   0 Batch  460/3125   train\_loss = 1.613
2018-12-08T15:26:04.154756: Epoch   0 Batch  480/3125   train\_loss = 1.623
2018-12-08T15:26:04.490305: Epoch   0 Batch  500/3125   train\_loss = 1.485
2018-12-08T15:26:04.810231: Epoch   0 Batch  520/3125   train\_loss = 1.701
2018-12-08T15:26:05.159972: Epoch   0 Batch  540/3125   train\_loss = 1.630
2018-12-08T15:26:05.490387: Epoch   0 Batch  560/3125   train\_loss = 1.810
2018-12-08T15:26:05.819594: Epoch   0 Batch  580/3125   train\_loss = 1.748
2018-12-08T15:26:06.150430: Epoch   0 Batch  600/3125   train\_loss = 1.604
2018-12-08T15:26:06.479341: Epoch   0 Batch  620/3125   train\_loss = 1.787
2018-12-08T15:26:06.810657: Epoch   0 Batch  640/3125   train\_loss = 1.612
2018-12-08T15:26:07.130484: Epoch   0 Batch  660/3125   train\_loss = 1.517
2018-12-08T15:26:07.464788: Epoch   0 Batch  680/3125   train\_loss = 1.561
2018-12-08T15:26:07.780462: Epoch   0 Batch  700/3125   train\_loss = 1.530
2018-12-08T15:26:08.110699: Epoch   0 Batch  720/3125   train\_loss = 1.345
2018-12-08T15:26:08.440492: Epoch   0 Batch  740/3125   train\_loss = 1.659
2018-12-08T15:26:08.770247: Epoch   0 Batch  760/3125   train\_loss = 1.606
2018-12-08T15:26:09.090549: Epoch   0 Batch  780/3125   train\_loss = 1.675
2018-12-08T15:26:09.424084: Epoch   0 Batch  800/3125   train\_loss = 1.787
2018-12-08T15:26:09.740513: Epoch   0 Batch  820/3125   train\_loss = 1.442
2018-12-08T15:26:10.070432: Epoch   0 Batch  840/3125   train\_loss = 1.571
2018-12-08T15:26:10.389509: Epoch   0 Batch  860/3125   train\_loss = 1.308
2018-12-08T15:26:10.714365: Epoch   0 Batch  880/3125   train\_loss = 1.374
2018-12-08T15:26:11.034515: Epoch   0 Batch  900/3125   train\_loss = 1.379
2018-12-08T15:26:11.360807: Epoch   0 Batch  920/3125   train\_loss = 1.552
2018-12-08T15:26:11.689439: Epoch   0 Batch  940/3125   train\_loss = 1.653
2018-12-08T15:26:12.010668: Epoch   0 Batch  960/3125   train\_loss = 1.518
2018-12-08T15:26:12.354582: Epoch   0 Batch  980/3125   train\_loss = 1.528
2018-12-08T15:26:12.690904: Epoch   0 Batch 1000/3125   train\_loss = 1.516
2018-12-08T15:26:13.014459: Epoch   0 Batch 1020/3125   train\_loss = 1.517
2018-12-08T15:26:13.340779: Epoch   0 Batch 1040/3125   train\_loss = 1.553
2018-12-08T15:26:13.664811: Epoch   0 Batch 1060/3125   train\_loss = 1.704
2018-12-08T15:26:13.999746: Epoch   0 Batch 1080/3125   train\_loss = 1.427
2018-12-08T15:26:14.343574: Epoch   0 Batch 1100/3125   train\_loss = 1.510
2018-12-08T15:26:14.667287: Epoch   0 Batch 1120/3125   train\_loss = 1.565
2018-12-08T15:26:14.980551: Epoch   0 Batch 1140/3125   train\_loss = 1.497
2018-12-08T15:26:15.299482: Epoch   0 Batch 1160/3125   train\_loss = 1.483
2018-12-08T15:26:15.630646: Epoch   0 Batch 1180/3125   train\_loss = 1.300
2018-12-08T15:26:15.963613: Epoch   0 Batch 1200/3125   train\_loss = 1.462
2018-12-08T15:26:16.285560: Epoch   0 Batch 1220/3125   train\_loss = 1.384
2018-12-08T15:26:16.615811: Epoch   0 Batch 1240/3125   train\_loss = 1.195
2018-12-08T15:26:16.940308: Epoch   0 Batch 1260/3125   train\_loss = 1.443
2018-12-08T15:26:17.260324: Epoch   0 Batch 1280/3125   train\_loss = 1.380
2018-12-08T15:26:17.602766: Epoch   0 Batch 1300/3125   train\_loss = 1.438
2018-12-08T15:26:17.940626: Epoch   0 Batch 1320/3125   train\_loss = 1.306
2018-12-08T15:26:18.260272: Epoch   0 Batch 1340/3125   train\_loss = 1.191
2018-12-08T15:26:18.594273: Epoch   0 Batch 1360/3125   train\_loss = 1.378
2018-12-08T15:26:18.930319: Epoch   0 Batch 1380/3125   train\_loss = 1.289
2018-12-08T15:26:19.271742: Epoch   0 Batch 1400/3125   train\_loss = 1.480
2018-12-08T15:26:19.580318: Epoch   0 Batch 1420/3125   train\_loss = 1.304
2018-12-08T15:26:19.900628: Epoch   0 Batch 1440/3125   train\_loss = 1.136
2018-12-08T15:26:20.230240: Epoch   0 Batch 1460/3125   train\_loss = 1.157
2018-12-08T15:26:20.560703: Epoch   0 Batch 1480/3125   train\_loss = 1.446
2018-12-08T15:26:20.908201: Epoch   0 Batch 1500/3125   train\_loss = 1.545
2018-12-08T15:26:21.233524: Epoch   0 Batch 1520/3125   train\_loss = 1.304
2018-12-08T15:26:21.551634: Epoch   0 Batch 1540/3125   train\_loss = 1.498
2018-12-08T15:26:21.885185: Epoch   0 Batch 1560/3125   train\_loss = 1.171
2018-12-08T15:26:22.213545: Epoch   0 Batch 1580/3125   train\_loss = 1.401
2018-12-08T15:26:22.550480: Epoch   0 Batch 1600/3125   train\_loss = 1.268
2018-12-08T15:26:22.880310: Epoch   0 Batch 1620/3125   train\_loss = 1.240
2018-12-08T15:26:23.220326: Epoch   0 Batch 1640/3125   train\_loss = 1.419
2018-12-08T15:26:23.541793: Epoch   0 Batch 1660/3125   train\_loss = 1.460
2018-12-08T15:26:23.870429: Epoch   0 Batch 1680/3125   train\_loss = 1.268
2018-12-08T15:26:24.205614: Epoch   0 Batch 1700/3125   train\_loss = 1.200
2018-12-08T15:26:24.530718: Epoch   0 Batch 1720/3125   train\_loss = 1.300
2018-12-08T15:26:24.870398: Epoch   0 Batch 1740/3125   train\_loss = 1.306
2018-12-08T15:26:25.204386: Epoch   0 Batch 1760/3125   train\_loss = 1.357
2018-12-08T15:26:25.520577: Epoch   0 Batch 1780/3125   train\_loss = 1.145
2018-12-08T15:26:25.843545: Epoch   0 Batch 1800/3125   train\_loss = 1.340
2018-12-08T15:26:26.176088: Epoch   0 Batch 1820/3125   train\_loss = 1.132
2018-12-08T15:26:26.490500: Epoch   0 Batch 1840/3125   train\_loss = 1.328
2018-12-08T15:26:26.824628: Epoch   0 Batch 1860/3125   train\_loss = 1.378
2018-12-08T15:26:27.150400: Epoch   0 Batch 1880/3125   train\_loss = 1.269
2018-12-08T15:26:27.470674: Epoch   0 Batch 1900/3125   train\_loss = 1.195
2018-12-08T15:26:27.815996: Epoch   0 Batch 1920/3125   train\_loss = 1.193
2018-12-08T15:26:28.149068: Epoch   0 Batch 1940/3125   train\_loss = 1.076
2018-12-08T15:26:28.460458: Epoch   0 Batch 1960/3125   train\_loss = 1.134
2018-12-08T15:26:28.790654: Epoch   0 Batch 1980/3125   train\_loss = 1.173
2018-12-08T15:26:29.133212: Epoch   0 Batch 2000/3125   train\_loss = 1.319
2018-12-08T15:26:29.450347: Epoch   0 Batch 2020/3125   train\_loss = 1.364
2018-12-08T15:26:29.760411: Epoch   0 Batch 2040/3125   train\_loss = 1.283
2018-12-08T15:26:30.100344: Epoch   0 Batch 2060/3125   train\_loss = 1.121
2018-12-08T15:26:30.440705: Epoch   0 Batch 2080/3125   train\_loss = 1.407
2018-12-08T15:26:30.760502: Epoch   0 Batch 2100/3125   train\_loss = 1.292
2018-12-08T15:26:31.104725: Epoch   0 Batch 2120/3125   train\_loss = 1.129
2018-12-08T15:26:31.430467: Epoch   0 Batch 2140/3125   train\_loss = 1.089
2018-12-08T15:26:31.749590: Epoch   0 Batch 2160/3125   train\_loss = 1.157
2018-12-08T15:26:32.085066: Epoch   0 Batch 2180/3125   train\_loss = 1.186
2018-12-08T15:26:32.410617: Epoch   0 Batch 2200/3125   train\_loss = 1.075
2018-12-08T15:26:32.740788: Epoch   0 Batch 2220/3125   train\_loss = 1.251
2018-12-08T15:26:33.049255: Epoch   0 Batch 2240/3125   train\_loss = 1.051
2018-12-08T15:26:33.380758: Epoch   0 Batch 2260/3125   train\_loss = 1.156
2018-12-08T15:26:33.704339: Epoch   0 Batch 2280/3125   train\_loss = 1.132
2018-12-08T15:26:34.034741: Epoch   0 Batch 2300/3125   train\_loss = 1.156
2018-12-08T15:26:34.360774: Epoch   0 Batch 2320/3125   train\_loss = 1.225
2018-12-08T15:26:34.680534: Epoch   0 Batch 2340/3125   train\_loss = 1.120
2018-12-08T15:26:35.020430: Epoch   0 Batch 2360/3125   train\_loss = 1.155
2018-12-08T15:26:35.351484: Epoch   0 Batch 2380/3125   train\_loss = 1.027
2018-12-08T15:26:35.684834: Epoch   0 Batch 2400/3125   train\_loss = 1.204
2018-12-08T15:26:36.020745: Epoch   0 Batch 2420/3125   train\_loss = 1.082
2018-12-08T15:26:36.352544: Epoch   0 Batch 2440/3125   train\_loss = 1.287
2018-12-08T15:26:36.670676: Epoch   0 Batch 2460/3125   train\_loss = 1.208
2018-12-08T15:26:37.000459: Epoch   0 Batch 2480/3125   train\_loss = 1.237
2018-12-08T15:26:37.330468: Epoch   0 Batch 2500/3125   train\_loss = 1.159
2018-12-08T15:26:37.670316: Epoch   0 Batch 2520/3125   train\_loss = 1.117
2018-12-08T15:26:37.990352: Epoch   0 Batch 2540/3125   train\_loss = 1.087
2018-12-08T15:26:38.320521: Epoch   0 Batch 2560/3125   train\_loss = 0.950
2018-12-08T15:26:38.640738: Epoch   0 Batch 2580/3125   train\_loss = 1.168
2018-12-08T15:26:38.970397: Epoch   0 Batch 2600/3125   train\_loss = 1.069
2018-12-08T15:26:39.304743: Epoch   0 Batch 2620/3125   train\_loss = 1.059
2018-12-08T15:26:39.630460: Epoch   0 Batch 2640/3125   train\_loss = 1.101
2018-12-08T15:26:39.960722: Epoch   0 Batch 2660/3125   train\_loss = 1.213
2018-12-08T15:26:40.280589: Epoch   0 Batch 2680/3125   train\_loss = 0.985
2018-12-08T15:26:40.610804: Epoch   0 Batch 2700/3125   train\_loss = 1.213
2018-12-08T15:26:40.940650: Epoch   0 Batch 2720/3125   train\_loss = 1.073
2018-12-08T15:26:41.263398: Epoch   0 Batch 2740/3125   train\_loss = 1.256
2018-12-08T15:26:41.580381: Epoch   0 Batch 2760/3125   train\_loss = 1.087
2018-12-08T15:26:41.910519: Epoch   0 Batch 2780/3125   train\_loss = 0.970
2018-12-08T15:26:42.240356: Epoch   0 Batch 2800/3125   train\_loss = 1.307
2018-12-08T15:26:42.580702: Epoch   0 Batch 2820/3125   train\_loss = 1.314
2018-12-08T15:26:42.910397: Epoch   0 Batch 2840/3125   train\_loss = 1.165
2018-12-08T15:26:43.240784: Epoch   0 Batch 2860/3125   train\_loss = 1.090
2018-12-08T15:26:43.570975: Epoch   0 Batch 2880/3125   train\_loss = 1.128
2018-12-08T15:26:43.900625: Epoch   0 Batch 2900/3125   train\_loss = 1.137
2018-12-08T15:26:44.230741: Epoch   0 Batch 2920/3125   train\_loss = 1.133
2018-12-08T15:26:44.564333: Epoch   0 Batch 2940/3125   train\_loss = 1.230
2018-12-08T15:26:44.879277: Epoch   0 Batch 2960/3125   train\_loss = 1.148
2018-12-08T15:26:45.200506: Epoch   0 Batch 2980/3125   train\_loss = 1.132
2018-12-08T15:26:45.534472: Epoch   0 Batch 3000/3125   train\_loss = 1.110
2018-12-08T15:26:45.861630: Epoch   0 Batch 3020/3125   train\_loss = 1.326
2018-12-08T15:26:46.190647: Epoch   0 Batch 3040/3125   train\_loss = 1.145
2018-12-08T15:26:46.510232: Epoch   0 Batch 3060/3125   train\_loss = 1.121
2018-12-08T15:26:46.840567: Epoch   0 Batch 3080/3125   train\_loss = 1.138
2018-12-08T15:26:47.170282: Epoch   0 Batch 3100/3125   train\_loss = 1.226
2018-12-08T15:26:47.500602: Epoch   0 Batch 3120/3125   train\_loss = 1.002
2018-12-08T15:26:47.650329: Epoch   0 Batch    0/781   test\_loss = 1.067
2018-12-08T15:26:47.820462: Epoch   0 Batch   20/781   test\_loss = 1.158
2018-12-08T15:26:47.973863: Epoch   0 Batch   40/781   test\_loss = 0.999
2018-12-08T15:26:48.110333: Epoch   0 Batch   60/781   test\_loss = 1.247
2018-12-08T15:26:48.250302: Epoch   0 Batch   80/781   test\_loss = 1.176
2018-12-08T15:26:48.389857: Epoch   0 Batch  100/781   test\_loss = 1.229
2018-12-08T15:26:48.533633: Epoch   0 Batch  120/781   test\_loss = 1.185
2018-12-08T15:26:48.670584: Epoch   0 Batch  140/781   test\_loss = 1.204
2018-12-08T15:26:48.824449: Epoch   0 Batch  160/781   test\_loss = 1.266
2018-12-08T15:26:48.972763: Epoch   0 Batch  180/781   test\_loss = 1.224
2018-12-08T15:26:49.120693: Epoch   0 Batch  200/781   test\_loss = 1.152
2018-12-08T15:26:49.263910: Epoch   0 Batch  220/781   test\_loss = 0.946
2018-12-08T15:26:49.400396: Epoch   0 Batch  240/781   test\_loss = 1.193
2018-12-08T15:26:49.550351: Epoch   0 Batch  260/781   test\_loss = 1.274
2018-12-08T15:26:49.690943: Epoch   0 Batch  280/781   test\_loss = 1.382
2018-12-08T15:26:49.840751: Epoch   0 Batch  300/781   test\_loss = 1.095
2018-12-08T15:26:49.988369: Epoch   0 Batch  320/781   test\_loss = 1.222
2018-12-08T15:26:50.130495: Epoch   0 Batch  340/781   test\_loss = 0.989
2018-12-08T15:26:50.280504: Epoch   0 Batch  360/781   test\_loss = 1.220
2018-12-08T15:26:50.420522: Epoch   0 Batch  380/781   test\_loss = 1.167
2018-12-08T15:26:50.572222: Epoch   0 Batch  400/781   test\_loss = 1.111
2018-12-08T15:26:50.723284: Epoch   0 Batch  420/781   test\_loss = 1.017
2018-12-08T15:26:50.870341: Epoch   0 Batch  440/781   test\_loss = 1.164
2018-12-08T15:26:51.020593: Epoch   0 Batch  460/781   test\_loss = 1.078
2018-12-08T15:26:51.170351: Epoch   0 Batch  480/781   test\_loss = 1.103
2018-12-08T15:26:51.313798: Epoch   0 Batch  500/781   test\_loss = 0.966
2018-12-08T15:26:51.460319: Epoch   0 Batch  520/781   test\_loss = 1.123
2018-12-08T15:26:51.610295: Epoch   0 Batch  540/781   test\_loss = 1.038
2018-12-08T15:26:51.760515: Epoch   0 Batch  560/781   test\_loss = 1.264
2018-12-08T15:26:51.910349: Epoch   0 Batch  580/781   test\_loss = 1.109
2018-12-08T15:26:52.063823: Epoch   0 Batch  600/781   test\_loss = 1.154
2018-12-08T15:26:52.210048: Epoch   0 Batch  620/781   test\_loss = 1.310
2018-12-08T15:26:52.343387: Epoch   0 Batch  640/781   test\_loss = 1.194
2018-12-08T15:26:52.490513: Epoch   0 Batch  660/781   test\_loss = 1.176
2018-12-08T15:26:52.630552: Epoch   0 Batch  680/781   test\_loss = 1.400
2018-12-08T15:26:52.770645: Epoch   0 Batch  700/781   test\_loss = 1.021
2018-12-08T15:26:52.909612: Epoch   0 Batch  720/781   test\_loss = 1.367
2018-12-08T15:26:53.065621: Epoch   0 Batch  740/781   test\_loss = 1.129
2018-12-08T15:26:53.202472: Epoch   0 Batch  760/781   test\_loss = 1.157
2018-12-08T15:26:53.356525: Epoch   0 Batch  780/781   test\_loss = 1.134
2018-12-08T15:26:54.120329: Epoch   1 Batch   15/3125   train\_loss = 1.095
2018-12-08T15:26:54.490287: Epoch   1 Batch   35/3125   train\_loss = 1.136
2018-12-08T15:26:54.809323: Epoch   1 Batch   55/3125   train\_loss = 1.172
2018-12-08T15:26:55.130431: Epoch   1 Batch   75/3125   train\_loss = 1.065
2018-12-08T15:26:55.460361: Epoch   1 Batch   95/3125   train\_loss = 1.007
2018-12-08T15:26:55.803406: Epoch   1 Batch  115/3125   train\_loss = 1.228
2018-12-08T15:26:56.110621: Epoch   1 Batch  135/3125   train\_loss = 0.948
2018-12-08T15:26:56.440639: Epoch   1 Batch  155/3125   train\_loss = 1.089
2018-12-08T15:26:56.770510: Epoch   1 Batch  175/3125   train\_loss = 1.043
2018-12-08T15:26:57.106133: Epoch   1 Batch  195/3125   train\_loss = 1.154
2018-12-08T15:26:57.430246: Epoch   1 Batch  215/3125   train\_loss = 1.054
2018-12-08T15:26:57.760398: Epoch   1 Batch  235/3125   train\_loss = 1.085
2018-12-08T15:26:58.080358: Epoch   1 Batch  255/3125   train\_loss = 1.184
2018-12-08T15:26:58.410370: Epoch   1 Batch  275/3125   train\_loss = 0.939
2018-12-08T15:26:58.730405: Epoch   1 Batch  295/3125   train\_loss = 0.928
2018-12-08T15:26:59.050592: Epoch   1 Batch  315/3125   train\_loss = 1.059
2018-12-08T15:26:59.380322: Epoch   1 Batch  335/3125   train\_loss = 0.951
2018-12-08T15:26:59.700421: Epoch   1 Batch  355/3125   train\_loss = 1.119
2018-12-08T15:27:00.030427: Epoch   1 Batch  375/3125   train\_loss = 1.141
2018-12-08T15:27:00.360552: Epoch   1 Batch  395/3125   train\_loss = 1.008
2018-12-08T15:27:00.686546: Epoch   1 Batch  415/3125   train\_loss = 1.209
2018-12-08T15:27:01.068985: Epoch   1 Batch  435/3125   train\_loss = 1.205
2018-12-08T15:27:01.397806: Epoch   1 Batch  455/3125   train\_loss = 1.034
2018-12-08T15:27:01.710515: Epoch   1 Batch  475/3125   train\_loss = 1.182
2018-12-08T15:27:02.029350: Epoch   1 Batch  495/3125   train\_loss = 1.004
2018-12-08T15:27:02.360417: Epoch   1 Batch  515/3125   train\_loss = 1.115
2018-12-08T15:27:02.680365: Epoch   1 Batch  535/3125   train\_loss = 1.098
2018-12-08T15:27:03.020552: Epoch   1 Batch  555/3125   train\_loss = 1.214
2018-12-08T15:27:03.331242: Epoch   1 Batch  575/3125   train\_loss = 1.149
2018-12-08T15:27:03.664431: Epoch   1 Batch  595/3125   train\_loss = 1.220
2018-12-08T15:27:03.986244: Epoch   1 Batch  615/3125   train\_loss = 1.060
2018-12-08T15:27:04.310306: Epoch   1 Batch  635/3125   train\_loss = 1.104
2018-12-08T15:27:04.633266: Epoch   1 Batch  655/3125   train\_loss = 1.009
2018-12-08T15:27:04.950508: Epoch   1 Batch  675/3125   train\_loss = 0.834
2018-12-08T15:27:05.290432: Epoch   1 Batch  695/3125   train\_loss = 1.010
2018-12-08T15:27:05.610661: Epoch   1 Batch  715/3125   train\_loss = 1.057
2018-12-08T15:27:05.939668: Epoch   1 Batch  735/3125   train\_loss = 0.948
2018-12-08T15:27:06.270706: Epoch   1 Batch  755/3125   train\_loss = 1.185
2018-12-08T15:27:06.600378: Epoch   1 Batch  775/3125   train\_loss = 0.985
2018-12-08T15:27:06.930284: Epoch   1 Batch  795/3125   train\_loss = 1.131
2018-12-08T15:27:07.260379: Epoch   1 Batch  815/3125   train\_loss = 1.055
2018-12-08T15:27:07.600290: Epoch   1 Batch  835/3125   train\_loss = 0.994
2018-12-08T15:27:07.934633: Epoch   1 Batch  855/3125   train\_loss = 1.218
2018-12-08T15:27:08.260548: Epoch   1 Batch  875/3125   train\_loss = 1.105
2018-12-08T15:27:08.580709: Epoch   1 Batch  895/3125   train\_loss = 1.008
2018-12-08T15:27:08.900351: Epoch   1 Batch  915/3125   train\_loss = 1.066
2018-12-08T15:27:09.210460: Epoch   1 Batch  935/3125   train\_loss = 1.096
2018-12-08T15:27:09.520364: Epoch   1 Batch  955/3125   train\_loss = 1.059
2018-12-08T15:27:09.840452: Epoch   1 Batch  975/3125   train\_loss = 1.027
2018-12-08T15:27:10.160606: Epoch   1 Batch  995/3125   train\_loss = 0.857
2018-12-08T15:27:10.500548: Epoch   1 Batch 1015/3125   train\_loss = 1.059
2018-12-08T15:27:10.820400: Epoch   1 Batch 1035/3125   train\_loss = 1.095
2018-12-08T15:27:11.151647: Epoch   1 Batch 1055/3125   train\_loss = 1.088
2018-12-08T15:27:11.480697: Epoch   1 Batch 1075/3125   train\_loss = 1.096
2018-12-08T15:27:11.804523: Epoch   1 Batch 1095/3125   train\_loss = 0.953
2018-12-08T15:27:12.130757: Epoch   1 Batch 1115/3125   train\_loss = 1.072
2018-12-08T15:27:12.461945: Epoch   1 Batch 1135/3125   train\_loss = 0.971
2018-12-08T15:27:12.780243: Epoch   1 Batch 1155/3125   train\_loss = 1.089
2018-12-08T15:27:13.100437: Epoch   1 Batch 1175/3125   train\_loss = 1.094
2018-12-08T15:27:13.430301: Epoch   1 Batch 1195/3125   train\_loss = 1.163
2018-12-08T15:27:13.750340: Epoch   1 Batch 1215/3125   train\_loss = 0.917
2018-12-08T15:27:14.080323: Epoch   1 Batch 1235/3125   train\_loss = 1.096
2018-12-08T15:27:14.410372: Epoch   1 Batch 1255/3125   train\_loss = 0.965
2018-12-08T15:27:14.730728: Epoch   1 Batch 1275/3125   train\_loss = 0.999
2018-12-08T15:27:15.050412: Epoch   1 Batch 1295/3125   train\_loss = 1.006
2018-12-08T15:27:15.410226: Epoch   1 Batch 1315/3125   train\_loss = 1.209
2018-12-08T15:27:15.730614: Epoch   1 Batch 1335/3125   train\_loss = 1.020
2018-12-08T15:27:16.044661: Epoch   1 Batch 1355/3125   train\_loss = 1.007
2018-12-08T15:27:16.360641: Epoch   1 Batch 1375/3125   train\_loss = 1.076
2018-12-08T15:27:16.680619: Epoch   1 Batch 1395/3125   train\_loss = 1.057
2018-12-08T15:27:17.010778: Epoch   1 Batch 1415/3125   train\_loss = 1.079
2018-12-08T15:27:17.340531: Epoch   1 Batch 1435/3125   train\_loss = 1.030
2018-12-08T15:27:17.667577: Epoch   1 Batch 1455/3125   train\_loss = 1.075
2018-12-08T15:27:17.990331: Epoch   1 Batch 1475/3125   train\_loss = 1.100
2018-12-08T15:27:18.324456: Epoch   1 Batch 1495/3125   train\_loss = 1.014
2018-12-08T15:27:18.640219: Epoch   1 Batch 1515/3125   train\_loss = 0.975
2018-12-08T15:27:18.971051: Epoch   1 Batch 1535/3125   train\_loss = 0.923
2018-12-08T15:27:19.300553: Epoch   1 Batch 1555/3125   train\_loss = 1.019
2018-12-08T15:27:19.620485: Epoch   1 Batch 1575/3125   train\_loss = 1.000
2018-12-08T15:27:19.950760: Epoch   1 Batch 1595/3125   train\_loss = 1.124
2018-12-08T15:27:20.279077: Epoch   1 Batch 1615/3125   train\_loss = 1.048
2018-12-08T15:27:20.600596: Epoch   1 Batch 1635/3125   train\_loss = 1.080
2018-12-08T15:27:20.935829: Epoch   1 Batch 1655/3125   train\_loss = 1.149
2018-12-08T15:27:21.260329: Epoch   1 Batch 1675/3125   train\_loss = 0.939
2018-12-08T15:27:21.579845: Epoch   1 Batch 1695/3125   train\_loss = 1.027
2018-12-08T15:27:21.910551: Epoch   1 Batch 1715/3125   train\_loss = 0.974
2018-12-08T15:27:22.230280: Epoch   1 Batch 1735/3125   train\_loss = 1.128
2018-12-08T15:27:22.570606: Epoch   1 Batch 1755/3125   train\_loss = 1.085
2018-12-08T15:27:22.890340: Epoch   1 Batch 1775/3125   train\_loss = 1.063
2018-12-08T15:27:23.220578: Epoch   1 Batch 1795/3125   train\_loss = 1.093
2018-12-08T15:27:23.544401: Epoch   1 Batch 1815/3125   train\_loss = 0.989
2018-12-08T15:27:23.870552: Epoch   1 Batch 1835/3125   train\_loss = 1.086
2018-12-08T15:27:24.200631: Epoch   1 Batch 1855/3125   train\_loss = 0.965
2018-12-08T15:27:24.540576: Epoch   1 Batch 1875/3125   train\_loss = 1.063
2018-12-08T15:27:24.874013: Epoch   1 Batch 1895/3125   train\_loss = 0.942
2018-12-08T15:27:25.212686: Epoch   1 Batch 1915/3125   train\_loss = 0.898
2018-12-08T15:27:25.520265: Epoch   1 Batch 1935/3125   train\_loss = 1.001
2018-12-08T15:27:25.850618: Epoch   1 Batch 1955/3125   train\_loss = 0.983
2018-12-08T15:27:26.191090: Epoch   1 Batch 1975/3125   train\_loss = 1.013
2018-12-08T15:27:26.544540: Epoch   1 Batch 1995/3125   train\_loss = 1.202
2018-12-08T15:27:26.874587: Epoch   1 Batch 2015/3125   train\_loss = 1.101
2018-12-08T15:27:27.199346: Epoch   1 Batch 2035/3125   train\_loss = 1.154
2018-12-08T15:27:27.524347: Epoch   1 Batch 2055/3125   train\_loss = 0.890
2018-12-08T15:27:27.854174: Epoch   1 Batch 2075/3125   train\_loss = 1.142
2018-12-08T15:27:28.174557: Epoch   1 Batch 2095/3125   train\_loss = 0.939
2018-12-08T15:27:28.490501: Epoch   1 Batch 2115/3125   train\_loss = 1.044
2018-12-08T15:27:28.810765: Epoch   1 Batch 2135/3125   train\_loss = 1.035
2018-12-08T15:27:29.120745: Epoch   1 Batch 2155/3125   train\_loss = 0.983
2018-12-08T15:27:29.421004: Epoch   1 Batch 2175/3125   train\_loss = 1.026
2018-12-08T15:27:29.750653: Epoch   1 Batch 2195/3125   train\_loss = 1.087
2018-12-08T15:27:30.070521: Epoch   1 Batch 2215/3125   train\_loss = 1.044
2018-12-08T15:27:30.400484: Epoch   1 Batch 2235/3125   train\_loss = 1.173
2018-12-08T15:27:30.730570: Epoch   1 Batch 2255/3125   train\_loss = 1.133
2018-12-08T15:27:31.060328: Epoch   1 Batch 2275/3125   train\_loss = 0.885
2018-12-08T15:27:31.390287: Epoch   1 Batch 2295/3125   train\_loss = 1.278
2018-12-08T15:27:31.710394: Epoch   1 Batch 2315/3125   train\_loss = 1.089
2018-12-08T15:27:32.037722: Epoch   1 Batch 2335/3125   train\_loss = 1.066
2018-12-08T15:27:32.360694: Epoch   1 Batch 2355/3125   train\_loss = 0.997
2018-12-08T15:27:32.690337: Epoch   1 Batch 2375/3125   train\_loss = 1.156
2018-12-08T15:27:33.020701: Epoch   1 Batch 2395/3125   train\_loss = 0.975
2018-12-08T15:27:33.350364: Epoch   1 Batch 2415/3125   train\_loss = 1.061
2018-12-08T15:27:33.676773: Epoch   1 Batch 2435/3125   train\_loss = 0.952
2018-12-08T15:27:33.990532: Epoch   1 Batch 2455/3125   train\_loss = 1.040
2018-12-08T15:27:34.323323: Epoch   1 Batch 2475/3125   train\_loss = 1.029
2018-12-08T15:27:34.650698: Epoch   1 Batch 2495/3125   train\_loss = 0.995
2018-12-08T15:27:34.970237: Epoch   1 Batch 2515/3125   train\_loss = 1.050
2018-12-08T15:27:35.300211: Epoch   1 Batch 2535/3125   train\_loss = 1.100
2018-12-08T15:27:35.630373: Epoch   1 Batch 2555/3125   train\_loss = 0.829
2018-12-08T15:27:35.950611: Epoch   1 Batch 2575/3125   train\_loss = 0.882
2018-12-08T15:27:36.280338: Epoch   1 Batch 2595/3125   train\_loss = 1.029
2018-12-08T15:27:36.610480: Epoch   1 Batch 2615/3125   train\_loss = 1.121
2018-12-08T15:27:36.933770: Epoch   1 Batch 2635/3125   train\_loss = 0.895
2018-12-08T15:27:37.250258: Epoch   1 Batch 2655/3125   train\_loss = 1.021
2018-12-08T15:27:37.580405: Epoch   1 Batch 2675/3125   train\_loss = 0.910
2018-12-08T15:27:37.908226: Epoch   1 Batch 2695/3125   train\_loss = 1.042
2018-12-08T15:27:38.230648: Epoch   1 Batch 2715/3125   train\_loss = 0.936
2018-12-08T15:27:38.554355: Epoch   1 Batch 2735/3125   train\_loss = 0.883
2018-12-08T15:27:38.880323: Epoch   1 Batch 2755/3125   train\_loss = 0.975
2018-12-08T15:27:39.200412: Epoch   1 Batch 2775/3125   train\_loss = 1.023
2018-12-08T15:27:39.524862: Epoch   1 Batch 2795/3125   train\_loss = 1.072
2018-12-08T15:27:39.850468: Epoch   1 Batch 2815/3125   train\_loss = 0.932
2018-12-08T15:27:40.170343: Epoch   1 Batch 2835/3125   train\_loss = 1.007
2018-12-08T15:27:40.500534: Epoch   1 Batch 2855/3125   train\_loss = 1.021
2018-12-08T15:27:40.829883: Epoch   1 Batch 2875/3125   train\_loss = 1.103
2018-12-08T15:27:41.160362: Epoch   1 Batch 2895/3125   train\_loss = 0.969
2018-12-08T15:27:41.480530: Epoch   1 Batch 2915/3125   train\_loss = 0.964
2018-12-08T15:27:41.800744: Epoch   1 Batch 2935/3125   train\_loss = 1.083
2018-12-08T15:27:42.134097: Epoch   1 Batch 2955/3125   train\_loss = 1.000
2018-12-08T15:27:42.460303: Epoch   1 Batch 2975/3125   train\_loss = 0.941
2018-12-08T15:27:42.790699: Epoch   1 Batch 2995/3125   train\_loss = 0.950
2018-12-08T15:27:43.110465: Epoch   1 Batch 3015/3125   train\_loss = 0.986
2018-12-08T15:27:43.444778: Epoch   1 Batch 3035/3125   train\_loss = 0.974
2018-12-08T15:27:43.770361: Epoch   1 Batch 3055/3125   train\_loss = 1.006
2018-12-08T15:27:44.090363: Epoch   1 Batch 3075/3125   train\_loss = 0.996
2018-12-08T15:27:44.438047: Epoch   1 Batch 3095/3125   train\_loss = 0.928
2018-12-08T15:27:44.750601: Epoch   1 Batch 3115/3125   train\_loss = 0.830
2018-12-08T15:27:45.040558: Epoch   1 Batch   19/781   test\_loss = 1.039
2018-12-08T15:27:45.190405: Epoch   1 Batch   39/781   test\_loss = 0.819
2018-12-08T15:27:45.336201: Epoch   1 Batch   59/781   test\_loss = 0.931
2018-12-08T15:27:45.470290: Epoch   1 Batch   79/781   test\_loss = 1.006
2018-12-08T15:27:45.610524: Epoch   1 Batch   99/781   test\_loss = 0.933
2018-12-08T15:27:45.760468: Epoch   1 Batch  119/781   test\_loss = 0.960
2018-12-08T15:27:45.900398: Epoch   1 Batch  139/781   test\_loss = 1.007
2018-12-08T15:27:46.041962: Epoch   1 Batch  159/781   test\_loss = 1.058
2018-12-08T15:27:46.180462: Epoch   1 Batch  179/781   test\_loss = 0.867
2018-12-08T15:27:46.320538: Epoch   1 Batch  199/781   test\_loss = 0.914
2018-12-08T15:27:46.463733: Epoch   1 Batch  219/781   test\_loss = 0.994
2018-12-08T15:27:46.600422: Epoch   1 Batch  239/781   test\_loss = 1.224
2018-12-08T15:27:46.742200: Epoch   1 Batch  259/781   test\_loss = 0.909
2018-12-08T15:27:46.884844: Epoch   1 Batch  279/781   test\_loss = 1.050
2018-12-08T15:27:47.030232: Epoch   1 Batch  299/781   test\_loss = 1.109
2018-12-08T15:27:47.160603: Epoch   1 Batch  319/781   test\_loss = 0.938
2018-12-08T15:27:47.300607: Epoch   1 Batch  339/781   test\_loss = 0.878
2018-12-08T15:27:47.447966: Epoch   1 Batch  359/781   test\_loss = 0.899
2018-12-08T15:27:47.580430: Epoch   1 Batch  379/781   test\_loss = 0.973
2018-12-08T15:27:47.720586: Epoch   1 Batch  399/781   test\_loss = 0.842
2018-12-08T15:27:47.849349: Epoch   1 Batch  419/781   test\_loss = 1.048
2018-12-08T15:27:47.990698: Epoch   1 Batch  439/781   test\_loss = 0.966
2018-12-08T15:27:48.130337: Epoch   1 Batch  459/781   test\_loss = 1.019
2018-12-08T15:27:48.274571: Epoch   1 Batch  479/781   test\_loss = 0.961
2018-12-08T15:27:48.420432: Epoch   1 Batch  499/781   test\_loss = 0.919
2018-12-08T15:27:48.570299: Epoch   1 Batch  519/781   test\_loss = 1.057
2018-12-08T15:27:48.710427: Epoch   1 Batch  539/781   test\_loss = 0.862
2018-12-08T15:27:48.860647: Epoch   1 Batch  559/781   test\_loss = 1.079
2018-12-08T15:27:49.000401: Epoch   1 Batch  579/781   test\_loss = 1.063
2018-12-08T15:27:49.140429: Epoch   1 Batch  599/781   test\_loss = 0.940
2018-12-08T15:27:49.280354: Epoch   1 Batch  619/781   test\_loss = 1.156
2018-12-08T15:27:49.420388: Epoch   1 Batch  639/781   test\_loss = 0.916
2018-12-08T15:27:49.560741: Epoch   1 Batch  659/781   test\_loss = 1.067
2018-12-08T15:27:49.700416: Epoch   1 Batch  679/781   test\_loss = 1.141
2018-12-08T15:27:49.840477: Epoch   1 Batch  699/781   test\_loss = 0.870
2018-12-08T15:27:49.980408: Epoch   1 Batch  719/781   test\_loss = 0.949
2018-12-08T15:27:50.120268: Epoch   1 Batch  739/781   test\_loss = 0.987
2018-12-08T15:27:50.259391: Epoch   1 Batch  759/781   test\_loss = 0.918
2018-12-08T15:27:50.400269: Epoch   1 Batch  779/781   test\_loss = 0.797
2018-12-08T15:27:51.090289: Epoch   2 Batch   10/3125   train\_loss = 0.915
2018-12-08T15:27:51.430332: Epoch   2 Batch   30/3125   train\_loss = 1.016
2018-12-08T15:27:51.753661: Epoch   2 Batch   50/3125   train\_loss = 1.019
2018-12-08T15:27:52.071669: Epoch   2 Batch   70/3125   train\_loss = 0.936
2018-12-08T15:27:52.400614: Epoch   2 Batch   90/3125   train\_loss = 0.982
2018-12-08T15:27:52.720700: Epoch   2 Batch  110/3125   train\_loss = 0.873
2018-12-08T15:27:53.040356: Epoch   2 Batch  130/3125   train\_loss = 0.904
2018-12-08T15:27:53.370424: Epoch   2 Batch  150/3125   train\_loss = 1.006
2018-12-08T15:27:53.690641: Epoch   2 Batch  170/3125   train\_loss = 0.967
2018-12-08T15:27:54.020350: Epoch   2 Batch  190/3125   train\_loss = 0.952
2018-12-08T15:27:54.353255: Epoch   2 Batch  210/3125   train\_loss = 0.994
2018-12-08T15:27:54.669426: Epoch   2 Batch  230/3125   train\_loss = 1.001
2018-12-08T15:27:55.010284: Epoch   2 Batch  250/3125   train\_loss = 0.898
2018-12-08T15:27:55.340538: Epoch   2 Batch  270/3125   train\_loss = 0.814
2018-12-08T15:27:55.674846: Epoch   2 Batch  290/3125   train\_loss = 1.032
2018-12-08T15:27:56.010395: Epoch   2 Batch  310/3125   train\_loss = 1.018
2018-12-08T15:27:56.340335: Epoch   2 Batch  330/3125   train\_loss = 1.063
2018-12-08T15:27:56.669661: Epoch   2 Batch  350/3125   train\_loss = 0.863
2018-12-08T15:27:57.004911: Epoch   2 Batch  370/3125   train\_loss = 1.116
2018-12-08T15:27:57.320397: Epoch   2 Batch  390/3125   train\_loss = 1.160
2018-12-08T15:27:57.660654: Epoch   2 Batch  410/3125   train\_loss = 0.868
2018-12-08T15:27:57.990651: Epoch   2 Batch  430/3125   train\_loss = 1.137
2018-12-08T15:27:58.313887: Epoch   2 Batch  450/3125   train\_loss = 0.956
2018-12-08T15:27:58.640349: Epoch   2 Batch  470/3125   train\_loss = 0.852
2018-12-08T15:27:58.964358: Epoch   2 Batch  490/3125   train\_loss = 0.979
2018-12-08T15:27:59.279761: Epoch   2 Batch  510/3125   train\_loss = 1.030
2018-12-08T15:27:59.590570: Epoch   2 Batch  530/3125   train\_loss = 0.904
2018-12-08T15:27:59.920228: Epoch   2 Batch  550/3125   train\_loss = 0.954
2018-12-08T15:28:00.244353: Epoch   2 Batch  570/3125   train\_loss = 1.016
2018-12-08T15:28:00.560404: Epoch   2 Batch  590/3125   train\_loss = 0.991
2018-12-08T15:28:00.893962: Epoch   2 Batch  610/3125   train\_loss = 0.898
2018-12-08T15:28:01.214728: Epoch   2 Batch  630/3125   train\_loss = 1.055
2018-12-08T15:28:01.540503: Epoch   2 Batch  650/3125   train\_loss = 0.989
2018-12-08T15:28:01.870476: Epoch   2 Batch  670/3125   train\_loss = 0.960
2018-12-08T15:28:02.190519: Epoch   2 Batch  690/3125   train\_loss = 0.876
2018-12-08T15:28:02.530639: Epoch   2 Batch  710/3125   train\_loss = 0.905
2018-12-08T15:28:02.864769: Epoch   2 Batch  730/3125   train\_loss = 0.787
2018-12-08T15:28:03.183052: Epoch   2 Batch  750/3125   train\_loss = 0.910
2018-12-08T15:28:03.500707: Epoch   2 Batch  770/3125   train\_loss = 0.790
2018-12-08T15:28:03.830312: Epoch   2 Batch  790/3125   train\_loss = 0.856
2018-12-08T15:28:04.164316: Epoch   2 Batch  810/3125   train\_loss = 0.844
2018-12-08T15:28:04.489749: Epoch   2 Batch  830/3125   train\_loss = 0.816
2018-12-08T15:28:04.820514: Epoch   2 Batch  850/3125   train\_loss = 0.985
2018-12-08T15:28:05.154582: Epoch   2 Batch  870/3125   train\_loss = 0.851
2018-12-08T15:28:05.486973: Epoch   2 Batch  890/3125   train\_loss = 0.868
2018-12-08T15:28:05.820500: Epoch   2 Batch  910/3125   train\_loss = 0.995
2018-12-08T15:28:06.140649: Epoch   2 Batch  930/3125   train\_loss = 0.983
2018-12-08T15:28:06.474300: Epoch   2 Batch  950/3125   train\_loss = 0.901
2018-12-08T15:28:06.799692: Epoch   2 Batch  970/3125   train\_loss = 1.020
2018-12-08T15:28:07.120245: Epoch   2 Batch  990/3125   train\_loss = 0.757
2018-12-08T15:28:07.440634: Epoch   2 Batch 1010/3125   train\_loss = 1.080
2018-12-08T15:28:07.774557: Epoch   2 Batch 1030/3125   train\_loss = 0.883
2018-12-08T15:28:08.099832: Epoch   2 Batch 1050/3125   train\_loss = 0.899
2018-12-08T15:28:08.420325: Epoch   2 Batch 1070/3125   train\_loss = 0.926
2018-12-08T15:28:08.750487: Epoch   2 Batch 1090/3125   train\_loss = 1.005
2018-12-08T15:28:09.074753: Epoch   2 Batch 1110/3125   train\_loss = 1.046
2018-12-08T15:28:09.400750: Epoch   2 Batch 1130/3125   train\_loss = 0.868
2018-12-08T15:28:09.720632: Epoch   2 Batch 1150/3125   train\_loss = 0.916
2018-12-08T15:28:10.044439: Epoch   2 Batch 1170/3125   train\_loss = 0.922
2018-12-08T15:28:10.370589: Epoch   2 Batch 1190/3125   train\_loss = 0.956
2018-12-08T15:28:10.701472: Epoch   2 Batch 1210/3125   train\_loss = 0.872
2018-12-08T15:28:11.020539: Epoch   2 Batch 1230/3125   train\_loss = 0.876
2018-12-08T15:28:11.350666: Epoch   2 Batch 1250/3125   train\_loss = 0.941
2018-12-08T15:28:11.680450: Epoch   2 Batch 1270/3125   train\_loss = 0.919
2018-12-08T15:28:12.009572: Epoch   2 Batch 1290/3125   train\_loss = 0.889
2018-12-08T15:28:12.334718: Epoch   2 Batch 1310/3125   train\_loss = 0.890
2018-12-08T15:28:12.660423: Epoch   2 Batch 1330/3125   train\_loss = 1.046
2018-12-08T15:28:13.000441: Epoch   2 Batch 1350/3125   train\_loss = 0.845
2018-12-08T15:28:13.320286: Epoch   2 Batch 1370/3125   train\_loss = 0.817
2018-12-08T15:28:13.660336: Epoch   2 Batch 1390/3125   train\_loss = 0.944
2018-12-08T15:28:13.980334: Epoch   2 Batch 1410/3125   train\_loss = 0.927
2018-12-08T15:28:14.310341: Epoch   2 Batch 1430/3125   train\_loss = 0.919
2018-12-08T15:28:14.640622: Epoch   2 Batch 1450/3125   train\_loss = 0.959
2018-12-08T15:28:14.970514: Epoch   2 Batch 1470/3125   train\_loss = 0.888
2018-12-08T15:28:15.290523: Epoch   2 Batch 1490/3125   train\_loss = 0.985
2018-12-08T15:28:15.620259: Epoch   2 Batch 1510/3125   train\_loss = 0.959
2018-12-08T15:28:15.940355: Epoch   2 Batch 1530/3125   train\_loss = 0.987
2018-12-08T15:28:16.280285: Epoch   2 Batch 1550/3125   train\_loss = 0.854
2018-12-08T15:28:16.612430: Epoch   2 Batch 1570/3125   train\_loss = 0.915
2018-12-08T15:28:16.940607: Epoch   2 Batch 1590/3125   train\_loss = 0.927
2018-12-08T15:28:17.270297: Epoch   2 Batch 1610/3125   train\_loss = 0.895
2018-12-08T15:28:17.594621: Epoch   2 Batch 1630/3125   train\_loss = 0.983
2018-12-08T15:28:17.913207: Epoch   2 Batch 1650/3125   train\_loss = 0.800
2018-12-08T15:28:18.230382: Epoch   2 Batch 1670/3125   train\_loss = 0.762
2018-12-08T15:28:18.560464: Epoch   2 Batch 1690/3125   train\_loss = 0.869
2018-12-08T15:28:18.880524: Epoch   2 Batch 1710/3125   train\_loss = 0.928
2018-12-08T15:28:19.210547: Epoch   2 Batch 1730/3125   train\_loss = 0.959
2018-12-08T15:28:19.530596: Epoch   2 Batch 1750/3125   train\_loss = 0.854
2018-12-08T15:28:19.840356: Epoch   2 Batch 1770/3125   train\_loss = 1.130
2018-12-08T15:28:20.160221: Epoch   2 Batch 1790/3125   train\_loss = 0.871
2018-12-08T15:28:20.500308: Epoch   2 Batch 1810/3125   train\_loss = 0.917
2018-12-08T15:28:20.826786: Epoch   2 Batch 1830/3125   train\_loss = 0.993
2018-12-08T15:28:21.150345: Epoch   2 Batch 1850/3125   train\_loss = 0.852
2018-12-08T15:28:21.480282: Epoch   2 Batch 1870/3125   train\_loss = 0.979
2018-12-08T15:28:21.800660: Epoch   2 Batch 1890/3125   train\_loss = 0.778
2018-12-08T15:28:22.129730: Epoch   2 Batch 1910/3125   train\_loss = 0.877
2018-12-08T15:28:22.454206: Epoch   2 Batch 1930/3125   train\_loss = 0.969
2018-12-08T15:28:22.790718: Epoch   2 Batch 1950/3125   train\_loss = 0.843
2018-12-08T15:28:23.110246: Epoch   2 Batch 1970/3125   train\_loss = 0.959
2018-12-08T15:28:23.432102: Epoch   2 Batch 1990/3125   train\_loss = 0.858
2018-12-08T15:28:23.750384: Epoch   2 Batch 2010/3125   train\_loss = 0.846
2018-12-08T15:28:24.090321: Epoch   2 Batch 2030/3125   train\_loss = 0.836
2018-12-08T15:28:24.410253: Epoch   2 Batch 2050/3125   train\_loss = 0.988
2018-12-08T15:28:24.740734: Epoch   2 Batch 2070/3125   train\_loss = 0.850
2018-12-08T15:28:25.064185: Epoch   2 Batch 2090/3125   train\_loss = 0.834
2018-12-08T15:28:25.380672: Epoch   2 Batch 2110/3125   train\_loss = 0.994
2018-12-08T15:28:25.710467: Epoch   2 Batch 2130/3125   train\_loss = 0.945
2018-12-08T15:28:26.034166: Epoch   2 Batch 2150/3125   train\_loss = 0.960
2018-12-08T15:28:26.360201: Epoch   2 Batch 2170/3125   train\_loss = 0.839
2018-12-08T15:28:26.700298: Epoch   2 Batch 2190/3125   train\_loss = 0.916
2018-12-08T15:28:27.063166: Epoch   2 Batch 2210/3125   train\_loss = 0.914
2018-12-08T15:28:27.410349: Epoch   2 Batch 2230/3125   train\_loss = 0.852
2018-12-08T15:28:27.724907: Epoch   2 Batch 2250/3125   train\_loss = 0.976
2018-12-08T15:28:28.040676: Epoch   2 Batch 2270/3125   train\_loss = 0.872
2018-12-08T15:28:28.370409: Epoch   2 Batch 2290/3125   train\_loss = 0.820
2018-12-08T15:28:28.710336: Epoch   2 Batch 2310/3125   train\_loss = 0.873
2018-12-08T15:28:29.048770: Epoch   2 Batch 2330/3125   train\_loss = 1.001
2018-12-08T15:28:29.404257: Epoch   2 Batch 2350/3125   train\_loss = 1.005
2018-12-08T15:28:29.734514: Epoch   2 Batch 2370/3125   train\_loss = 0.867
2018-12-08T15:28:30.120399: Epoch   2 Batch 2390/3125   train\_loss = 0.951
2018-12-08T15:28:30.440621: Epoch   2 Batch 2410/3125   train\_loss = 1.051
2018-12-08T15:28:30.773615: Epoch   2 Batch 2430/3125   train\_loss = 0.861
2018-12-08T15:28:31.104411: Epoch   2 Batch 2450/3125   train\_loss = 0.970
2018-12-08T15:28:31.430532: Epoch   2 Batch 2470/3125   train\_loss = 0.964
2018-12-08T15:28:31.761317: Epoch   2 Batch 2490/3125   train\_loss = 0.974
2018-12-08T15:28:32.103965: Epoch   2 Batch 2510/3125   train\_loss = 1.084
2018-12-08T15:28:32.429557: Epoch   2 Batch 2530/3125   train\_loss = 0.767
2018-12-08T15:28:32.754227: Epoch   2 Batch 2550/3125   train\_loss = 0.971
2018-12-08T15:28:33.090378: Epoch   2 Batch 2570/3125   train\_loss = 0.925
2018-12-08T15:28:33.430187: Epoch   2 Batch 2590/3125   train\_loss = 0.958
2018-12-08T15:28:33.759778: Epoch   2 Batch 2610/3125   train\_loss = 0.978
2018-12-08T15:28:34.080340: Epoch   2 Batch 2630/3125   train\_loss = 0.635
2018-12-08T15:28:34.400410: Epoch   2 Batch 2650/3125   train\_loss = 0.867
2018-12-08T15:28:34.734578: Epoch   2 Batch 2670/3125   train\_loss = 0.901
2018-12-08T15:28:35.070707: Epoch   2 Batch 2690/3125   train\_loss = 0.911
2018-12-08T15:28:35.390627: Epoch   2 Batch 2710/3125   train\_loss = 0.840
2018-12-08T15:28:35.710640: Epoch   2 Batch 2730/3125   train\_loss = 1.039
2018-12-08T15:28:36.051442: Epoch   2 Batch 2750/3125   train\_loss = 1.008
2018-12-08T15:28:36.380516: Epoch   2 Batch 2770/3125   train\_loss = 0.936
2018-12-08T15:28:36.700528: Epoch   2 Batch 2790/3125   train\_loss = 0.866
2018-12-08T15:28:37.030532: Epoch   2 Batch 2810/3125   train\_loss = 0.938
2018-12-08T15:28:37.350214: Epoch   2 Batch 2830/3125   train\_loss = 0.807
2018-12-08T15:28:37.686838: Epoch   2 Batch 2850/3125   train\_loss = 0.932
2018-12-08T15:28:38.010617: Epoch   2 Batch 2870/3125   train\_loss = 0.793
2018-12-08T15:28:38.330419: Epoch   2 Batch 2890/3125   train\_loss = 0.790
2018-12-08T15:28:38.660392: Epoch   2 Batch 2910/3125   train\_loss = 0.962
2018-12-08T15:28:39.000227: Epoch   2 Batch 2930/3125   train\_loss = 0.734
2018-12-08T15:28:39.330632: Epoch   2 Batch 2950/3125   train\_loss = 1.015
2018-12-08T15:28:39.634527: Epoch   2 Batch 2970/3125   train\_loss = 0.913
2018-12-08T15:28:39.960330: Epoch   2 Batch 2990/3125   train\_loss = 0.848
2018-12-08T15:28:40.285714: Epoch   2 Batch 3010/3125   train\_loss = 0.947
2018-12-08T15:28:40.620568: Epoch   2 Batch 3030/3125   train\_loss = 0.896
2018-12-08T15:28:40.940710: Epoch   2 Batch 3050/3125   train\_loss = 0.851
2018-12-08T15:28:41.268427: Epoch   2 Batch 3070/3125   train\_loss = 0.832
2018-12-08T15:28:41.593577: Epoch   2 Batch 3090/3125   train\_loss = 0.730
2018-12-08T15:28:41.913503: Epoch   2 Batch 3110/3125   train\_loss = 0.815
2018-12-08T15:28:42.290214: Epoch   2 Batch   18/781   test\_loss = 0.778
2018-12-08T15:28:42.440671: Epoch   2 Batch   38/781   test\_loss = 0.848
2018-12-08T15:28:42.594470: Epoch   2 Batch   58/781   test\_loss = 0.823
2018-12-08T15:28:42.737486: Epoch   2 Batch   78/781   test\_loss = 0.851
2018-12-08T15:28:42.880396: Epoch   2 Batch   98/781   test\_loss = 0.859
2018-12-08T15:28:43.020635: Epoch   2 Batch  118/781   test\_loss = 0.888
2018-12-08T15:28:43.160608: Epoch   2 Batch  138/781   test\_loss = 0.980
2018-12-08T15:28:43.301827: Epoch   2 Batch  158/781   test\_loss = 0.809
2018-12-08T15:28:43.450673: Epoch   2 Batch  178/781   test\_loss = 0.813
2018-12-08T15:28:43.590185: Epoch   2 Batch  198/781   test\_loss = 0.906
2018-12-08T15:28:43.730691: Epoch   2 Batch  218/781   test\_loss = 1.008
2018-12-08T15:28:43.880302: Epoch   2 Batch  238/781   test\_loss = 0.954
2018-12-08T15:28:44.020617: Epoch   2 Batch  258/781   test\_loss = 0.965
2018-12-08T15:28:44.160333: Epoch   2 Batch  278/781   test\_loss = 1.030
2018-12-08T15:28:44.309771: Epoch   2 Batch  298/781   test\_loss = 0.908
2018-12-08T15:28:44.460597: Epoch   2 Batch  318/781   test\_loss = 0.867
2018-12-08T15:28:44.590403: Epoch   2 Batch  338/781   test\_loss = 0.933
2018-12-08T15:28:44.730444: Epoch   2 Batch  358/781   test\_loss = 0.914
2018-12-08T15:28:44.876408: Epoch   2 Batch  378/781   test\_loss = 0.835
2018-12-08T15:28:45.009090: Epoch   2 Batch  398/781   test\_loss = 0.850
2018-12-08T15:28:45.160249: Epoch   2 Batch  418/781   test\_loss = 0.957
2018-12-08T15:28:45.300419: Epoch   2 Batch  438/781   test\_loss = 0.949
2018-12-08T15:28:45.440260: Epoch   2 Batch  458/781   test\_loss = 0.905
2018-12-08T15:28:45.580582: Epoch   2 Batch  478/781   test\_loss = 0.894
2018-12-08T15:28:45.720396: Epoch   2 Batch  498/781   test\_loss = 0.788
2018-12-08T15:28:45.860437: Epoch   2 Batch  518/781   test\_loss = 0.838
2018-12-08T15:28:46.000360: Epoch   2 Batch  538/781   test\_loss = 0.824
2018-12-08T15:28:46.140411: Epoch   2 Batch  558/781   test\_loss = 0.843
2018-12-08T15:28:46.274861: Epoch   2 Batch  578/781   test\_loss = 0.887
2018-12-08T15:28:46.410419: Epoch   2 Batch  598/781   test\_loss = 1.033
2018-12-08T15:28:46.560508: Epoch   2 Batch  618/781   test\_loss = 0.822
2018-12-08T15:28:46.700581: Epoch   2 Batch  638/781   test\_loss = 0.876
2018-12-08T15:28:46.850345: Epoch   2 Batch  658/781   test\_loss = 1.022
2018-12-08T15:28:46.992224: Epoch   2 Batch  678/781   test\_loss = 0.940
2018-12-08T15:28:47.130415: Epoch   2 Batch  698/781   test\_loss = 0.869
2018-12-08T15:28:47.260597: Epoch   2 Batch  718/781   test\_loss = 0.991
2018-12-08T15:28:47.400297: Epoch   2 Batch  738/781   test\_loss = 0.825
2018-12-08T15:28:47.540681: Epoch   2 Batch  758/781   test\_loss = 0.945
2018-12-08T15:28:47.684387: Epoch   2 Batch  778/781   test\_loss = 0.936
2018-12-08T15:28:48.300523: Epoch   3 Batch    5/3125   train\_loss = 0.867
2018-12-08T15:28:48.630378: Epoch   3 Batch   25/3125   train\_loss = 0.938
2018-12-08T15:28:48.973467: Epoch   3 Batch   45/3125   train\_loss = 0.821
2018-12-08T15:28:49.312600: Epoch   3 Batch   65/3125   train\_loss = 0.929
2018-12-08T15:28:49.612780: Epoch   3 Batch   85/3125   train\_loss = 0.817
2018-12-08T15:28:49.930619: Epoch   3 Batch  105/3125   train\_loss = 0.767
2018-12-08T15:28:50.271955: Epoch   3 Batch  125/3125   train\_loss = 0.871
2018-12-08T15:28:50.590477: Epoch   3 Batch  145/3125   train\_loss = 0.917
2018-12-08T15:28:50.926959: Epoch   3 Batch  165/3125   train\_loss = 0.893
2018-12-08T15:28:51.260414: Epoch   3 Batch  185/3125   train\_loss = 0.779
2018-12-08T15:28:51.570442: Epoch   3 Batch  205/3125   train\_loss = 0.757
2018-12-08T15:28:51.900222: Epoch   3 Batch  225/3125   train\_loss = 0.769
2018-12-08T15:28:52.223565: Epoch   3 Batch  245/3125   train\_loss = 1.024
2018-12-08T15:28:52.564607: Epoch   3 Batch  265/3125   train\_loss = 0.883
2018-12-08T15:28:52.890253: Epoch   3 Batch  285/3125   train\_loss = 0.890
2018-12-08T15:28:53.230513: Epoch   3 Batch  305/3125   train\_loss = 0.807
2018-12-08T15:28:53.560361: Epoch   3 Batch  325/3125   train\_loss = 0.844
2018-12-08T15:28:53.880645: Epoch   3 Batch  345/3125   train\_loss = 0.950
2018-12-08T15:28:54.200308: Epoch   3 Batch  365/3125   train\_loss = 0.864
2018-12-08T15:28:54.555134: Epoch   3 Batch  385/3125   train\_loss = 0.874
2018-12-08T15:28:54.881325: Epoch   3 Batch  405/3125   train\_loss = 0.838
2018-12-08T15:28:55.200661: Epoch   3 Batch  425/3125   train\_loss = 0.884
2018-12-08T15:28:55.541055: Epoch   3 Batch  445/3125   train\_loss = 0.940
2018-12-08T15:28:55.850218: Epoch   3 Batch  465/3125   train\_loss = 0.844
2018-12-08T15:28:56.180199: Epoch   3 Batch  485/3125   train\_loss = 0.977
2018-12-08T15:28:56.500550: Epoch   3 Batch  505/3125   train\_loss = 0.793
2018-12-08T15:28:56.839984: Epoch   3 Batch  525/3125   train\_loss = 0.932
2018-12-08T15:28:57.153384: Epoch   3 Batch  545/3125   train\_loss = 0.794
2018-12-08T15:28:57.490358: Epoch   3 Batch  565/3125   train\_loss = 1.019
2018-12-08T15:28:57.820198: Epoch   3 Batch  585/3125   train\_loss = 0.793
2018-12-08T15:28:58.160234: Epoch   3 Batch  605/3125   train\_loss = 0.902
2018-12-08T15:28:58.480653: Epoch   3 Batch  625/3125   train\_loss = 0.863
2018-12-08T15:28:58.800329: Epoch   3 Batch  645/3125   train\_loss = 0.937
2018-12-08T15:28:59.148369: Epoch   3 Batch  665/3125   train\_loss = 0.935
2018-12-08T15:28:59.488646: Epoch   3 Batch  685/3125   train\_loss = 0.886
2018-12-08T15:28:59.796518: Epoch   3 Batch  705/3125   train\_loss = 1.079
2018-12-08T15:29:00.110287: Epoch   3 Batch  725/3125   train\_loss = 0.905
2018-12-08T15:29:00.449469: Epoch   3 Batch  745/3125   train\_loss = 0.836
2018-12-08T15:29:00.780612: Epoch   3 Batch  765/3125   train\_loss = 0.863
2018-12-08T15:29:01.120654: Epoch   3 Batch  785/3125   train\_loss = 1.036
2018-12-08T15:29:01.430527: Epoch   3 Batch  805/3125   train\_loss = 0.815
2018-12-08T15:29:01.774089: Epoch   3 Batch  825/3125   train\_loss = 0.859
2018-12-08T15:29:02.104792: Epoch   3 Batch  845/3125   train\_loss = 0.870
2018-12-08T15:29:02.430688: Epoch   3 Batch  865/3125   train\_loss = 0.944
2018-12-08T15:29:02.759999: Epoch   3 Batch  885/3125   train\_loss = 0.933
2018-12-08T15:29:03.080487: Epoch   3 Batch  905/3125   train\_loss = 0.976
2018-12-08T15:29:03.409939: Epoch   3 Batch  925/3125   train\_loss = 0.839
2018-12-08T15:29:03.740264: Epoch   3 Batch  945/3125   train\_loss = 0.886
2018-12-08T15:29:04.067458: Epoch   3 Batch  965/3125   train\_loss = 0.739
2018-12-08T15:29:04.394887: Epoch   3 Batch  985/3125   train\_loss = 0.971
2018-12-08T15:29:04.720311: Epoch   3 Batch 1005/3125   train\_loss = 0.719
2018-12-08T15:29:05.055802: Epoch   3 Batch 1025/3125   train\_loss = 0.855
2018-12-08T15:29:05.380208: Epoch   3 Batch 1045/3125   train\_loss = 1.077
2018-12-08T15:29:05.722466: Epoch   3 Batch 1065/3125   train\_loss = 0.860
2018-12-08T15:29:06.040198: Epoch   3 Batch 1085/3125   train\_loss = 0.822
2018-12-08T15:29:06.380467: Epoch   3 Batch 1105/3125   train\_loss = 0.730
2018-12-08T15:29:06.700667: Epoch   3 Batch 1125/3125   train\_loss = 0.800
2018-12-08T15:29:07.039741: Epoch   3 Batch 1145/3125   train\_loss = 0.876
2018-12-08T15:29:07.360286: Epoch   3 Batch 1165/3125   train\_loss = 0.978
2018-12-08T15:29:07.691320: Epoch   3 Batch 1185/3125   train\_loss = 0.817
2018-12-08T15:29:08.000588: Epoch   3 Batch 1205/3125   train\_loss = 0.823
2018-12-08T15:29:08.330523: Epoch   3 Batch 1225/3125   train\_loss = 0.926
2018-12-08T15:29:08.660224: Epoch   3 Batch 1245/3125   train\_loss = 0.982
2018-12-08T15:29:08.990189: Epoch   3 Batch 1265/3125   train\_loss = 0.912
2018-12-08T15:29:09.330611: Epoch   3 Batch 1285/3125   train\_loss = 0.927
2018-12-08T15:29:09.650496: Epoch   3 Batch 1305/3125   train\_loss = 0.781
2018-12-08T15:29:09.973347: Epoch   3 Batch 1325/3125   train\_loss = 0.813
2018-12-08T15:29:10.300719: Epoch   3 Batch 1345/3125   train\_loss = 0.885
2018-12-08T15:29:10.632476: Epoch   3 Batch 1365/3125   train\_loss = 0.798
2018-12-08T15:29:10.970259: Epoch   3 Batch 1385/3125   train\_loss = 0.766
2018-12-08T15:29:11.279733: Epoch   3 Batch 1405/3125   train\_loss = 0.881
2018-12-08T15:29:11.630204: Epoch   3 Batch 1425/3125   train\_loss = 1.023
2018-12-08T15:29:11.954011: Epoch   3 Batch 1445/3125   train\_loss = 0.977
2018-12-08T15:29:12.271264: Epoch   3 Batch 1465/3125   train\_loss = 0.868
2018-12-08T15:29:12.603594: Epoch   3 Batch 1485/3125   train\_loss = 0.878
2018-12-08T15:29:12.925992: Epoch   3 Batch 1505/3125   train\_loss = 0.740
2018-12-08T15:29:13.249419: Epoch   3 Batch 1525/3125   train\_loss = 0.784
2018-12-08T15:29:13.570595: Epoch   3 Batch 1545/3125   train\_loss = 0.857
2018-12-08T15:29:13.890558: Epoch   3 Batch 1565/3125   train\_loss = 0.872
2018-12-08T15:29:14.218477: Epoch   3 Batch 1585/3125   train\_loss = 0.816
2018-12-08T15:29:14.550355: Epoch   3 Batch 1605/3125   train\_loss = 0.825
2018-12-08T15:29:14.884323: Epoch   3 Batch 1625/3125   train\_loss = 0.926
2018-12-08T15:29:15.210769: Epoch   3 Batch 1645/3125   train\_loss = 0.908
2018-12-08T15:29:15.530512: Epoch   3 Batch 1665/3125   train\_loss = 0.851
2018-12-08T15:29:15.860357: Epoch   3 Batch 1685/3125   train\_loss = 0.930
2018-12-08T15:29:16.195292: Epoch   3 Batch 1705/3125   train\_loss = 0.874
2018-12-08T15:29:16.525812: Epoch   3 Batch 1725/3125   train\_loss = 0.821
2018-12-08T15:29:16.850415: Epoch   3 Batch 1745/3125   train\_loss = 0.781
2018-12-08T15:29:17.170321: Epoch   3 Batch 1765/3125   train\_loss = 0.828
2018-12-08T15:29:17.501963: Epoch   3 Batch 1785/3125   train\_loss = 0.956
2018-12-08T15:29:17.834219: Epoch   3 Batch 1805/3125   train\_loss = 0.941
2018-12-08T15:29:18.160399: Epoch   3 Batch 1825/3125   train\_loss = 0.989
2018-12-08T15:29:18.480592: Epoch   3 Batch 1845/3125   train\_loss = 0.925
2018-12-08T15:29:18.809715: Epoch   3 Batch 1865/3125   train\_loss = 0.744
2018-12-08T15:29:19.134624: Epoch   3 Batch 1885/3125   train\_loss = 0.902
2018-12-08T15:29:19.460565: Epoch   3 Batch 1905/3125   train\_loss = 0.803
2018-12-08T15:29:19.770242: Epoch   3 Batch 1925/3125   train\_loss = 0.840
2018-12-08T15:29:20.100336: Epoch   3 Batch 1945/3125   train\_loss = 0.851
2018-12-08T15:29:20.450558: Epoch   3 Batch 1965/3125   train\_loss = 0.872
2018-12-08T15:29:20.772660: Epoch   3 Batch 1985/3125   train\_loss = 0.827
2018-12-08T15:29:21.087035: Epoch   3 Batch 2005/3125   train\_loss = 0.897
2018-12-08T15:29:21.418281: Epoch   3 Batch 2025/3125   train\_loss = 0.861
2018-12-08T15:29:21.753351: Epoch   3 Batch 2045/3125   train\_loss = 0.730
2018-12-08T15:29:22.081475: Epoch   3 Batch 2065/3125   train\_loss = 0.706
2018-12-08T15:29:22.418592: Epoch   3 Batch 2085/3125   train\_loss = 0.970
2018-12-08T15:29:22.740730: Epoch   3 Batch 2105/3125   train\_loss = 0.819
2018-12-08T15:29:23.067818: Epoch   3 Batch 2125/3125   train\_loss = 0.950
2018-12-08T15:29:23.380470: Epoch   3 Batch 2145/3125   train\_loss = 0.973
2018-12-08T15:29:23.716631: Epoch   3 Batch 2165/3125   train\_loss = 0.798
2018-12-08T15:29:24.048393: Epoch   3 Batch 2185/3125   train\_loss = 0.915
2018-12-08T15:29:24.384330: Epoch   3 Batch 2205/3125   train\_loss = 0.899
2018-12-08T15:29:24.700453: Epoch   3 Batch 2225/3125   train\_loss = 0.817
2018-12-08T15:29:25.033333: Epoch   3 Batch 2245/3125   train\_loss = 0.778
2018-12-08T15:29:25.350539: Epoch   3 Batch 2265/3125   train\_loss = 0.912
2018-12-08T15:29:25.682043: Epoch   3 Batch 2285/3125   train\_loss = 1.014
2018-12-08T15:29:26.010445: Epoch   3 Batch 2305/3125   train\_loss = 0.828
2018-12-08T15:29:26.340665: Epoch   3 Batch 2325/3125   train\_loss = 0.789
2018-12-08T15:29:26.660313: Epoch   3 Batch 2345/3125   train\_loss = 0.845
2018-12-08T15:29:26.990588: Epoch   3 Batch 2365/3125   train\_loss = 0.741
2018-12-08T15:29:27.320410: Epoch   3 Batch 2385/3125   train\_loss = 0.925
2018-12-08T15:29:27.653741: Epoch   3 Batch 2405/3125   train\_loss = 0.868
2018-12-08T15:29:27.980622: Epoch   3 Batch 2425/3125   train\_loss = 0.825
2018-12-08T15:29:28.314478: Epoch   3 Batch 2445/3125   train\_loss = 0.898
2018-12-08T15:29:28.648907: Epoch   3 Batch 2465/3125   train\_loss = 0.756
2018-12-08T15:29:28.983528: Epoch   3 Batch 2485/3125   train\_loss = 0.817
2018-12-08T15:29:29.320599: Epoch   3 Batch 2505/3125   train\_loss = 0.810
2018-12-08T15:29:29.640555: Epoch   3 Batch 2525/3125   train\_loss = 0.885
2018-12-08T15:29:29.950448: Epoch   3 Batch 2545/3125   train\_loss = 0.962
2018-12-08T15:29:30.281149: Epoch   3 Batch 2565/3125   train\_loss = 0.858
2018-12-08T15:29:30.600845: Epoch   3 Batch 2585/3125   train\_loss = 0.797
2018-12-08T15:29:30.930314: Epoch   3 Batch 2605/3125   train\_loss = 0.799
2018-12-08T15:29:31.270438: Epoch   3 Batch 2625/3125   train\_loss = 0.972
2018-12-08T15:29:31.592946: Epoch   3 Batch 2645/3125   train\_loss = 0.829
2018-12-08T15:29:31.913907: Epoch   3 Batch 2665/3125   train\_loss = 0.881
2018-12-08T15:29:32.234559: Epoch   3 Batch 2685/3125   train\_loss = 0.805
2018-12-08T15:29:32.565456: Epoch   3 Batch 2705/3125   train\_loss = 0.801
2018-12-08T15:29:32.894188: Epoch   3 Batch 2725/3125   train\_loss = 0.896
2018-12-08T15:29:33.215605: Epoch   3 Batch 2745/3125   train\_loss = 0.863
2018-12-08T15:29:33.550745: Epoch   3 Batch 2765/3125   train\_loss = 0.809
2018-12-08T15:29:33.870854: Epoch   3 Batch 2785/3125   train\_loss = 0.935
2018-12-08T15:29:34.193463: Epoch   3 Batch 2805/3125   train\_loss = 0.846
2018-12-08T15:29:34.524707: Epoch   3 Batch 2825/3125   train\_loss = 0.880
2018-12-08T15:29:34.850652: Epoch   3 Batch 2845/3125   train\_loss = 0.817
2018-12-08T15:29:35.179375: Epoch   3 Batch 2865/3125   train\_loss = 0.841
2018-12-08T15:29:35.514878: Epoch   3 Batch 2885/3125   train\_loss = 0.875
2018-12-08T15:29:35.845453: Epoch   3 Batch 2905/3125   train\_loss = 0.945
2018-12-08T15:29:36.174091: Epoch   3 Batch 2925/3125   train\_loss = 0.892
2018-12-08T15:29:36.500638: Epoch   3 Batch 2945/3125   train\_loss = 0.880
2018-12-08T15:29:36.830240: Epoch   3 Batch 2965/3125   train\_loss = 0.918
2018-12-08T15:29:37.174916: Epoch   3 Batch 2985/3125   train\_loss = 0.851
2018-12-08T15:29:37.500209: Epoch   3 Batch 3005/3125   train\_loss = 0.727
2018-12-08T15:29:37.840253: Epoch   3 Batch 3025/3125   train\_loss = 0.945
2018-12-08T15:29:38.176886: Epoch   3 Batch 3045/3125   train\_loss = 0.894
2018-12-08T15:29:38.500262: Epoch   3 Batch 3065/3125   train\_loss = 0.823
2018-12-08T15:29:38.820669: Epoch   3 Batch 3085/3125   train\_loss = 0.849
2018-12-08T15:29:39.162512: Epoch   3 Batch 3105/3125   train\_loss = 0.855
2018-12-08T15:29:39.660237: Epoch   3 Batch   17/781   test\_loss = 0.898
2018-12-08T15:29:39.800168: Epoch   3 Batch   37/781   test\_loss = 0.906
2018-12-08T15:29:39.945752: Epoch   3 Batch   57/781   test\_loss = 0.950
2018-12-08T15:29:40.110312: Epoch   3 Batch   77/781   test\_loss = 0.849
2018-12-08T15:29:40.250507: Epoch   3 Batch   97/781   test\_loss = 0.757
2018-12-08T15:29:40.430552: Epoch   3 Batch  117/781   test\_loss = 0.925
2018-12-08T15:29:40.610326: Epoch   3 Batch  137/781   test\_loss = 0.932
2018-12-08T15:29:40.760496: Epoch   3 Batch  157/781   test\_loss = 0.898
2018-12-08T15:29:40.890898: Epoch   3 Batch  177/781   test\_loss = 0.843
2018-12-08T15:29:41.040123: Epoch   3 Batch  197/781   test\_loss = 0.873
2018-12-08T15:29:41.191311: Epoch   3 Batch  217/781   test\_loss = 0.725
2018-12-08T15:29:41.330456: Epoch   3 Batch  237/781   test\_loss = 0.769
2018-12-08T15:29:41.480356: Epoch   3 Batch  257/781   test\_loss = 1.037
2018-12-08T15:29:41.630333: Epoch   3 Batch  277/781   test\_loss = 0.959
2018-12-08T15:29:41.780525: Epoch   3 Batch  297/781   test\_loss = 0.924
2018-12-08T15:29:41.940220: Epoch   3 Batch  317/781   test\_loss = 0.976
2018-12-08T15:29:42.099509: Epoch   3 Batch  337/781   test\_loss = 0.899
2018-12-08T15:29:42.240414: Epoch   3 Batch  357/781   test\_loss = 0.928
2018-12-08T15:29:42.380497: Epoch   3 Batch  377/781   test\_loss = 0.969
2018-12-08T15:29:42.530210: Epoch   3 Batch  397/781   test\_loss = 0.888
2018-12-08T15:29:42.684308: Epoch   3 Batch  417/781   test\_loss = 0.824
2018-12-08T15:29:42.834318: Epoch   3 Batch  437/781   test\_loss = 0.768
2018-12-08T15:29:42.984738: Epoch   3 Batch  457/781   test\_loss = 0.715
2018-12-08T15:29:43.140332: Epoch   3 Batch  477/781   test\_loss = 0.855
2018-12-08T15:29:43.294202: Epoch   3 Batch  497/781   test\_loss = 0.815
2018-12-08T15:29:43.420657: Epoch   3 Batch  517/781   test\_loss = 0.790
2018-12-08T15:29:43.570458: Epoch   3 Batch  537/781   test\_loss = 0.851
2018-12-08T15:29:43.730630: Epoch   3 Batch  557/781   test\_loss = 0.971
2018-12-08T15:29:43.890490: Epoch   3 Batch  577/781   test\_loss = 0.881
2018-12-08T15:29:44.060364: Epoch   3 Batch  597/781   test\_loss = 0.803
2018-12-08T15:29:44.210165: Epoch   3 Batch  617/781   test\_loss = 0.863
2018-12-08T15:29:44.350178: Epoch   3 Batch  637/781   test\_loss = 0.776
2018-12-08T15:29:44.501257: Epoch   3 Batch  657/781   test\_loss = 0.950
2018-12-08T15:29:44.650322: Epoch   3 Batch  677/781   test\_loss = 0.935
2018-12-08T15:29:44.801628: Epoch   3 Batch  697/781   test\_loss = 0.956
2018-12-08T15:29:44.950290: Epoch   3 Batch  717/781   test\_loss = 0.848
2018-12-08T15:29:45.101672: Epoch   3 Batch  737/781   test\_loss = 0.704
2018-12-08T15:29:45.250618: Epoch   3 Batch  757/781   test\_loss = 0.995
2018-12-08T15:29:45.416761: Epoch   3 Batch  777/781   test\_loss = 0.889
2018-12-08T15:29:46.035714: Epoch   4 Batch    0/3125   train\_loss = 0.942
2018-12-08T15:29:46.350637: Epoch   4 Batch   20/3125   train\_loss = 0.864
2018-12-08T15:29:46.684552: Epoch   4 Batch   40/3125   train\_loss = 0.853
2018-12-08T15:29:47.009737: Epoch   4 Batch   60/3125   train\_loss = 0.761
2018-12-08T15:29:47.350671: Epoch   4 Batch   80/3125   train\_loss = 0.791
2018-12-08T15:29:47.684753: Epoch   4 Batch  100/3125   train\_loss = 0.917
2018-12-08T15:29:48.006722: Epoch   4 Batch  120/3125   train\_loss = 0.961
2018-12-08T15:29:48.333569: Epoch   4 Batch  140/3125   train\_loss = 0.857
2018-12-08T15:29:48.660449: Epoch   4 Batch  160/3125   train\_loss = 0.729
2018-12-08T15:29:49.000394: Epoch   4 Batch  180/3125   train\_loss = 0.801
2018-12-08T15:29:49.323879: Epoch   4 Batch  200/3125   train\_loss = 1.001
2018-12-08T15:29:49.633516: Epoch   4 Batch  220/3125   train\_loss = 0.860
2018-12-08T15:29:49.950487: Epoch   4 Batch  240/3125   train\_loss = 0.917
2018-12-08T15:29:50.270475: Epoch   4 Batch  260/3125   train\_loss = 0.895
2018-12-08T15:29:50.600387: Epoch   4 Batch  280/3125   train\_loss = 0.969
2018-12-08T15:29:50.930837: Epoch   4 Batch  300/3125   train\_loss = 1.037
2018-12-08T15:29:51.260370: Epoch   4 Batch  320/3125   train\_loss = 0.942
2018-12-08T15:29:51.580402: Epoch   4 Batch  340/3125   train\_loss = 0.728
2018-12-08T15:29:51.914866: Epoch   4 Batch  360/3125   train\_loss = 0.791
2018-12-08T15:29:52.230750: Epoch   4 Batch  380/3125   train\_loss = 0.830
2018-12-08T15:29:52.550398: Epoch   4 Batch  400/3125   train\_loss = 0.831
2018-12-08T15:29:52.895293: Epoch   4 Batch  420/3125   train\_loss = 0.782
2018-12-08T15:29:53.221623: Epoch   4 Batch  440/3125   train\_loss = 0.775
2018-12-08T15:29:53.553940: Epoch   4 Batch  460/3125   train\_loss = 0.825
2018-12-08T15:29:53.880224: Epoch   4 Batch  480/3125   train\_loss = 0.969
2018-12-08T15:29:54.200587: Epoch   4 Batch  500/3125   train\_loss = 0.656
2018-12-08T15:29:54.533959: Epoch   4 Batch  520/3125   train\_loss = 0.889
2018-12-08T15:29:54.884129: Epoch   4 Batch  540/3125   train\_loss = 0.794
2018-12-08T15:29:55.200387: Epoch   4 Batch  560/3125   train\_loss = 1.028
2018-12-08T15:29:55.529460: Epoch   4 Batch  580/3125   train\_loss = 0.961
2018-12-08T15:29:55.860374: Epoch   4 Batch  600/3125   train\_loss = 0.825
2018-12-08T15:29:56.190470: Epoch   4 Batch  620/3125   train\_loss = 0.900
2018-12-08T15:29:56.529403: Epoch   4 Batch  640/3125   train\_loss = 0.838
2018-12-08T15:29:56.856018: Epoch   4 Batch  660/3125   train\_loss = 0.833
2018-12-08T15:29:57.180289: Epoch   4 Batch  680/3125   train\_loss = 0.962
2018-12-08T15:29:57.500566: Epoch   4 Batch  700/3125   train\_loss = 0.883
2018-12-08T15:29:57.830293: Epoch   4 Batch  720/3125   train\_loss = 0.761
2018-12-08T15:29:58.164409: Epoch   4 Batch  740/3125   train\_loss = 0.930
2018-12-08T15:29:58.494076: Epoch   4 Batch  760/3125   train\_loss = 0.779
2018-12-08T15:29:58.820348: Epoch   4 Batch  780/3125   train\_loss = 0.882
2018-12-08T15:29:59.164396: Epoch   4 Batch  800/3125   train\_loss = 0.760
2018-12-08T15:29:59.511266: Epoch   4 Batch  820/3125   train\_loss = 0.846
2018-12-08T15:29:59.821856: Epoch   4 Batch  840/3125   train\_loss = 0.816
2018-12-08T15:30:00.161465: Epoch   4 Batch  860/3125   train\_loss = 0.805
2018-12-08T15:30:00.480620: Epoch   4 Batch  880/3125   train\_loss = 0.780
2018-12-08T15:30:00.800137: Epoch   4 Batch  900/3125   train\_loss = 0.832
2018-12-08T15:30:01.130419: Epoch   4 Batch  920/3125   train\_loss = 0.871
2018-12-08T15:30:01.460487: Epoch   4 Batch  940/3125   train\_loss = 0.845
2018-12-08T15:30:01.799589: Epoch   4 Batch  960/3125   train\_loss = 0.891
2018-12-08T15:30:02.120502: Epoch   4 Batch  980/3125   train\_loss = 0.967
2018-12-08T15:30:02.460274: Epoch   4 Batch 1000/3125   train\_loss = 0.929
2018-12-08T15:30:02.780360: Epoch   4 Batch 1020/3125   train\_loss = 0.889
2018-12-08T15:30:03.110184: Epoch   4 Batch 1040/3125   train\_loss = 0.738
2018-12-08T15:30:03.444593: Epoch   4 Batch 1060/3125   train\_loss = 0.942
2018-12-08T15:30:03.765168: Epoch   4 Batch 1080/3125   train\_loss = 0.841
2018-12-08T15:30:04.080602: Epoch   4 Batch 1100/3125   train\_loss = 0.862
2018-12-08T15:30:04.414776: Epoch   4 Batch 1120/3125   train\_loss = 0.845
2018-12-08T15:30:04.744799: Epoch   4 Batch 1140/3125   train\_loss = 0.857
2018-12-08T15:30:05.060497: Epoch   4 Batch 1160/3125   train\_loss = 0.809
2018-12-08T15:30:05.380137: Epoch   4 Batch 1180/3125   train\_loss = 0.799
2018-12-08T15:30:05.713927: Epoch   4 Batch 1200/3125   train\_loss = 0.927
2018-12-08T15:30:06.040531: Epoch   4 Batch 1220/3125   train\_loss = 0.885
2018-12-08T15:30:06.360316: Epoch   4 Batch 1240/3125   train\_loss = 0.747
2018-12-08T15:30:06.680278: Epoch   4 Batch 1260/3125   train\_loss = 0.868
2018-12-08T15:30:07.000311: Epoch   4 Batch 1280/3125   train\_loss = 0.866
2018-12-08T15:30:07.338400: Epoch   4 Batch 1300/3125   train\_loss = 0.786
2018-12-08T15:30:07.664873: Epoch   4 Batch 1320/3125   train\_loss = 0.831
2018-12-08T15:30:07.990602: Epoch   4 Batch 1340/3125   train\_loss = 0.768
2018-12-08T15:30:08.320644: Epoch   4 Batch 1360/3125   train\_loss = 0.764
2018-12-08T15:30:08.640499: Epoch   4 Batch 1380/3125   train\_loss = 0.848
2018-12-08T15:30:08.994071: Epoch   4 Batch 1400/3125   train\_loss = 0.925
2018-12-08T15:30:09.329683: Epoch   4 Batch 1420/3125   train\_loss = 0.871
2018-12-08T15:30:09.640166: Epoch   4 Batch 1440/3125   train\_loss = 0.744
2018-12-08T15:30:09.961176: Epoch   4 Batch 1460/3125   train\_loss = 0.818
2018-12-08T15:30:10.291561: Epoch   4 Batch 1480/3125   train\_loss = 0.829
2018-12-08T15:30:10.620468: Epoch   4 Batch 1500/3125   train\_loss = 0.909
2018-12-08T15:30:10.954132: Epoch   4 Batch 1520/3125   train\_loss = 0.781
2018-12-08T15:30:11.290258: Epoch   4 Batch 1540/3125   train\_loss = 0.943
2018-12-08T15:30:11.610222: Epoch   4 Batch 1560/3125   train\_loss = 0.729
2018-12-08T15:30:11.943871: Epoch   4 Batch 1580/3125   train\_loss = 0.937
2018-12-08T15:30:12.279163: Epoch   4 Batch 1600/3125   train\_loss = 0.791
2018-12-08T15:30:12.600673: Epoch   4 Batch 1620/3125   train\_loss = 0.817
2018-12-08T15:30:12.936458: Epoch   4 Batch 1640/3125   train\_loss = 0.900
2018-12-08T15:30:13.271000: Epoch   4 Batch 1660/3125   train\_loss = 0.972
2018-12-08T15:30:13.604359: Epoch   4 Batch 1680/3125   train\_loss = 0.829
2018-12-08T15:30:13.930229: Epoch   4 Batch 1700/3125   train\_loss = 0.785
2018-12-08T15:30:14.250453: Epoch   4 Batch 1720/3125   train\_loss = 0.872
2018-12-08T15:30:14.572479: Epoch   4 Batch 1740/3125   train\_loss = 0.904
2018-12-08T15:30:14.904344: Epoch   4 Batch 1760/3125   train\_loss = 0.876
2018-12-08T15:30:15.240274: Epoch   4 Batch 1780/3125   train\_loss = 0.875
2018-12-08T15:30:15.570217: Epoch   4 Batch 1800/3125   train\_loss = 0.840
2018-12-08T15:30:15.900145: Epoch   4 Batch 1820/3125   train\_loss = 0.791
2018-12-08T15:30:16.230148: Epoch   4 Batch 1840/3125   train\_loss = 0.893
2018-12-08T15:30:16.550443: Epoch   4 Batch 1860/3125   train\_loss = 0.940
2018-12-08T15:30:16.883074: Epoch   4 Batch 1880/3125   train\_loss = 0.827
2018-12-08T15:30:17.214357: Epoch   4 Batch 1900/3125   train\_loss = 0.750
2018-12-08T15:30:17.541451: Epoch   4 Batch 1920/3125   train\_loss = 0.804
2018-12-08T15:30:17.870175: Epoch   4 Batch 1940/3125   train\_loss = 0.752
2018-12-08T15:30:18.212132: Epoch   4 Batch 1960/3125   train\_loss = 0.753
2018-12-08T15:30:18.530404: Epoch   4 Batch 1980/3125   train\_loss = 0.786
2018-12-08T15:30:18.867156: Epoch   4 Batch 2000/3125   train\_loss = 0.979
2018-12-08T15:30:19.199411: Epoch   4 Batch 2020/3125   train\_loss = 0.890
2018-12-08T15:30:19.513778: Epoch   4 Batch 2040/3125   train\_loss = 0.780
2018-12-08T15:30:19.820253: Epoch   4 Batch 2060/3125   train\_loss = 0.816
2018-12-08T15:30:20.148906: Epoch   4 Batch 2080/3125   train\_loss = 0.972
2018-12-08T15:30:20.470486: Epoch   4 Batch 2100/3125   train\_loss = 0.826
2018-12-08T15:30:20.799217: Epoch   4 Batch 2120/3125   train\_loss = 0.767
2018-12-08T15:30:21.137222: Epoch   4 Batch 2140/3125   train\_loss = 0.804
2018-12-08T15:30:21.454336: Epoch   4 Batch 2160/3125   train\_loss = 0.813
2018-12-08T15:30:21.792234: Epoch   4 Batch 2180/3125   train\_loss = 0.888
2018-12-08T15:30:22.120424: Epoch   4 Batch 2200/3125   train\_loss = 0.807
2018-12-08T15:30:22.444434: Epoch   4 Batch 2220/3125   train\_loss = 0.847
2018-12-08T15:30:22.770580: Epoch   4 Batch 2240/3125   train\_loss = 0.834
2018-12-08T15:30:23.114430: Epoch   4 Batch 2260/3125   train\_loss = 0.857
2018-12-08T15:30:23.430479: Epoch   4 Batch 2280/3125   train\_loss = 0.822
2018-12-08T15:30:23.773383: Epoch   4 Batch 2300/3125   train\_loss = 0.833
2018-12-08T15:30:24.104618: Epoch   4 Batch 2320/3125   train\_loss = 0.872
2018-12-08T15:30:24.440912: Epoch   4 Batch 2340/3125   train\_loss = 0.790
2018-12-08T15:30:24.760279: Epoch   4 Batch 2360/3125   train\_loss = 0.851
2018-12-08T15:30:25.100635: Epoch   4 Batch 2380/3125   train\_loss = 0.812
2018-12-08T15:30:25.425111: Epoch   4 Batch 2400/3125   train\_loss = 0.873
2018-12-08T15:30:25.740536: Epoch   4 Batch 2420/3125   train\_loss = 0.757
2018-12-08T15:30:26.074540: Epoch   4 Batch 2440/3125   train\_loss = 0.817
2018-12-08T15:30:26.404465: Epoch   4 Batch 2460/3125   train\_loss = 0.863
2018-12-08T15:30:26.730527: Epoch   4 Batch 2480/3125   train\_loss = 0.959
2018-12-08T15:30:27.050582: Epoch   4 Batch 2500/3125   train\_loss = 0.771
2018-12-08T15:30:27.378158: Epoch   4 Batch 2520/3125   train\_loss = 0.897
2018-12-08T15:30:27.695175: Epoch   4 Batch 2540/3125   train\_loss = 0.850
2018-12-08T15:30:28.024595: Epoch   4 Batch 2560/3125   train\_loss = 0.642
2018-12-08T15:30:28.350321: Epoch   4 Batch 2580/3125   train\_loss = 0.883
2018-12-08T15:30:28.674415: Epoch   4 Batch 2600/3125   train\_loss = 0.800
2018-12-08T15:30:28.990374: Epoch   4 Batch 2620/3125   train\_loss = 0.748
2018-12-08T15:30:29.322296: Epoch   4 Batch 2640/3125   train\_loss = 0.812
2018-12-08T15:30:29.640645: Epoch   4 Batch 2660/3125   train\_loss = 0.944
2018-12-08T15:30:29.954669: Epoch   4 Batch 2680/3125   train\_loss = 0.780
2018-12-08T15:30:30.277306: Epoch   4 Batch 2700/3125   train\_loss = 0.862
2018-12-08T15:30:30.614679: Epoch   4 Batch 2720/3125   train\_loss = 0.728
2018-12-08T15:30:30.940642: Epoch   4 Batch 2740/3125   train\_loss = 0.886
2018-12-08T15:30:31.260295: Epoch   4 Batch 2760/3125   train\_loss = 0.743
2018-12-08T15:30:31.590243: Epoch   4 Batch 2780/3125   train\_loss = 0.792
2018-12-08T15:30:31.910494: Epoch   4 Batch 2800/3125   train\_loss = 1.014
2018-12-08T15:30:32.244084: Epoch   4 Batch 2820/3125   train\_loss = 1.001
2018-12-08T15:30:32.570427: Epoch   4 Batch 2840/3125   train\_loss = 0.814
2018-12-08T15:30:32.917431: Epoch   4 Batch 2860/3125   train\_loss = 0.803
2018-12-08T15:30:33.237214: Epoch   4 Batch 2880/3125   train\_loss = 0.832
2018-12-08T15:30:33.560508: Epoch   4 Batch 2900/3125   train\_loss = 0.784
2018-12-08T15:30:33.880592: Epoch   4 Batch 2920/3125   train\_loss = 0.837
2018-12-08T15:30:34.220482: Epoch   4 Batch 2940/3125   train\_loss = 0.929
2018-12-08T15:30:34.554189: Epoch   4 Batch 2960/3125   train\_loss = 0.833
2018-12-08T15:30:34.902470: Epoch   4 Batch 2980/3125   train\_loss = 0.800
2018-12-08T15:30:35.239392: Epoch   4 Batch 3000/3125   train\_loss = 0.916
2018-12-08T15:30:35.563058: Epoch   4 Batch 3020/3125   train\_loss = 0.958
2018-12-08T15:30:35.890366: Epoch   4 Batch 3040/3125   train\_loss = 0.912
2018-12-08T15:30:36.227758: Epoch   4 Batch 3060/3125   train\_loss = 0.738
2018-12-08T15:30:36.558917: Epoch   4 Batch 3080/3125   train\_loss = 0.968
2018-12-08T15:30:36.870391: Epoch   4 Batch 3100/3125   train\_loss = 1.014
2018-12-08T15:30:37.208219: Epoch   4 Batch 3120/3125   train\_loss = 0.783
2018-12-08T15:30:37.395825: Epoch   4 Batch   16/781   test\_loss = 0.808
2018-12-08T15:30:37.544447: Epoch   4 Batch   36/781   test\_loss = 0.898
2018-12-08T15:30:37.693430: Epoch   4 Batch   56/781   test\_loss = 0.901
2018-12-08T15:30:37.830464: Epoch   4 Batch   76/781   test\_loss = 0.993
2018-12-08T15:30:37.988669: Epoch   4 Batch   96/781   test\_loss = 0.964
2018-12-08T15:30:38.130626: Epoch   4 Batch  116/781   test\_loss = 0.869
2018-12-08T15:30:38.270138: Epoch   4 Batch  136/781   test\_loss = 0.783
2018-12-08T15:30:38.428155: Epoch   4 Batch  156/781   test\_loss = 0.869
2018-12-08T15:30:38.570574: Epoch   4 Batch  176/781   test\_loss = 0.836
2018-12-08T15:30:38.717029: Epoch   4 Batch  196/781   test\_loss = 0.806
2018-12-08T15:30:38.850176: Epoch   4 Batch  216/781   test\_loss = 0.941
2018-12-08T15:30:38.990278: Epoch   4 Batch  236/781   test\_loss = 0.778
2018-12-08T15:30:39.120226: Epoch   4 Batch  256/781   test\_loss = 0.815
2018-12-08T15:30:39.270565: Epoch   4 Batch  276/781   test\_loss = 1.098
2018-12-08T15:30:39.429288: Epoch   4 Batch  296/781   test\_loss = 0.799
2018-12-08T15:30:39.581225: Epoch   4 Batch  316/781   test\_loss = 0.835
2018-12-08T15:30:39.710272: Epoch   4 Batch  336/781   test\_loss = 0.745
2018-12-08T15:30:39.850285: Epoch   4 Batch  356/781   test\_loss = 0.833
2018-12-08T15:30:39.990671: Epoch   4 Batch  376/781   test\_loss = 0.910
2018-12-08T15:30:40.137589: Epoch   4 Batch  396/781   test\_loss = 0.836
2018-12-08T15:30:40.275096: Epoch   4 Batch  416/781   test\_loss = 0.920
2018-12-08T15:30:40.414234: Epoch   4 Batch  436/781   test\_loss = 0.919
2018-12-08T15:30:40.561444: Epoch   4 Batch  456/781   test\_loss = 0.753
2018-12-08T15:30:40.700164: Epoch   4 Batch  476/781   test\_loss = 0.924
2018-12-08T15:30:40.830735: Epoch   4 Batch  496/781   test\_loss = 0.939
2018-12-08T15:30:40.980311: Epoch   4 Batch  516/781   test\_loss = 0.787
2018-12-08T15:30:41.120207: Epoch   4 Batch  536/781   test\_loss = 0.896
2018-12-08T15:30:41.269251: Epoch   4 Batch  556/781   test\_loss = 0.802
2018-12-08T15:30:41.404796: Epoch   4 Batch  576/781   test\_loss = 0.953
2018-12-08T15:30:41.550324: Epoch   4 Batch  596/781   test\_loss = 0.956
2018-12-08T15:30:41.683544: Epoch   4 Batch  616/781   test\_loss = 0.912
2018-12-08T15:30:41.830984: Epoch   4 Batch  636/781   test\_loss = 0.857
2018-12-08T15:30:41.963295: Epoch   4 Batch  656/781   test\_loss = 0.872
2018-12-08T15:30:42.113400: Epoch   4 Batch  676/781   test\_loss = 1.031
2018-12-08T15:30:42.263521: Epoch   4 Batch  696/781   test\_loss = 0.814
2018-12-08T15:30:42.400397: Epoch   4 Batch  716/781   test\_loss = 0.877
2018-12-08T15:30:42.540309: Epoch   4 Batch  736/781   test\_loss = 1.079
2018-12-08T15:30:42.680227: Epoch   4 Batch  756/781   test\_loss = 0.830
2018-12-08T15:30:42.810240: Epoch   4 Batch  776/781   test\_loss = 0.744
Model Trained and Saved

    \end{Verbatim}

    \subsection{在 TensorBoard
中查看可视化结果}\label{ux5728-tensorboard-ux4e2dux67e5ux770bux53efux89c6ux5316ux7ed3ux679c}

    tensorboard -\/-logdir /PATH\_TO\_CODE/runs/1513402825/summaries/

tensorboard
-\/-logdir=C:\Users\tree\PycharmProjects\recommendation\SecondWeek1202\runs\1544103667\summaries\train
<img src="assets/loss.png"/>

    \subsection{保存参数}\label{ux4fddux5b58ux53c2ux6570}

保存\texttt{save\_dir} 在生成预测时使用。

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{n}{save\PYZus{}params}\PY{p}{(}\PY{p}{(}\PY{n}{save\PYZus{}dir}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{load\PYZus{}dir} \PY{o}{=} \PY{n}{load\PYZus{}params}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}  load\PYZus{}params()读取结果数据流}
\end{Verbatim}


    \subsection{显示训练Loss}\label{ux663eux793aux8badux7ec3loss}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{losses}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_104_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{显示测试Loss}\label{ux663eux793aux6d4bux8bd5loss}

迭代次数再增加一些，下降的趋势会明显一些

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{losses}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_106_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{获取 Tensors}\label{ux83b7ux53d6-tensors}

使用函数
\href{https://www.tensorflow.org/api_docs/python/tf/Graph\#get_tensor_by_name}{\texttt{get\_tensor\_by\_name()}}从
\texttt{loaded\_graph} 中获取tensors，后面的推荐功能要用到。

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{k}{def} \PY{n+nf}{get\PYZus{}tensors}\PY{p}{(}\PY{n}{loaded\PYZus{}graph}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}，就可以使用\PYZlt{}name\PYZgt{}获取Tensor }
             \PY{n}{uid} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uid:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{movie\PYZus{}id} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}id:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{movie\PYZus{}categories} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}categories:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{movie\PYZus{}titles} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}titles:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{targets} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{targets:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{dropout\PYZus{}keep\PYZus{}prob} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dropout\PYZus{}keep\PYZus{}prob:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{lr} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LearningRate:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}两种不同计算预测评分的方案使用不同的name获取tensor inference}
         \PY{c+c1}{\PYZsh{}     inference = loaded\PYZus{}graph.get\PYZus{}tensor\PYZus{}by\PYZus{}name(\PYZdq{}inference/inference/BiasAdd:0\PYZdq{})}
             \PY{n}{inference} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{inference/ExpandDims:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} 之前是MatMul:0 因为inference代码修改了 这里也要修改 感谢网友 @清歌 指出问题}
             \PY{c+c1}{\PYZsh{}inference = tf.expand\PYZus{}dims(inference, axis=1)}
             \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{movie\PYZus{}fc/Reshape:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{loaded\PYZus{}graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{user\PYZus{}fc/Reshape:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{uid}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{,} \PY{n}{inference}\PY{p}{,} \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat}\PY{p}{,} \PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat}
\end{Verbatim}


    \subsection{指定用户和电影进行评分}\label{ux6307ux5b9aux7528ux6237ux548cux7535ux5f71ux8fdbux884cux8bc4ux5206}

这部分就是对网络做正向传播，计算得到预测的评分

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}52}]:} \PY{k}{def} \PY{n+nf}{rating\PYZus{}movie}\PY{p}{(}\PY{n}{user\PYZus{}id\PYZus{}val}\PY{p}{,} \PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{)}\PY{p}{:}
             \PY{n}{loaded\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{loaded\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}  \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Load saved model读取保存的模型}
                 \PY{n}{loader} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{import\PYZus{}meta\PYZus{}graph}\PY{p}{(}\PY{n}{load\PYZus{}dir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.meta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}读取结果数据流}
                 \PY{n}{loader}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{load\PYZus{}dir}\PY{p}{)}
             
                 \PY{c+c1}{\PYZsh{} Get Tensors from loaded model}
                 \PY{n}{uid}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{,} \PY{n}{inference}\PY{p}{,}\PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}\PYZus{}} \PY{o}{=} \PY{n}{get\PYZus{}tensors}\PY{p}{(}\PY{n}{loaded\PYZus{}graph}\PY{p}{)}  \PY{c+c1}{\PYZsh{}loaded\PYZus{}graph}
             
                 \PY{n}{categories} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{]}\PY{p}{)}\PY{c+c1}{\PYZsh{}初始化一个属性向量}
                 \PY{n}{categories}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{}movieid2idx电影ID转下标的字典 将指定用户id对应下标的movies嵌入值}
                 \PY{c+c1}{\PYZsh{}movies 的pandas数据movies.values[2]对应电脑的属性特征}
             
                 \PY{n}{titles} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{sentences\PYZus{}size}\PY{p}{]}\PY{p}{)}
                 \PY{n}{titles}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
                 \PY{c+c1}{\PYZsh{}对应电脑的标题特征}
         
                             
                 \PY{n}{feed} \PY{o}{=} \PY{p}{\PYZob{}}
                       \PY{n}{uid}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{users}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{n}{user\PYZus{}id\PYZus{}val}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                       \PY{n}{movie\PYZus{}id}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                       \PY{n}{movie\PYZus{}categories}\PY{p}{:} \PY{n}{categories}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(6,1)}
                       \PY{n}{movie\PYZus{}titles}\PY{p}{:} \PY{n}{titles}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(5,1)}
                       \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
             
                 \PY{c+c1}{\PYZsh{} Get Prediction}
                 \PY{n}{inference\PYZus{}val} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{inference}\PY{p}{]}\PY{p}{,} \PY{n}{feed}\PY{p}{)}  
             
                 \PY{k}{return} \PY{p}{(}\PY{n}{inference\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}53}]:} \PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}53}]:} array([1, list([2121, 3945, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
                list([15, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],
               dtype=object)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{n}{users}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{l+m+mi}{234}\PY{p}{]}
         \PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{l+m+mi}{1401}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}54}]:} array([1425, list([3226, 3840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
                list([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],
               dtype=object)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{n}{rating\PYZus{}movie}\PY{p}{(}\PY{l+m+mi}{234}\PY{p}{,} \PY{l+m+mi}{1401}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from ./save

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}55}]:} [array([[3.5986848]], dtype=float32)]
\end{Verbatim}
            
    \subsection{生成Movie特征矩阵}\label{ux751fux6210movieux7279ux5f81ux77e9ux9635}

将训练好的电影特征组合成电影特征矩阵并保存到本地

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{n}{loaded\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
         \PY{n}{movie\PYZus{}matrics} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{loaded\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}  \PY{c+c1}{\PYZsh{}}
             \PY{c+c1}{\PYZsh{} Load saved model读取保存的模型}
             \PY{n}{loader} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{import\PYZus{}meta\PYZus{}graph}\PY{p}{(}\PY{n}{load\PYZus{}dir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.meta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{loader}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{load\PYZus{}dir}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Get Tensors from loaded model}
             \PY{n}{uid}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat}\PY{p}{,} \PY{n}{\PYZus{}\PYZus{}} \PY{o}{=} \PY{n}{get\PYZus{}tensors}\PY{p}{(}\PY{n}{loaded\PYZus{}graph}\PY{p}{)}  \PY{c+c1}{\PYZsh{}loaded\PYZus{}graph}
         
             \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{movies}\PY{o}{.}\PY{n}{values}\PY{p}{:}
                 \PY{n}{categories} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{]}\PY{p}{)}
                 \PY{n}{categories}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{item}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)}
         
                 \PY{n}{titles} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{sentences\PYZus{}size}\PY{p}{]}\PY{p}{)}
                 \PY{n}{titles}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{item}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
         
                 \PY{n}{feed} \PY{o}{=} \PY{p}{\PYZob{}}
                     \PY{n}{movie\PYZus{}id}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{item}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                     \PY{n}{movie\PYZus{}categories}\PY{p}{:} \PY{n}{categories}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(6,1)}
                     \PY{n}{movie\PYZus{}titles}\PY{p}{:} \PY{n}{titles}\PY{p}{,}  \PY{c+c1}{\PYZsh{}x.take(5,1)}
                     \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
         
                 \PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat\PYZus{}val} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat}\PY{p}{]}\PY{p}{,} \PY{n}{feed}\PY{p}{)}  
                 \PY{n}{movie\PYZus{}matrics}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{movie\PYZus{}combine\PYZus{}layer\PYZus{}flat\PYZus{}val}\PY{p}{)}
         
         \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{movie\PYZus{}matrics}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{movie\PYZus{}matrics.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{movie\PYZus{}matrics} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{movie\PYZus{}matrics.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from ./save

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{n}{movie\PYZus{}matrics} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{movie\PYZus{}matrics.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}58}]:} \PY{n}{movie\PYZus{}matrics}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}58}]:} (3883, 200)
\end{Verbatim}
            
    \subsection{生成User特征矩阵}\label{ux751fux6210userux7279ux5f81ux77e9ux9635}

将训练好的用户特征组合成用户特征矩阵并保存到本地

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{n}{loaded\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
         \PY{n}{users\PYZus{}matrics} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{loaded\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}  \PY{c+c1}{\PYZsh{}}
             \PY{c+c1}{\PYZsh{} Load saved model}
             \PY{n}{loader} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{import\PYZus{}meta\PYZus{}graph}\PY{p}{(}\PY{n}{load\PYZus{}dir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.meta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{loader}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{load\PYZus{}dir}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{} Get Tensors from loaded model}
             \PY{n}{uid}\PY{p}{,} \PY{n}{movie\PYZus{}id}\PY{p}{,} \PY{n}{movie\PYZus{}categories}\PY{p}{,} \PY{n}{movie\PYZus{}titles}\PY{p}{,} \PY{n}{targets}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{\PYZus{}\PYZus{}}\PY{p}{,}\PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat} \PY{o}{=} \PY{n}{get\PYZus{}tensors}\PY{p}{(}\PY{n}{loaded\PYZus{}graph}\PY{p}{)}  \PY{c+c1}{\PYZsh{}loaded\PYZus{}graph}
         
             \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n}{users}\PY{o}{.}\PY{n}{values}\PY{p}{:}
         
                 \PY{n}{feed} \PY{o}{=} \PY{p}{\PYZob{}}
                     \PY{n}{uid}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{item}\PY{o}{.}\PY{n}{take}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                     \PY{n}{dropout\PYZus{}keep\PYZus{}prob}\PY{p}{:} \PY{l+m+mi}{1}\PY{p}{\PYZcb{}}
         
                 \PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat\PYZus{}val} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{[}\PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat}\PY{p}{]}\PY{p}{,} \PY{n}{feed}\PY{p}{)}  
                 \PY{n}{users\PYZus{}matrics}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{user\PYZus{}combine\PYZus{}layer\PYZus{}flat\PYZus{}val}\PY{p}{)}
         
         \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{users\PYZus{}matrics}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{users\PYZus{}matrics.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{users\PYZus{}matrics} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{users\PYZus{}matrics.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from ./save

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}60}]:} \PY{n}{users\PYZus{}matrics} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{users\PYZus{}matrics.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}61}]:} \PY{n}{users\PYZus{}matrics}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}61}]:} (6040, 200)
\end{Verbatim}
            
    \subsection{开始推荐电影}\label{ux5f00ux59cbux63a8ux8350ux7535ux5f71}

使用生产的用户特征矩阵和电影特征矩阵做电影推荐

    \subsubsection{推荐同类型的电影（基于movie）}\label{ux63a8ux8350ux540cux7c7bux578bux7684ux7535ux5f71ux57faux4e8emovie}

思路是计算当前看的电影特征向量与整个电影特征矩阵的余弦相似度，取相似度最大的top\_k个，这里加了些随机选择在里面，保证每次的推荐稍稍有些不同。

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}62}]:} \PY{k}{def} \PY{n+nf}{recommend\PYZus{}same\PYZus{}type\PYZus{}movie}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{,} \PY{n}{top\PYZus{}k} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}电影id ，top取20}
             \PY{n}{loaded\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{loaded\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}  \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Load saved model}
                 \PY{c+c1}{\PYZsh{}读取模型}
                 \PY{n}{loader} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{import\PYZus{}meta\PYZus{}graph}\PY{p}{(}\PY{n}{load\PYZus{}dir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.meta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{loader}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{load\PYZus{}dir}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{}}
                 \PY{n}{norm\PYZus{}movie\PYZus{}matrics} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}sum}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{movie\PYZus{}matrics}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{keep\PYZus{}dims}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}movie\PYZus{}matrics电影特征矩阵}
                 \PY{c+c1}{\PYZsh{}tf.squarea里的每一个元素求平方}
                 \PY{c+c1}{\PYZsh{}求和(3883, 200) axis=1 ，将特征相加求平方跟}
                 
                 \PY{n}{normalized\PYZus{}movie\PYZus{}matrics} \PY{o}{=} \PY{n}{movie\PYZus{}matrics} \PY{o}{/} \PY{n}{norm\PYZus{}movie\PYZus{}matrics}
                 \PY{c+c1}{\PYZsh{}归一化处理}
         
                 \PY{c+c1}{\PYZsh{}推荐同类型的电影}
                 \PY{n}{probs\PYZus{}embeddings} \PY{o}{=} \PY{p}{(}\PY{n}{movie\PYZus{}matrics}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{}对应电影id对应的嵌入向量}
                 \PY{n}{probs\PYZus{}similarity} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{probs\PYZus{}embeddings}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{normalized\PYZus{}movie\PYZus{}matrics}\PY{p}{)}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}矩阵相乘}
                 \PY{c+c1}{\PYZsh{}probs\PYZus{}embeddings某个电影id对应嵌入向量}
                 \PY{c+c1}{\PYZsh{} tf.transpose(normalized\PYZus{}movie\PYZus{}matrics)为normalized\PYZus{}movie\PYZus{}matrics的转置}
                 \PY{c+c1}{\PYZsh{}相乘矩阵结果为对应movie\PYZus{}id\PYZus{}val与矩阵中每一个嵌入向量的像地府}
                 \PY{n}{sim} \PY{o}{=} \PY{p}{(}\PY{n}{probs\PYZus{}similarity}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}tensor计算}
                 \PY{c+c1}{\PYZsh{}使用Tensor.eval()时只能在同一步当中获取一个tensor值}
             \PY{c+c1}{\PYZsh{}     results = (\PYZhy{}sim[0]).argsort()[0:top\PYZus{}k]}
             \PY{c+c1}{\PYZsh{}     print(results)}
                 
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{您看的电影是：}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{movies\PYZus{}orig}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{以下是给您的推荐：}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{n}{p} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{n}{sim}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}numpy.squeeze(a,axis = None)从数组的形状中删除单维度条目，即把shape中为1的维度去掉}
                 \PY{c+c1}{\PYZsh{} axis的取值可为None 或 int 或 tuple of ints, 可选。若axis为空，则删除所有单维度的条目；}
                 \PY{n}{p}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{p}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{n}{top\PYZus{}k}\PY{p}{]}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
                 \PY{c+c1}{\PYZsh{}将x中的元素从小到大排列，提取其对应的index(索引)}
                 \PY{c+c1}{\PYZsh{}设定排序将除了topk的全部设为0}
                 \PY{n}{p} \PY{o}{=} \PY{n}{p} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{p}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}相似度归一化}
                 \PY{c+c1}{\PYZsh{}加入一些随机选择}
                 \PY{n}{results} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}\PY{c+c1}{\PYZsh{}生成一个空集合}
                 \PY{k}{while} \PY{n+nb}{len}\PY{p}{(}\PY{n}{results}\PY{p}{)} \PY{o}{!=} \PY{l+m+mi}{5}\PY{p}{:}
                     \PY{n}{c} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{l+m+mi}{3883}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{n}{p}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                     \PY{c+c1}{\PYZsh{}以p作为i概率分布随机选择}
                     \PY{n}{results}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{c}\PY{p}{)}
                     
                 \PY{c+c1}{\PYZsh{}打印出根据电影推荐的相似电影}
                 \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{p}{(}\PY{n}{results}\PY{p}{)}\PY{p}{:}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{val}\PY{p}{)}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{movies\PYZus{}orig}\PY{p}{[}\PY{n}{val}\PY{p}{]}\PY{p}{)}
                 
                 \PY{k}{return} \PY{n}{results}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}63}]:} \PY{n}{recommend\PYZus{}same\PYZus{}type\PYZus{}movie}\PY{p}{(}\PY{l+m+mi}{1401}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from ./save
您看的电影是：[1401 'Ghosts of Mississippi (1996)' 'Drama']
以下是给您的推荐：
3137
[3206 'Against All Odds (1984)' 'Romance']
234
[237 'Forget Paris (1995)' 'Comedy|Romance']
1379
[1400 'Somebody is Waiting (1996)' 'Drama']
2893
[2962 'Fever Pitch (1997)' 'Comedy|Romance']
3722
[3791 'Footloose (1984)' 'Drama']

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}63}]:} \{234, 1379, 2893, 3137, 3722\}
\end{Verbatim}
            
    \subsubsection{推荐您喜欢的电影（基于users）}\label{ux63a8ux8350ux60a8ux559cux6b22ux7684ux7535ux5f71ux57faux4e8eusers}

思路是使用用户特征向量与电影特征矩阵计算所有电影的评分，取评分最高的top\_k个，同样加了些随机选择部分。

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}64}]:} \PY{k}{def} \PY{n+nf}{recommend\PYZus{}your\PYZus{}favorite\PYZus{}movie}\PY{p}{(}\PY{n}{user\PYZus{}id\PYZus{}val}\PY{p}{,} \PY{n}{top\PYZus{}k} \PY{o}{=} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{:}
         
             \PY{n}{loaded\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{loaded\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}  \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Load saved model}
                 \PY{n}{loader} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{import\PYZus{}meta\PYZus{}graph}\PY{p}{(}\PY{n}{load\PYZus{}dir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.meta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{loader}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{load\PYZus{}dir}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{}推荐您喜欢的电影}
                 \PY{n}{probs\PYZus{}embeddings} \PY{o}{=} \PY{p}{(}\PY{n}{users\PYZus{}matrics}\PY{p}{[}\PY{n}{user\PYZus{}id\PYZus{}val}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}获得对应user的特征向量}
         
                 \PY{n}{probs\PYZus{}similarity} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{probs\PYZus{}embeddings}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{movie\PYZus{}matrics}\PY{p}{)}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}计算user特征向量与电影特征向量乘积}
                 \PY{n}{sim} \PY{o}{=} \PY{p}{(}\PY{n}{probs\PYZus{}similarity}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}     print(sim.shape)}
             \PY{c+c1}{\PYZsh{}     results = (\PYZhy{}sim[0]).argsort()[0:top\PYZus{}k]}
             \PY{c+c1}{\PYZsh{}     print(results)}
                 
             \PY{c+c1}{\PYZsh{}     sim\PYZus{}norm = probs\PYZus{}norm\PYZus{}similarity.eval()}
             \PY{c+c1}{\PYZsh{}     print((\PYZhy{}sim\PYZus{}norm[0]).argsort()[0:top\PYZus{}k])}
             
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{以下是给您的推荐：}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}获取对应评分预测最高top}
                 \PY{n}{p} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{squeeze}\PY{p}{(}\PY{n}{sim}\PY{p}{)}
                 \PY{n}{p}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{p}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{n}{top\PYZus{}k}\PY{p}{]}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
                 \PY{n}{p} \PY{o}{=} \PY{n}{p} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{p}\PY{p}{)}
                 \PY{n}{results} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}生成五个推荐}
                 \PY{k}{while} \PY{n+nb}{len}\PY{p}{(}\PY{n}{results}\PY{p}{)} \PY{o}{!=} \PY{l+m+mi}{5}\PY{p}{:}
                     \PY{n}{c} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{l+m+mi}{3883}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{p}\PY{o}{=}\PY{n}{p}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                     \PY{n}{results}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{c}\PY{p}{)}
                 \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{p}{(}\PY{n}{results}\PY{p}{)}\PY{p}{:}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{val}\PY{p}{)}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{movies\PYZus{}orig}\PY{p}{[}\PY{n}{val}\PY{p}{]}\PY{p}{)}
         
                 \PY{k}{return} \PY{n}{results}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}65}]:} \PY{n}{recommend\PYZus{}your\PYZus{}favorite\PYZus{}movie}\PY{p}{(}\PY{l+m+mi}{234}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from ./save
以下是给您的推荐：
672
[679 'Run of the Country, The (1995)' 'Drama']
49
[50 'Usual Suspects, The (1995)' 'Crime|Thriller']
315
[318 'Shawshank Redemption, The (1994)' 'Drama']
3829
[3899 'Circus (2000)' 'Comedy']
679
[687 'Country Life (1994)' 'Drama|Romance']

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}65}]:} \{49, 315, 672, 679, 3829\}
\end{Verbatim}
            
    \subsubsection{看过这个电影的人还看了（喜欢）哪些电影}\label{ux770bux8fc7ux8fd9ux4e2aux7535ux5f71ux7684ux4ebaux8fd8ux770bux4e86ux559cux6b22ux54eaux4e9bux7535ux5f71}

\begin{itemize}
\tightlist
\item
  首先选出喜欢某个电影的top\_k个人，得到这几个人的用户特征向量。
\item
  然后计算这几个人对所有电影的评分
\item
  选择每个人评分最高的电影作为推荐
\item
  同样加入了随机选择
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}66}]:} \PY{k+kn}{import} \PY{n+nn}{random}
         
         \PY{k}{def} \PY{n+nf}{recommend\PYZus{}other\PYZus{}favorite\PYZus{}movie}\PY{p}{(}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{,} \PY{n}{top\PYZus{}k} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{:}
             \PY{n}{loaded\PYZus{}graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{}}
             \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{loaded\PYZus{}graph}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}  \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Load saved model}
                 \PY{n}{loader} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{import\PYZus{}meta\PYZus{}graph}\PY{p}{(}\PY{n}{load\PYZus{}dir} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.meta}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{loader}\PY{o}{.}\PY{n}{restore}\PY{p}{(}\PY{n}{sess}\PY{p}{,} \PY{n}{load\PYZus{}dir}\PY{p}{)}
         
                 \PY{n}{probs\PYZus{}movie\PYZus{}embeddings} \PY{o}{=} \PY{p}{(}\PY{n}{movie\PYZus{}matrics}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{)}
                 \PY{n}{probs\PYZus{}user\PYZus{}favorite\PYZus{}similarity} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{probs\PYZus{}movie\PYZus{}embeddings}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{users\PYZus{}matrics}\PY{p}{)}\PY{p}{)}
                 \PY{n}{favorite\PYZus{}user\PYZus{}id} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{probs\PYZus{}user\PYZus{}favorite\PYZus{}similarity}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{n}{top\PYZus{}k}\PY{p}{:}\PY{p}{]}
             \PY{c+c1}{\PYZsh{}     print(normalized\PYZus{}users\PYZus{}matrics.eval().shape)}
             \PY{c+c1}{\PYZsh{}     print(probs\PYZus{}user\PYZus{}favorite\PYZus{}similarity.eval()[0][favorite\PYZus{}user\PYZus{}id])}
             \PY{c+c1}{\PYZsh{}     print(favorite\PYZus{}user\PYZus{}id.shape)}
             
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{您看的电影是：}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{movies\PYZus{}orig}\PY{p}{[}\PY{n}{movieid2idx}\PY{p}{[}\PY{n}{movie\PYZus{}id\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{喜欢看这个电影的人是：}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{users\PYZus{}orig}\PY{p}{[}\PY{n}{favorite\PYZus{}user\PYZus{}id}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n}{probs\PYZus{}users\PYZus{}embeddings} \PY{o}{=} \PY{p}{(}\PY{n}{users\PYZus{}matrics}\PY{p}{[}\PY{n}{favorite\PYZus{}user\PYZus{}id}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{)}
                 \PY{n}{probs\PYZus{}similarity} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{probs\PYZus{}users\PYZus{}embeddings}\PY{p}{,} \PY{n}{tf}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{movie\PYZus{}matrics}\PY{p}{)}\PY{p}{)}
                 \PY{n}{sim} \PY{o}{=} \PY{p}{(}\PY{n}{probs\PYZus{}similarity}\PY{o}{.}\PY{n}{eval}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}     results = (\PYZhy{}sim[0]).argsort()[0:top\PYZus{}k]}
             \PY{c+c1}{\PYZsh{}     print(results)}
             
             \PY{c+c1}{\PYZsh{}     print(sim.shape)}
             \PY{c+c1}{\PYZsh{}     print(np.argmax(sim, 1))}
                 \PY{n}{p} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{sim}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{喜欢看这个电影的人还喜欢看：}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
                 \PY{n}{results} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{p}{)}
                 \PY{k}{while} \PY{n+nb}{len}\PY{p}{(}\PY{n}{results}\PY{p}{)} \PY{o}{!=} \PY{l+m+mi}{5}\PY{p}{:}
                     \PY{n}{c} \PY{o}{=} \PY{n}{p}\PY{p}{[}\PY{n}{random}\PY{o}{.}\PY{n}{randrange}\PY{p}{(}\PY{n}{top\PYZus{}k}\PY{p}{)}\PY{p}{]}
                     \PY{n}{results}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{c}\PY{p}{)}
                 \PY{k}{for} \PY{n}{val} \PY{o+ow}{in} \PY{p}{(}\PY{n}{results}\PY{p}{)}\PY{p}{:}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{val}\PY{p}{)}
                     \PY{n+nb}{print}\PY{p}{(}\PY{n}{movies\PYZus{}orig}\PY{p}{[}\PY{n}{val}\PY{p}{]}\PY{p}{)}
                 
                 \PY{k}{return} \PY{n}{results}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{recommend\PYZus{}other\PYZus{}favorite\PYZus{}movie}\PY{p}{(}\PY{l+m+mi}{1401}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
INFO:tensorflow:Restoring parameters from ./save
您看的电影是：[1401 'Ghosts of Mississippi (1996)' 'Drama']
喜欢看这个电影的人是：[[3833 'M' 25 1]
 [4903 'M' 35 12]
 [277 'F' 35 1]
 [4460 'M' 25 14]
 [2338 'M' 45 17]
 [5461 'M' 50 0]
 [1763 'M' 35 7]
 [3295 'M' 18 18]
 [371 'M' 18 4]
 [102 'M' 35 19]
 [100 'M' 35 17]
 [1745 'M' 45 0]
 [581 'M' 50 14]
 [2693 'M' 56 13]
 [4696 'M' 18 12]
 [4085 'F' 25 6]
 [5861 'F' 50 1]
 [3031 'M' 18 4]
 [4800 'M' 18 4]
 [3901 'M' 18 14]]
喜欢看这个电影的人还喜欢看：

    \end{Verbatim}

    \section{结论}\label{ux7ed3ux8bba}

以上就是实现的常用的推荐功能，将网络模型作为回归问题进行训练，得到训练好的用户特征矩阵和电影特征矩阵进行推荐。

    \subsection{扩展阅读}\label{ux6269ux5c55ux9605ux8bfb}

如果你对个性化推荐感兴趣，以下资料建议你看看：

    \begin{itemize}
\item
  \href{http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/}{\texttt{Understanding\ Convolutional\ Neural\ Networks\ for\ NLP}}
\item
  \href{https://github.com/yoonkim/CNN_sentence}{\texttt{Convolutional\ Neural\ Networks\ for\ Sentence\ Classification}}
\item
  \href{http://www.jianshu.com/p/ed3eac3dcb39?from=singlemessage}{\texttt{利用TensorFlow实现卷积神经网络做文本分类}}
\item
  \href{https://github.com/dennybritz/cnn-text-classification-tf}{\texttt{Convolutional\ Neural\ Network\ for\ Text\ Classification\ in\ Tensorflow}}
\item
  \href{https://github.com/songgc/TF-recomm}{\texttt{SVD\ Implement\ Recommendation\ systems}}
\end{itemize}

    今天的分享就到这里，请多指教！


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}

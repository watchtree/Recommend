---
typora-root-url: image
typora-copy-images-to: image
---

# multi-objective ranking

outline
多⽬标排序介绍
learning to rank

* evaluation
* BPR
* LambdaMart

Multi-task learning

* MTL介绍
* MTL在阿⾥的实践：ESMM

## 多⽬标排序介绍

### 什么是多⽬标排序



![1545313759057](/1545313759057.png)

多个目标综合考虑并排序

利用点击、购买或者加购去评价推荐系统满意度

### 为什么要有多⽬标排序

⼯业界推荐系统多基于隐式反馈
•Global bias：不同⽬标表达不同的偏好程度（买的偏好总比看偏好深，从整体角度的偏差）
•Item bias：单个⽬标衡量不全⾯（标题党）（相同指标不同item是不一样的）（视频不一定看的时间长就是好的）
•User bias：⽤户表达满意度的⽅式不同（购物车/收藏夹，对于人不同，偏好可能无法捕捉到）
•综合⽬标收益最⼤化 

### 多⽬标排序流程

![1545358658158](/1545358658158.png)

score = CTR * (α +CVR)\*(β +price)\*stay^a\*cart^b*collect^c *rule_weight …
Rules: 同⼀XX N出1；活动扶持、新品扶持、低俗打压；流量控制…

candidate候选集， 例如1000个item

Ranker模型

PS、DB(数据库)特征

去做预估CTR、CVR购买转化率、收藏率、加购率、停留时长

在点击之后发生、五个目标对应五个不同的模型

ranker的目标是计算返回目标值，融合模型预估分数，形成召回结果的队列

直接召回队列返回到显示出来，会导致重复率过高（对鞋的分数高全是鞋子）

因子配合探索，和一些规则（同一种类出现不超过）、活动扶持、冷启动问题（新品去扶持）、低俗打压；流量控制…

reranker重排序，兼顾上述各个

例如(β +price)对商家来说，推荐高价（低价点击会更多，因此给高价更多分数）

label经常也要手动调整

### 多⽬标排序的难点

多⽬标 vs CTR预估

* 部分⽬标数据稀疏，模型准确率低（正负样本不平衡）
* 在线服务计算量⼤（ranker给多个模型打分）
* 多个⽬标间重要性难以量化（各个用户可能重要性不一样）
* 分数融合的超参难以学习
  •⼈⼯标注为label
  •长期⽬标为label
* 规则不够智能化

## learning to rank

![1545706535713](/1545706535713.png)

排序问题转化为分类问题

pointwise计算每一篇文章点击的概率，概率做排序，每一个点是独立

pairwise成对出现，两者对比，做一个排序

listwise

### LTR evaluation-MAP（评估）

![1545706794735](/1545706794735.png)

平均的准确率，p@n前n个结果由多少个相关的

AP每一个位置相关度相加除以总数量

MAP所有请求相加

计算：前n个由多少一个相关的

### LTR evaluation-F1 score

![1545707155590](/1545707155590.png)

### LTR evaluation-AUC（阈值）

![1545708623274](/1545708623274.png)

• AUC：Area Under ROC curve，ROC曲线下的⾯积，取值范围为[0.5,1]。
• AUC的直观意义:当你随机挑选⼀个正样本以及⼀个负样本时，当前的分类算法将这个正样本排在负样本前⾯的概率。

AUC越大，分类器的准确性越高

![1545708667042](/1545708667042.png)

绘图：

![1545709716659](/1545709716659.png)

当任意在样本集选一个正样本和负样本，把正样本排到负样本之前的概率为AUC

计算：M个正样本 N个负样本

M*N个pair

1-逆序对的个数（按正样本排序，前面有多少个）

### AUC实战

• train AUC >> test AUC？过拟合 
• test AUC >> online AUC？原因在于样本分布、特征等，或者可能出现偷窥
• ⽤户AUC
• 多⾼的auc算是好的

![1545710889641](/1545710889641.png)

### LTR evaluation-nDCG

**ndcg：https://www.cnblogs.com/eyeszjwang/articles/2368087.html**   

归一化折损累计增益：https://www.cnblogs.com/by-dream/p/9403984.html

![1545725013246](/1545725013246.png)

Cumulating 加权

Gain收益Position diccount（相关性或者点击率去衡量收益）

Position discount位置，越靠前作用越大

Normalization 长度不一定，因此需要进行归一化

### Non Smoothness

![1545726884574](/1545726884574.png)

### Bayesian Personalized Ranking

**刘建平BPR：http://www.cnblogs.com/pinard/p/9128682.html** 

贝叶斯个性化排序

![1545727850905](/1545727850905.png)

例如：电影评分user-item，作假设：

（离散数学当中）完全性：要不大于要不小于、不是大于就是小于，abc传递



在BPR算法中，我们将任意用户u对应的物品进行标记，如果用户u在同时有物品i和j的时候点击了i，那么我们就得到了一个三元组<u,i,j><u,i,j>，它表示对用户u来说，i的排序要比j靠前。如果对于用户u来说我们有m组这样的反馈，那么我们就可以得到m组用户u对应的训练样本。

既然是基于贝叶斯，那么我们也就有假设，这里的假设有两个：一是每个用户之间的偏好行为相互独立，即用户u在商品i和j之间的偏好和其他用户无关。二是同一用户对不同物品的偏序相互独立，也就是用户u在商品i和j之间的偏好和其他的商品无关。为了便于表述，我们用>u符号表示用户u的偏好，上面的<u,i,j><u,i,j>可以表示为：![1545825058975](/1545825058975.png)

![1545825751925](/1545825751925.png)

同时，BPR也用了和funkSVD类似的矩阵分解模型，这里BPR对于用户集U和物品集I的对应的U×IU×I的预测排序矩阵X¯¯¯¯X¯，我们期望得到两个分解后的用户矩阵WW(|U|×k|U|×k)和物品矩阵HH(|I|×k|I|×k)，满足

![1545825795482](/1545825795482.png)

![1545825816774](/1545825816774.png)





**详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解**

**https://blog.csdn.net/u011508640/article/details/72815981 **

**https://blog.csdn.net/bitcarmanlee/article/details/81417151 ** 

### BPR推导

![1545749089731](/1545749089731.png)

**∝,正比于**

![1545825903881](/1545825903881.png)

![1545826479663](/1545826479663.png)

![1545827849343](/1545827849343.png)

![1545827860392](/1545827860392.png)

![1545828119271](/1545828119271.png)

### BPR-MF

![1545785245522](/1545785245522.png)

### BPR-AUC analogy

![1545824138122](/1545824138122.png)

### BPR-MF实战

• 使⽤movielens数据实现BPR-MF
• 同⼀⽤户的评分不同构造pair
• 如何离线评估效果？
• 是使⽤point-wise MF在⽹络构造和排序效果上的差异？
• 加⼊隐反馈效果如何？看过和没看过构造pair
• 如何优化采样？通过评分分数差异优化

### RankNet

通过损失函数的方法去进行排序目标

• 常见的排序指标⽆法求梯度
• 通过概率损失函数学习Ranking Function
• 两个候选集之间的相对排序位置作为⽬标概率
• 交叉熵（cross entropy loss function）作为概率损失函数

![1545886301479](/1545886301479.png)



Pij损失函数类似于sigmoid

C交叉熵函数

可导，梯度 下降

• 优化逆序对数（13->11）
• 希望出现红⾊箭头的趋势
• 直接优化NDCG?

![1545886671035](/1545886671035.png)

aUC可能出现上述情况，虽然逆序对数减少，但是对于最相关的结果反而下移动了，不符合实际需求

直接对ndcg（会考虑位置因素）直接优化

更新为

### LambdaNet

• 训练模型只需要⽤到梯度，⽽不是损失函数本⾝
• 直接定义损失函数的梯度：lambda梯度
• 更关注位置靠前的优质⽂档的排序位置的提升

![1545886922749](/1545886922749.png)

### LambdaMart

 MART: multiple additive regression tree多个叠加回归树  

![1545888844021](/1545888844021.png)



• LambdaMart = MART + LambdaNet
• 2008 Yahoo! Learning to Rank Challengehttp://proceedings.mlr.press/v14/chapelle11a/chapelle11a.pdf
• 《From RankNet to LambdaRank to LambdaMART: an overview》http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.180.634&rep=rep1&type=pdf

![1545889238841](/1545889238841.png)

### Learning to Rank

比如对购买，加购，点击，收藏，对其设定不同的pair等级，学习偏序关系

* 优势
  • 直接优化排序⽬标，排序效果好
  • 单模型融合多⽬标，serving压⼒⼩
*  劣势
    • 样本数量⼤，训练速度慢
    • 有些偏序关系不容易构造
    • 多⽬标间的关系不易调整（比如双十一前加购，双十一当天购买）

## Multi-task learning

### transfer learning

![1545897241880](/1545897241880.png)

### 什么是MTL

![1545897475306](/1545897475306.png)

multi-task与迁移学习相比，数据一样，是不同任务的学习

![1545897805744](/1545897805744.png)

同一个数据，再不同的任务中有不同的输出

### MTL for version

![1545897883266](/1545897883266.png)

目标检测中，muititask多任务，不同特征（位置，便签，分类）

### 为什么MTL有效

•前提：多个任务具有相似性，可以共享底层特征
•解决数据稀疏问题
•不同模型善于学习不同特征，特征学习更充分
•引⼊归纳偏置（inductive bias），提⾼泛化性

### MTL for FM

![1545899107444](/1545899107444.png)

分享参数，分享多少取决于问题的相似程度

### CVR in Alibaba(以后未讲解放置在后面)

* CVR problem
  •post-click CVR 是指点击后转化率，
* CVR 应⽤场景
  •CPM 最⼤化：OCPC ⼴告系统使⽤ pCVR 来调整每次点击出
  价
  •GMV 最⼤化：推荐系统排序中 pCVR 是关键因⼦
* ⽤ CTR 的⽅法做 CVR 模型
  •采⽤类似点击率（CTR）预估任务的技术，通过点击的样本⼦
  集进⾏训练，推理的时候对整个展现样本空间进⾏推断。

### CVR预估的难点

• 样本选择偏差 (Sample Selection Bias, SSB) 问题：后⼀阶段的模
型基于上⼀阶段的采样后的样本⼦集进⾏训练，但是最终是在全样
本空间进⾏推理，这带来了严重的模型的泛化性问题
• 数据稀疏性 (Data Sparsity, DS) 问题 ：通常后⼀阶段模型的训练样
本规模通常远低于前⼀阶段任务，加⼤了模型训练的难度，同样带
来了泛化性问题。

![1545960263130](/1545960263130.png)

### 学术界解决⽅案

✓缓解 DS 问题
• 分层CVR模型 ：通过构建不同特征上层次建树，粗⼒度预估以解决 DS 问题。依赖于先验知识来构建分层结构，难以在具有数千万 user 和 item 的推荐系统中应⽤。
• 过采样⽅法： 通过复制稀少类的样本缓解 imbalance，这有助于缓解数据的稀疏性，对采样率很敏感。
✓缓解 SSB 问题
• All Missing As Negative ：应⽤随机抽样策略来选择未点击的展现作为负样本。它可以在⼀定程度上通过引⼊缺失观察的样本来消除 SSB 问题，通常会导致预测低估。

### ESMM：Entire Space MultiTask Model 

![1545960337107](/1545960337107.png)

### ESMM解决⽅案

✓SSB问题：
• 全空间建模： 和 在全部展现样本上建模。pCTCVR 和 pCTR，pCVR 都定义在全样本空间。通过分别估算单独训练的模型 pCTR和 pCTCVR 并通过上式可以获得 pCVR，三个关联和共同训练的分类器能够利⽤数据的序列模式并相互传递信息，保障物理意义
✓DS问题：
• 迁移学习：在 ESMM 中，CVR ⽹络的 Embedding 参数与 CTR 任务共享，遵循特征表⽰迁移学习范式。Embedding Layer 将⼤规模稀疏输⼊映射到低维稠密向量中，主导深度⽹络参数。CTR 任务所有展现样本规模⽐ CVR 任务要丰富多个量级，该参数共享机制使ESMM 中的 CVR ⽹络可以未点击展现中学习。

### ESMM效果

![1545960367052](/1545960367052.png)

### 多⽬标排序实践

* 构造评分矩阵
* 多⽬标召回
* learning to rank
  •BPR
  •LambdaMart
* multi-task learning
* 如何更好的融合各个⽬标的得分
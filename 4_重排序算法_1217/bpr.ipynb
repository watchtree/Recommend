{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.下载movielens 1M数据，根据打分构造样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 6040 6040 3952\n",
      "[(914, 3), (3408, 4), (2355, 5), (1197, 3), (1287, 5), (2804, 5), (594, 4), (919, 4), (595, 5), (938, 4), (2398, 4), (2918, 4), (1035, 5), (2791, 4), (2687, 3), (2018, 4), (3105, 5), (2797, 4), (2321, 3), (720, 3), (1270, 5), (527, 5), (2340, 3), (48, 5), (1097, 4), (1721, 4), (1545, 4), (745, 3), (2294, 4), (3186, 4), (1566, 4), (588, 4), (1907, 4), (783, 4), (1836, 5), (1022, 5), (2762, 4), (150, 5), (1, 5), (1961, 5), (1962, 4), (2692, 4), (260, 4), (1028, 5), (1029, 5), (1207, 4), (2028, 5), (531, 4), (3114, 4), (608, 4), (1246, 4)]\n",
      "[(1193, 5), (661, 3)]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data(data_path):\n",
    "    #\n",
    "    train_data = defaultdict(list)\n",
    "    test_data = defaultdict(list)\n",
    "    watch_list = defaultdict(set)\n",
    "    max_uid = -1\n",
    "    max_item = -1\n",
    "    \n",
    "    with open(data_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            u, i, r, t = map(int,line.strip().split(\"::\"))\n",
    "            watch_list[u].add(i)\n",
    "            #每个用户的评分都存在dict\n",
    "            if len(test_data[u]) == 0:\n",
    "                test_data[u].append((i,r))\n",
    "            elif len(test_data[u]) == 1 and test_data[u][0][1] != r:\n",
    "                test_data[u].append((i,r))\n",
    "            else:\n",
    "                train_data[u].append((i,r))\n",
    "            if u > max_uid:\n",
    "                max_uid = u\n",
    "            if i > max_item:\n",
    "                max_item = i\n",
    "    return train_data,test_data,watch_list,max_uid,max_item\n",
    "\n",
    "train_data, test_data, watch_list, user_count, item_count = load_data('ml-1m/ratings.dat')\n",
    "print(len(train_data), len(test_data), user_count, item_count)\n",
    "print(train_data[1])\n",
    "print(test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.随机采样，生成batch训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6027 1366 1210]\n",
      " [6027 1366 2714]\n",
      " [5978 1204 1217]\n",
      " [5978 1204 3372]\n",
      " [5991 2243 1704]]\n"
     ]
    }
   ],
   "source": [
    "def generate_train_batch(rating_data, batch_size=256):\n",
    "    t = []\n",
    "    for b in range(batch_size):\n",
    "        u = random.sample(rating_data.keys(), 1)[0]\n",
    "        i,r1 = random.sample(rating_data[u], 1)[0]\n",
    "        j,r2 = random.sample(rating_data[u], 1)[0] \n",
    "        #直到选到一个打分不同的pair\n",
    "        while r1 == r2:\n",
    "            u = random.sample(rating_data.keys(), 1)[0]\n",
    "            i,r1 = random.sample(rating_data[u], 1)[0]\n",
    "            j,r2 = random.sample(rating_data[u], 1)[0]\n",
    "        #i>j\n",
    "        if r1 > r2:\n",
    "            t.append([u, i, j])\n",
    "        else:\n",
    "            t.append([u, j, i])\n",
    "    return numpy.asarray(t)\n",
    "batch_data = generate_train_batch(train_data)\n",
    "print(batch_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1 1193  661]\n",
      " [   2 1357 3068]\n",
      " [   3 3421 1641]\n",
      " [   4 3468 1210]\n",
      " [   5 1175 2987]]\n"
     ]
    }
   ],
   "source": [
    "def generate_test_batch(rating_data):\n",
    "    t = []\n",
    "    for u in rating_data:\n",
    "        i,r1 = rating_data[u][0]\n",
    "        j,r2 = rating_data[u][1]\n",
    "        if r1 > r2:\n",
    "            t.append([u, i, j])\n",
    "        else:\n",
    "            t.append([u, j, i])\n",
    "    return numpy.asarray(t)\n",
    "batch_data = generate_test_batch(test_data)\n",
    "print(batch_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulation_rate = 0.01\n",
    "bias_reg = 0.01\n",
    "\n",
    "def bpr_mf(user_count, item_count, hidden_dim):\n",
    "    u = tf.placeholder(tf.int32, [None])\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        # Uv*Iv + Ub +Ib\n",
    "        user_vec = tf.get_variable(\"user_vec\", [user_count+1, hidden_dim], \n",
    "                            initializer=tf.random_normal_initializer(0, 0.1))\n",
    "        item_vec = tf.get_variable(\"item_vec\", [item_count+1, hidden_dim], \n",
    "                                initializer=tf.random_normal_initializer(0, 0.1))\n",
    "        item_bias = tf.get_variable(\"item_bias\", [item_count+1, 1], initializer=tf.random_normal_initializer(0, 0.1))    #item bias\n",
    "        # \n",
    "        u_vec = tf.nn.embedding_lookup(user_vec, u)\n",
    "        i_vec = tf.nn.embedding_lookup(item_vec, i)\n",
    "        j_vec = tf.nn.embedding_lookup(item_vec, j)  \n",
    "        #\n",
    "        i_bias = tf.nn.embedding_lookup(item_bias, i)       \n",
    "        j_bias = tf.nn.embedding_lookup(item_bias, j)  \n",
    "        #\n",
    "        xui = i_bias + tf.reduce_sum(tf.multiply(u_vec, i_vec), 1, keep_dims=True)\n",
    "        xuj = j_bias + tf.reduce_sum(tf.multiply(u_vec, j_vec), 1, keep_dims=True)\n",
    "        xuij = xui-xuj\n",
    "        #i+  j+ i>j\n",
    "        auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "        # norm\n",
    "        l2_norm = tf.add_n([\n",
    "              regulation_rate * tf.reduce_sum(tf.multiply(u_vec, u_vec)),\n",
    "              regulation_rate * tf.reduce_sum(tf.multiply(i_vec, i_vec)),\n",
    "              regulation_rate * tf.reduce_sum(tf.multiply(j_vec, j_vec)),\n",
    "              bias_reg * tf.reduce_sum(tf.multiply(i_bias, i_bias)),\n",
    "              bias_reg * tf.reduce_sum(tf.multiply(j_bias, j_bias)),\n",
    "          ]) \n",
    "        #auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "        bprloss =  l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(xuij))) \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        train_op =  tf.train.AdamOptimizer().minimize(bprloss, global_step=global_step)  \n",
    "    return u, i, j,auc, bprloss, train_op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.batch训练评估效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  100\n",
      "train_loss:  4.185711979866028\n",
      "train_auc:  0.51541015625\n",
      "test_loss:  27.968676\n",
      "test_auc:  0.5236755\n",
      "epoch:  200\n",
      "train_loss:  2.4613479840755463\n",
      "train_auc:  0.5675390625\n",
      "test_loss:  15.881258\n",
      "test_auc:  0.54900664\n",
      "epoch:  300\n",
      "train_loss:  1.7024341130256653\n",
      "train_auc:  0.6199609375\n",
      "test_loss:  9.477261\n",
      "test_auc:  0.57251656\n",
      "epoch:  400\n",
      "train_loss:  1.2980324614048004\n",
      "train_auc:  0.659609375\n",
      "test_loss:  6.0015306\n",
      "test_auc:  0.59072846\n",
      "epoch:  500\n",
      "train_loss:  1.0640179461240769\n",
      "train_auc:  0.69041015625\n",
      "test_loss:  4.0166397\n",
      "test_auc:  0.59635764\n",
      "epoch:  600\n",
      "train_loss:  0.9260004311800003\n",
      "train_auc:  0.7117578125\n",
      "test_loss:  2.781895\n",
      "test_auc:  0.5980132\n",
      "epoch:  700\n",
      "train_loss:  0.838837885260582\n",
      "train_auc:  0.72255859375\n",
      "test_loss:  2.0553913\n",
      "test_auc:  0.6072848\n",
      "epoch:  800\n",
      "train_loss:  0.7859539318084717\n",
      "train_auc:  0.7328515625\n",
      "test_loss:  1.5786643\n",
      "test_auc:  0.6157285\n",
      "epoch:  900\n",
      "train_loss:  0.7504508817195892\n",
      "train_auc:  0.736171875\n",
      "test_loss:  1.2853627\n",
      "test_auc:  0.61456954\n",
      "epoch:  1000\n",
      "train_loss:  0.7283809250593185\n",
      "train_auc:  0.73791015625\n",
      "test_loss:  1.0953131\n",
      "test_auc:  0.6165563\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    u, i, j, auc, bprloss, train_op = bpr_mf(user_count, item_count, 32)\n",
    "    tf.global_variables_initializer().run()\n",
    "    test_batch_data = generate_test_batch(test_data)\n",
    "    _batch_bprloss = 0\n",
    "    _batch_auc = 0\n",
    "    for epoch in range(1, 1001):\n",
    "        #\n",
    "        batch_data = generate_train_batch(train_data)\n",
    "        _auc,_bprloss, _train_op = session.run([auc, bprloss, train_op], \n",
    "                                feed_dict={u:batch_data[:,0], i:batch_data[:,1], j:batch_data[:,2]})\n",
    "        _batch_bprloss += _bprloss\n",
    "        _batch_auc += _auc\n",
    "        \n",
    "        if epoch%100 == 0:\n",
    "            print (\"epoch: \", epoch)\n",
    "            print (\"train_loss: \", _batch_bprloss / 100)\n",
    "            print (\"train_auc: \", _batch_auc / 100)\n",
    "            _batch_bprloss = 0\n",
    "            _batch_auc = 0\n",
    "            #\n",
    "            _auc, _bprloss = session.run([auc, bprloss],\n",
    "                                    feed_dict={u:test_batch_data[:,0], i:test_batch_data[:,1], j:test_batch_data[:,2]}\n",
    "                                )\n",
    "            \n",
    "            print(\"test_loss: \",_bprloss)\n",
    "            print(\"test_auc: \",_auc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

---
typora-root-url: image
typora-copy-images-to: image
---

# Build Large Scale Classification Model

目录：

分类模型应⽤

* 点击率预估
* ⽤户偏好预测

模型构建

* 线性模型
* ⾮线性模型
* 模型融合
* 互联⽹⾥的特征⼯程

AutoML

实战：超⼤规模Wide&Deep Learning模型实战

## Learning to Rank

![1545104049452](/1545104049452.png)

## 分类模型应⽤

### 点击率预估(CTR)

早期：

![1545129764749](/1545129764749.png)

user——item（ad广告） ——pv/click 点击

item物体，cate物体类型，cate_ctr该类型之前的历史平均

feature(除了user还可以加入其他特征)——label（统计历史数据的输入输出）

（上图中，当ad_pv>K利用赶稿的ctr，当小于时，利用类目的ctr）

logistic regression

![1545130062122](/1545130062122.png)

![1545130252125](/1545130252125.png)

### 线上CTR预估系统⽰例

![1545130449920](/1545130449920.png)

cateforical feature绝对特征，id，类别(FM模型，输出一个vector)

oridinal 虚相关（例如，店铺星际之类）(godt模型之类)

numberical 数字特征（销量）

### 基于ItemCF的推荐算法调⽤⽰意图

![1545131469114](/1545131469114.png)

### ⽤户偏好模型构造帮助Trigger Selection（选择）

![1545132777551](/1545132777551.png)

⽤户偏好模型

* 预测⽤户下⼀个浏览或者购买的类⽬、性别预测、年龄预测等

问题抽象：基于**时序⾏为**的⼆分类模型 

* 特征：统计量（销量、阅读时间）、变化类特征（⼈⼯组合）（最近几天有没有看，之前看吗，对片段行为进行人工设计）、序列类模型（部分⾃动组合）（RNN，自动给序列进行建模）
* 分析先⾏：⽐如对于⼀些商品trends变化和⽬标相关性进⾏分析
  •⼈⼯组合特征：x1*x2,x1/x2…（x1x2不一定是线性相加， 可能是乘除之类）
  •部分⾃动组合⽅式->GBDT/RF/FM/NN
* 模型⽤法：做独⽴model；做进feature.

![1545132793494](/1545132793494.png)

### ⽤户偏好模型思考题？

1. 样本和特征如何构造，⽤点击数据、还是浏览数据？
2. CTR和CVR（Conversion Rate: 转化率。是一个衡量CPA广告效果的指标,简言之就是用户点击广告到成为一个有效激活或者注册甚至付费用户的转化率）强相关，是否要构造两个模型？
3. 如何应对⼤促、季节等⽤户⾏为的变化对模型的影响？

## 模型构建

### 低维线性模型

![1545133502216](/1545133502216.png)

### ⾮线性模型——CART、RF

![1545134860757](/1545134860757.png)

决策树如果处理多维特征，维数越多，类别越多，越难以使用（例如id特征，本质上只是记录，没有泛化性能）

决策树用来做特征组合，但此处无意义

### ⾮线性模型——FM（寻找聚类关系，相似等）

• FM 受到前⾯所有的分解模型的启发
• 每个特征都表⽰成embedding vector，并且构造⼆阶关系
• FM 允许更多的特征⼯程，并且可以表⽰之前所有模型为特殊的FM（⼤家思考⼀
下）



![1545135118772](/1545135118772.png)

新id处理：实时学习onlinelearnin、构造id的统计的反馈特征、取近似top3进行补充学习

### ⾮线性模型——GBDT/DNN

![1545137217706](/1545137217706.png)

### 模型融合

![1545140385312](/1545140385312.png)

http://quinonero.net/Publications/predicting-clicks-facebook.pdf

GBDT+LR

https://www.microsoft.com/en-us/research/wp-content/uploads/2017/04/main-1.pdf

GBDT+LR+DNN结构 

### 特征分类

![1545140740311](/1545140740311.png)

match类：相关分数（相似性)

实数表示

离散化

高维ID，文本类

one—hot对应id

hash

embedding（无监督模型结果（文本相似分析，相关性分析），有监督模型中间结果）

embedding作为下一步的相关性分析

直接输入作为feature

embedding每次训练结果可能不同 

### 特征交叉（组合特征）

* Dense特征组合
  A. 将⼀个特征与其本⾝或其他特征相乘（称为特征组合）（⼆阶或者⾼阶）
  B. 两个特征相除。
  C. 对连续特征进⾏分桶，以分为多个区间分箱
* ID特征之间的组合
  D. 笛卡尔积：假如拥有⼀个特征A,A有两个可能值{A1，A2}。拥有⼀个特征B，存在{B1，B2}等可能
  值。然后，A&B之间的交叉特征如下：{（A1，B1），（A1，B2），（A2，B1），（A2，B2）}，
  ⽐如经纬度，⼀个更好地诠释好的交叉特征的实例是类似于（经度，纬度）。⼀个相同的经度对应了
  地图上很多的地⽅，纬度也是⼀样。但是⼀旦你将经度和纬度组合到⼀起，它们就代表了地理上特定
  的⼀块区域，区域中每⼀部分是拥有着类似的特性。

tf.feature_column.crossed_column（tensorflow特征组合）

* Demo : https://playground.tensorflow.org/

### 今⽇头条特征⼯程

* 第⼀类是相关性特征，就是评估内容的属性和与⽤户是否匹配。显性的匹配包括关键词匹配、分类匹配、来源匹配、主题匹配等。像FM模型中也有⼀些隐性匹配，从⽤户向量与内容向量的距离可以得出。
* 第⼆类是环境特征，包括地理位置、时间。这些既是bias特征，也能以此构建⼀些匹配特征。
* 第三类是热度特征。包括全局热度、分类热度，主题热度，以及关键词热度等。内容热度信息在⼤的推荐系统特别在⽤户冷启动的时候⾮常有效。
* 第四类是协同特征，它可以在部分程度上帮助解决所谓算法越推越窄的问题。协同特征并⾮考虑⽤户已有历史。⽽是通过⽤户⾏为分析不同⽤户间相似性，⽐如点击相似、兴趣分类相似、主题相似、兴趣词相似，甚⾄向量相似，从⽽扩展模型的探索能⼒。![1545188764372](/1545188764372.png)

### 特征选择

为什么要做特征选择：

无用特征、冗余特征

特征本身和目标无相关性

1. 特征与⽬标的相关性
2. 训练和预测同分布问题

特征选择⽅法分为3种：
1. Filter：过滤法，按照发散性或者相关性对各个特征进⾏评分，设定阈值或者待选择阈值的个
  数，选择特征。
2. Wrapper：包装法，根据⽬标函数（通常是预测效果评分），每次选择若⼲特征，或者排除若
  ⼲特征。
3. Embedded：嵌⼊法，先使⽤某些机器学习的算法和模型进⾏训练，得到各个特征的权值系
  数，根据系数从⼤到⼩选择特征。类似于Filter⽅法，但是是通过训练来确定特征的优劣。

### 特征⼯程汇总

![1545195052886](/1545195052886.png)

### Airbnb——UserID、ListingID稀疏性如何解决

![1545195073364](/1545195073364.png)

listing每年最多365天，对一个房间其样本最多出现365次，对于一个房价的训练不够

例如对于一个userid的128维特征向量，365次的样本去训练不出来 



### Airbnb——Embedding特征利⽤

![1545196814188](/1545196814188.png)

listening2vector 两个vector距离余弦相关性

embClicksim短点击

emblastlongclicksim长点击

usertypelisting联系用户

### Airbnb 特征⼯程经验

![1545201341597](/1545201341597.png)

![1545201360391](/1545201360391.png)

![1545201395746](/1545201395746.png)

指数分布取log缓解波动过大问题

粗粒度细粒度

Airbnb 特征⼯程经验

衡量特征重要性经验

1. 分数分解：基本不work
2. 训练集丢特征：仅做参考，可能有冗余
3. 测试集置换特征：有参考价值
4. TopDown分析：可视化分析

### Airbnb Rank模型演变

![1545201874141](/1545201874141.png)

## AutoML

![1545201949581](/1545201949581.png)

AutoML问题定义：我们有一个训练集、一组参数，然后训练出一个模型，利用测试集评测模型，根据评测结果来看参数效果好坏。我们希望整个过程能够自动化，这就是AutoML。从上图的简化目标函数来看，h指训练样本的目标函数，x是模型，λ是超参数，在训练时，我们指定一个λ将得到一个最优x，代入方程得到f(λ)，希望找到最小的λ使得f(λ)在测试集效果下比较好。

![1545202016973](/1545202016973.png)

特征工程只能简单的通用模式

超参数搜索可以实现

### AutoML——模型⽣成

![1545202406011](/1545202406011.png)

https://arxiv.org/pdf/1611.01578.pdfNeural 

Architecture Searchwith ReinforcementLearning, Zoph & Le, ICLR2016

google 利用RNN的CNN方法去进行参数搜寻

## Wide & Deep Learning实战

CTR预估用，

![1545202517713](/1545202517713.png)

左边是cateforical feature特征

右边是wide feature 组合特征 

补充笔记：

传统处理方法：人工特征工程+线性模型，如LR，但是人工进行特征组合通过会存在诸多困难，如特征爆炸， 特征难以被识别，组合特征难以设计等

深度学习处理方法，主要分为3类

* FM（因子分解机）对离散特征进行嵌入，然后对嵌入后的稠密向量进行内积来进行二阶特征组合，模型有FM、FMM
* Embedding（嵌入）+MLP（多层感知器），对不同领域 的one-hot特征进行嵌入，使其降维成低维稠密特征，然后将这些特征向量拼接成一个隐含层，之后再不断堆叠全连接层，模型有wide&deep、deep&cross、DIN等
* 组合模型：将以上模型串联组合使用，并对模型作出各种优化调整，模型有deepFM（深度因子分解机）、NFM（神经网络因子分解机）、AFM（注意力因此分解模型）等

![1545204839552](/1545204839552.png)

